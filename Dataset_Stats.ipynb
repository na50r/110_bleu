{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871abf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats Functions\n",
    "from transformers import XLMRobertaTokenizer, BertTokenizer\n",
    "from scripts.data_management import FloresPlusManager\n",
    "from os.path import join\n",
    "import tiktoken\n",
    "from scripts.util import split_sents\n",
    "ENC = tiktoken.encoding_for_model('gpt-4o')\n",
    "\n",
    "# Load tokenizers\n",
    "xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "\n",
    "def get_token_cnt(input_sents: list[str]):\n",
    "    text = '\\n'.join(input_sents)\n",
    "    return len(ENC.encode(text))\n",
    "\n",
    "def get_xlm_roberta_token_cnt(input_sents: list[str]):\n",
    "    xlmr_token_counts = [len(xlmr_tokenizer.tokenize(t)) for t in input_sents]\n",
    "    return sum(xlmr_token_counts)\n",
    "\n",
    "\n",
    "def get_bert_token_cnt(input_sents: list[str]):\n",
    "    bert_token_counts = [len(bert_tokenizer.tokenize(t)) for t in input_sents]\n",
    "    return sum(bert_token_counts)\n",
    "\n",
    "\n",
    "def get_char_cnt(input_sents: list[str]):\n",
    "    text = '\\n'.join(input_sents)\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def get_real_sent_cnt(input_sents: list[str], lang):\n",
    "    text = '\\n'.join(input_sents)\n",
    "    return len(split_sents(text, lang=lang))\n",
    "\n",
    "\n",
    "def get_flores_meta(lang: str, num_of_sents: int, *keys):\n",
    "    '''\n",
    "    lang: Flores code\n",
    "    num_of_sents: number of sents to load\n",
    "    keys: keys used in the JSON structure of each Flores+ entry\n",
    "    '''\n",
    "    dm = FloresPlusManager()\n",
    "    data = dm._load_data_files(join(dm.store, f'{lang}.jsonl'), num_of_sents)\n",
    "    meta_set = {k: set() for k in keys}\n",
    "\n",
    "\n",
    "    for o in data:\n",
    "        for k in keys:\n",
    "            meta_set[k].add(o[k])\n",
    "    nums = {key: len(meta_set[key]) for key in meta_set}\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b212ebe",
   "metadata": {},
   "source": [
    "## Flores+ Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec679b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da 50961 14097 437 12713 13999 {'url': 122, 'topic': 58}\n",
      "de 57714 13380 442 13544 27475 {'url': 122, 'topic': 58}\n",
      "el 59462 21925 431 16837 51749 {'url': 122, 'topic': 58}\n",
      "en 49427 10259 429 11573 62600 {'url': 122, 'topic': 58}\n",
      "es 58934 13463 436 13858 76509 {'url': 122, 'topic': 58}\n",
      "fi 53171 15686 448 13185 91860 {'url': 122, 'topic': 58}\n",
      "fr 58255 13914 431 14955 106291 {'url': 122, 'topic': 58}\n",
      "it 58720 14891 432 13844 120353 {'url': 122, 'topic': 58}\n",
      "nl 55471 12753 454 13233 134046 {'url': 122, 'topic': 58}\n",
      "pt 53279 12442 433 12740 147203 {'url': 122, 'topic': 58}\n",
      "sv 50031 13702 430 12490 161010 {'url': 122, 'topic': 58}\n",
      "---\n",
      "Flores 55039 14228 437 13543 14637\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import FloresPlusManager\n",
    "dm = FloresPlusManager()\n",
    "mean_flores_char = 0\n",
    "mean_flores_token = 0\n",
    "mean_flores_sent = 0\n",
    "mean_flores_xlm_roberta_token = 0\n",
    "mean_flores_bert_token = 0\n",
    "langs = FloresPlusManager.EURO_ISO_2_FLORES_CODE.keys()\n",
    "for lang in sorted(langs):\n",
    "    src_sents, _ = dm.get_sentence_pairs(lang, 'en', num_of_sents=400)\n",
    "    mean_flores_char += get_char_cnt(src_sents)\n",
    "    mean_flores_token += get_token_cnt(src_sents)\n",
    "    mean_flores_sent += get_real_sent_cnt(src_sents, lang)\n",
    "    mean_flores_xlm_roberta_token += get_xlm_roberta_token_cnt(src_sents)\n",
    "    mean_flores_bert_token += get_bert_token_cnt(src_sents)\n",
    "    \n",
    "    print(lang, get_char_cnt(src_sents), get_token_cnt(src_sents), get_real_sent_cnt(src_sents, lang), get_xlm_roberta_token_cnt(src_sents), mean_flores_bert_token, get_flores_meta(lang, 400, 'url', 'topic'))\n",
    "\n",
    "mean_flores_char /= 11\n",
    "mean_flores_token /= 11\n",
    "mean_flores_sent /= 11\n",
    "mean_flores_xlm_roberta_token /= 11\n",
    "mean_flores_bert_token /= 11\n",
    "print('---')\n",
    "print('Flores', round(mean_flores_char), round(mean_flores_token), round(mean_flores_sent), round(mean_flores_xlm_roberta_token), round(mean_flores_bert_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f8e53",
   "metadata": {},
   "source": [
    "## Europarl Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a26bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da 59634 15917 418\n",
      "de 64846 13790 434\n",
      "el 72660 24693 409\n",
      "en 62993 12323 418\n",
      "es 68227 14494 419\n",
      "fi 62544 17876 415\n",
      "fr 69581 14931 413\n",
      "it 71059 16821 422\n",
      "nl 67063 14350 462\n",
      "pt 68643 14671 413\n",
      "sv 61899 16315 447\n",
      "---\n",
      "EP 66286 16016 424\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "langs = EuroParlManager.EURO_LANGS\n",
    "mean_ep_char = 0\n",
    "mean_ep_token = 0\n",
    "mean_ep_sent = 0\n",
    "for lang in sorted(langs):\n",
    "    total_char = 0\n",
    "    total_token = 0\n",
    "    total_sent = 0\n",
    "    for l in sorted(langs):\n",
    "        if lang == l:\n",
    "            continue\n",
    "        src_sents, _ = dm.get_sentence_pairs(lang, l, num_of_sents=400)\n",
    "        total_char += get_char_cnt(src_sents)\n",
    "        total_token += get_token_cnt(src_sents)\n",
    "        total_sent += get_real_sent_cnt(src_sents, lang)\n",
    "    avg_char = total_char / 10\n",
    "    avg_token = total_token / 10\n",
    "    avg_sent = total_sent / 10\n",
    "    mean_ep_char += avg_char\n",
    "    mean_ep_token += avg_token\n",
    "    mean_ep_sent += avg_sent\n",
    "    print(lang, round(avg_char), round(avg_token), round(avg_sent))\n",
    "\n",
    "mean_ep_char /= 11\n",
    "mean_ep_token /= 11\n",
    "mean_ep_sent /= 11\n",
    "print('---')\n",
    "print('EP', round(mean_ep_char), round(mean_ep_token), round(mean_ep_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e663c0e",
   "metadata": {},
   "source": [
    "## OPUS100 Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2e9cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da 25992 7556 421\n",
      "de 32731 8295 444\n",
      "el 22259 8648 415\n",
      "es 34342 8004 430\n",
      "fi 21774 6843 423\n",
      "fr 46126 10852 422\n",
      "it 27914 7556 423\n",
      "nl 28485 6957 427\n",
      "pt 27073 6540 419\n",
      "sv 22505 6498 420\n",
      "---\n",
      "en 28320 6393 446\n",
      "---\n",
      "OPUS 28866 7649 426\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import Opus100Manager\n",
    "dm = Opus100Manager()\n",
    "langs = Opus100Manager.EURO_ISO_2_PAIR.keys()\n",
    "mean_opus_char = 0\n",
    "mean_opus_token = 0\n",
    "mean_opus_sent = 0\n",
    "\n",
    "total_char_en = 0\n",
    "total_token_en = 0\n",
    "total_sent_en = 0\n",
    "for lang in sorted(langs):\n",
    "    src_sents, _ = dm.get_sentence_pairs(lang, 'en', num_of_sents=400)\n",
    "    total_char_en += get_char_cnt(_)\n",
    "    total_token_en += get_token_cnt(_)\n",
    "    total_sent_en += get_real_sent_cnt(_, lang)\n",
    "    mean_opus_char += get_char_cnt(src_sents)\n",
    "    mean_opus_token += get_token_cnt(src_sents)\n",
    "    mean_opus_sent += get_real_sent_cnt(src_sents, lang)\n",
    "    print(lang, get_char_cnt(src_sents), get_token_cnt(src_sents), get_real_sent_cnt(src_sents, lang))\n",
    "print('---')\n",
    "avg_sent = total_sent_en / 10\n",
    "avg_token = total_token_en / 10\n",
    "avg_char = total_char_en / 10\n",
    "mean_opus_char += avg_char\n",
    "mean_opus_token += avg_token\n",
    "mean_opus_sent += avg_sent\n",
    "print('en', round(avg_char), round(avg_token), round(avg_sent))\n",
    "\n",
    "mean_opus_char /= 11\n",
    "mean_opus_token /= 11\n",
    "mean_opus_sent /= 11\n",
    "print('---')\n",
    "print('OPUS', round(mean_opus_char), round(mean_opus_token), round(mean_opus_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a95e8e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Flores Char: 55039\n",
      "Mean Flores Token: 14228\n",
      "Mean Flores Sent: 437\n",
      "---\n",
      "Mean EP Char: 66286\n",
      "Mean EP Token: 16016\n",
      "Mean EP Sent: 424\n",
      "---\n",
      "Mean Opus Char: 28866\n",
      "Mean Opus Token: 7649\n",
      "Mean Opus Sent: 426\n",
      "---\n",
      "OPUS Ratio\n",
      "Char: 0.52\n",
      "Token: 0.54\n",
      "Sent: 0.98\n",
      "---\n",
      "Char: 0.44\n",
      "Token: 0.48\n",
      "Sent: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Flores Char: {round(mean_flores_char)}')\n",
    "print(f'Mean Flores Token: {round(mean_flores_token)}')\n",
    "print(f'Mean Flores Sent: {round(mean_flores_sent)}')\n",
    "print('---')\n",
    "print(f'Mean EP Char: {round(mean_ep_char)}')\n",
    "print(f'Mean EP Token: {round(mean_ep_token)}')\n",
    "print(f'Mean EP Sent: {round(mean_ep_sent)}')\n",
    "print('---')\n",
    "print(f'Mean Opus Char: {round(mean_opus_char)}')\n",
    "print(f'Mean Opus Token: {round(mean_opus_token)}')\n",
    "print(f'Mean Opus Sent: {round(mean_opus_sent)}')\n",
    "print('---')\n",
    "print('OPUS Ratio')\n",
    "print(f'Char: {round(mean_opus_char / mean_flores_char, 2)}')\n",
    "print(f'Token: {round(mean_opus_token / mean_flores_token, 2)}')\n",
    "print(f'Sent: {round(mean_opus_sent / mean_flores_sent, 2)}')\n",
    "print('---')\n",
    "print(f'Char: {round(mean_opus_char / mean_ep_char, 2)}')\n",
    "print(f'Token: {round(mean_opus_token / mean_ep_token, 2)}')\n",
    "print(f'Sent: {round(mean_opus_sent / mean_ep_sent, 2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19958c05",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b40553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400 400\n",
      "442 429 431\n",
      "Die Polizei sagte, dass Lo Piccolo die Oberhand habe, weil er in Palermo Provenzanos rechte Hand war und seine größere Erfahrung ihm den Respekt der älteren Generationen einbrachte. Diese verfolgten Provenzanos Politik, keine Aufmerksamkeit auf sich zu ziehen, während sie ihr Machtnetzwerk stärkten.\n",
      "Police said Lo Piccolo had the upper hand because he had been Provenzano's right-hand man in Palermo and his greater experience won him the respect of the older generation of bosses as they pursued Provenzano's policy of keeping as low as possible while strengthening their power network.\n",
      "La police a déclaré que Lo Piccolo avait le dessus parce qu'il avait été le bras droit de Provenzano à Palerme et que sa plus grande expérience lui avait valu le respect de l'ancienne génération de patrons qui poursuivaient la politique de Provenzano consistant à rester aussi bas que possible tout en renforçant leur réseau de pouvoir.\n",
      "---\n",
      "Stardust wird einen neuen Allzeitrekord als das  schnellste Raumfahrzeug aufstellen, das je zur Erde zurückgekehrt ist. Damit bricht es den bisherigen Rekord, der im Mai 1969 bei der Rückkehr des Apollo X-Kommandomoduls aufgestellt wurde.\n",
      "Stardust will set a new all-time record for being the fastest spacecraft to return to Earth, breaking the previous record set in May of 1969 during the return of the Apollo X command module.\n",
      "Stardust établira un nouveau record historique pour être le vaisseau spatial le plus rapide à revenir sur Terre, battant le précédent record établi en mai 1969 lors du retour du module de commande d'Apollo X.\n",
      "---\n",
      "Enceladus ist das Objekt im Sonnensystem, das am stärksten reflektiert. Er wirft etwa 90 Prozent des auf ihn treffenden Sonnenlichts zurück.\n",
      "Enceladus is the most reflective object in the solar system, reflecting about 90 percent of the sunlight that hits it.\n",
      "Encelade est l'objet le plus réfléchissant du système solaire. Il réfléchit environ 90 % de la lumière du soleil qui le frappe.\n",
      "---\n",
      "Der Broadcasting Services Act sorgt für eine Regulierung von Online-Inhalten. Um jedoch als Online-Inhalt zu gelten, muss dieser physisch auf einem Server abgelegt sein.\n",
      "The Broadcasting Services Act provides for the regulation of Internet content, however to be considered Internet content, it must physically reside on a server.\n",
      "La loi sur les services de radiodiffusion prévoit la réglementation du contenu Internet, mais pour être considéré comme un contenu Internet, il doit physiquement résider sur un serveur.\n",
      "---\n",
      "Der Schriftzug wurde nicht physisch beschädigt. Die Änderung erfolgte mit schwarzen Planen, die mit Friedenszeichen und Herzen bedruckt waren, um das „O“ in ein kleines „e“ zu ändern.\n",
      "The sign was not physically damaged; the modification was done using black tarpaulins decorated with signs of peace and heart to alter the \"O\" to read lowercase \"e\".\n",
      "Le panneau n’a pas été endommagé ; la modification a été faite à l’aide de bâches noires décorées avec le symbole de la paix et celui de cœur pour changer le « O » en « e » minuscule.\n",
      "---\n",
      "Die Angreifer von Mumbai kamen am 26. November 2008 mit Hilfe von Booten und brachten Granaten und automatische Waffen mit. Sie trafen mehrere Ziele, einschließlich den vielbesuchten Chhatrapai Shivaji Terminus-Bahnhof und das berühmte Taj Mahal-Hotel.\n",
      "The Mumbai attackers arrived via boat on Novemeber 26, 2008, bringing with them grenades, automatic weapons and hit multiple targets including the crowded Chhatrapati Shivaji Terminus railway station and the famous Taj Mahal Hotel.\n",
      "Les attaquants de Mumbai sont arrivés par bateau le 26 novembre 2008, apportant avec eux des grenades, des armes automatiques et ont touché de multiples cibles, dont la gare ferroviaire bondée Chhatrapati Shivaji Terminus et le célèbre hôtel Taj Mahal.\n",
      "---\n",
      "Danach deuteten Beweismittel darauf hin, dass Testpapiere manipuliert worden waren. Hall wurde 2013 zusammen mit 34 anderen Entscheidungsträgern im Bildungswesen angeklagt.\n",
      "Evidence thereafter indicated test papers were tampered with Hall, along with 34 other education officials, was indicted in 2013.\n",
      "Les preuves ont montré par la suite que les tests avaient été falsifiés par Hall, ainsi que par 34 autres fonctionnaires de l'éducation nationale, qui ont été mis en examen en 2013.\n",
      "---\n",
      "Nach Zeugenaussagen fuhr der Bus am Samstag um 1:15 Uhr über ein grünes Licht, als das Auto vor ihm abbog.\n",
      "At 1:15 a.m. Saturday, according to witnesses, the bus was going through a green light when the car made a turn in front of it.\n",
      "Selon les témoins, samedi à 1 h 15 du matin, le bus franchissait une ligne verte quand la voiture s’est retournée devant lui.\n",
      "---\n",
      "Die Absturzstelle wurde heute gefunden. Sie ist so unzugänglich, dass zwei Polizisten im Dschungel abgesetzt wurden, um zum Unfallort zu gelangen und nach Überlebenden zu suchen.\n",
      "The crash site was located today and is so inaccessable that two policemen were dropped into the jungle in order to hike to the scene and seek survivors.\n",
      "Le lieu du crash, identifié ce jour, est si difficile d'accès qu'il a fallu déposer deux policiers dans la jungle afin qu'ils atteignent le site à la recherche d'éventuels survivants.\n",
      "---\n",
      "Diese Steilhänge wurden überall auf dem Mond gefunden und scheinen nur minimal verwittert zu sein. Das lässt darauf schließen, dass die geologischen Ereignisse, die sie verursachten, relativ kürzlich stattgefunden haben.\n",
      "These scarps were found all over the moon and appear to be minimally weathered, indicating that the geologic events that created them were fairly recent.\n",
      "Ces escarpements ont été trouvés sur toute la surface de la lune et semblent être très peu altérés, ce qui indique que les phénomènes géologiques qui les ont créés sont assez récents.\n",
      "---\n",
      "Am 18. März 1965 hat er den ersten bemannten Außenboardeinsatz (EVA), auch „Weltraumspaziergang“ genannt, durchgeführt. Dabei hielt er sich ein wenig länger als zwölf Minuten außerhalb des Raumfahrzeugs auf.\n",
      "On March 18, 1965, he performed the first manned extravehicular activity (EVA), or \"spacewalk\", remaining alone outside the spacecraft for just over twelve minutes.\n",
      "Le 18 mars 1965, il a effectué la première activité extravéhiculaire habitée, ou « sortie dans l'espace », restant seul à l'extérieur du vaisseau spatial pendant un peu plus de douze minutes.\n",
      "---\n",
      "Muldenkipper wurden eingesetzt, um die Eingänge der U-Bahn zu blockieren. 80 Polizisten waren zur Stelle, um die Autofahrer umzuleiten.\n",
      "Dump trucks were used to block tube entrances and assistance of 80 police were on hand to direct motorists to detours.\n",
      "Des camions-bennes ont été réquisitionnés pour bloquer les entrées du métro et 80 policiers se trouvaient sur place pour orienter les automobilistes vers les déviations.\n",
      "---\n",
      "\"Als ein Bundesstaat nach dem \"\"Winner takes all\"\"-Prinzip gab Florida alle fünfzig Wahlmännerstimmen an Romney. Damit beförderte es ihn an die Spitze für das Nominierungsrennen der Republikanischen Partei.\"\n",
      "As a winner-takes-all state, Florida awarded all fifty of its delegates to Romney, pushing him ahead as the front-runner for the Republican Party nomination.\n",
      "En tant qu'état où le vainqueur remporte tout, la Floride a décerné à Romney ses cinquante délégués, le poussant ainsi en tête de liste pour la nomination du parti républicain.\n",
      "---\n",
      "Manche Wissenschaftler denken, dass Triceratops Palmfarne fraß. Das ist eine Pflanzenart, die in der Kreidezeit verbreitet war.\n",
      "Some scientists think Triceratops ate cycads, which are a type of plant that was common in the Cretaceous.\n",
      "Certains scientifiques pensent que le tricératops mangeait des cycadées, un type de plante qui était très courant pendant la période crétacée.\n",
      "---\n",
      "Nach anfänglichen militärischen Rückschlägen konnte sich Æthelred mit Olaf auf Bedingungen einigen. Letzterer kehrte nach Norwegen zurück, um mit wechselhaftem Erfolg zu versuchen, sein Königreich zu erlangen.\n",
      "After initial military setbacks, Ethelred was able to agree to terms with Olaf, who returned to Norway to try to gain his kingdom with mixed success.\n",
      "Après les premiers échecs militaires, Ethereld est parventu à un accord avec Olaf, pour sa part retourné en Norvège afin d'essayer de reconquérir son royaume, pour des résultats mitigés.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import FloresPlusManager\n",
    "from scripts.util import split_sents\n",
    "dm = FloresPlusManager()\n",
    "\n",
    "de_sents, en_sents = dm.get_sentence_pairs('de', 'en', num_of_sents=400)\n",
    "fr_sents, en_sents = dm.get_sentence_pairs('fr', 'en', num_of_sents=400)\n",
    "print(len(de_sents), len(en_sents), len(fr_sents))\n",
    "print(get_real_sent_cnt(de_sents, 'de'), get_real_sent_cnt(en_sents, 'en'), get_real_sent_cnt(fr_sents, 'fr'))\n",
    "\n",
    "for i, (d, e) in enumerate(zip(de_sents, en_sents)):\n",
    "    d_s = split_sents(d, 'de')\n",
    "    e_s = split_sents(e, 'en')\n",
    "    if len(d_s) != len(e_s):\n",
    "        print(d)\n",
    "        print(e)\n",
    "        print(fr_sents[i])\n",
    "        print('---')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c962cb",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4811523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "tokens = tokenizer(\"This is a test.\", return_tensors=\"pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
