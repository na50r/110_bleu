{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a32e0c",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "**IMPORTANT**: This notebook assums that the `tasks` folder is in the same folder as the notebook, as well as `proc1-6.log`, `it-el.txt`, `it-el.log` and `it-el.mhtml`, otherwise it acts as documentation and should not be run.\n",
    "\n",
    "* The translation tasks have been completed and all translations are now stored in certain hierarchy within the `tasks` folder, which was backed up with the logs associated with it. At the time of writing, it is unclear what can be made public or not, the logs contain IP addresses in some cases due to how the errors were logged, the translations could be uplouded to Google Drive and provided to the public. For now, we plan to only provide them to evaluators of this project. \n",
    "\n",
    "* In this notebook, we re-structure the translation data to make it easier to work with them (align & evaluate)\n",
    "* First, we extract time information found in proc1-3 logs as the start times stored proc1-3 JSONL files include each time OpenAI's code triggered an automatic retry.\n",
    "* Second, we rename filenames and move all translations into a single folder, preserve hierarchy by using prefixes and omit procedure-related information, as it is not required for alignment and evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcc926c",
   "metadata": {},
   "source": [
    "## Getting Preciser Timestamps\n",
    "* In proc 1 to 3, there were cases where GPT4.1 took longer than expected. \n",
    "* The structured logs in the JSONL file stored the start time when the method that calls the API was called and the end time when the response was received. \n",
    "* However, this did not account for the case of OpenAI's code doing the retries, so the retries where included in the time calculation.\n",
    "* In this notebook, we use the logs to extract start and end times that are more in line with the real translation time\n",
    "* We do this by looking at the `DEBUG` logs created by OpenAI's code, they contain an entry of when exactly a request was sent.\n",
    "* The end time we can obtain by our own logs, looking for `Translated X sents for src-tgt` message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2895f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 2025-05-09 13:18:06 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 13:22:10 - [âœ”ï¸]: Translated 400 sents for fr-da\n",
      "DEBUG: 2025-05-09 13:22:10 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 13:26:42 - [âœ”ï¸]: Translated 400 sents for fr-de\n",
      "DEBUG: 2025-05-09 13:26:42 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG: 2025-05-09 13:31:43 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 13:36:34 - [âœ”ï¸]: Translated 400 sents for fr-el\n",
      "DEBUG: 2025-05-09 13:36:35 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 13:39:17 - [âœ”ï¸]: Translated 400 sents for fr-es\n",
      "DEBUG: 2025-05-09 13:39:17 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG: 2025-05-09 13:49:07 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG: 2025-05-09 13:54:08 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 13:58:41 - [âœ”ï¸]: Translated 400 sents for fr-fi\n",
      "DEBUG: 2025-05-09 13:58:41 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 14:02:23 - [âœ”ï¸]: Translated 400 sents for fr-it\n",
      "DEBUG: 2025-05-09 14:02:23 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 14:07:12 - [âœ”ï¸]: Translated 400 sents for fr-nl\n",
      "DEBUG: 2025-05-09 14:07:12 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-09 14:10:56 - [âœ”ï¸]: Translated 400 sents for fr-pt\n",
      "DEBUG: 2025-05-09 14:10:56 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n"
     ]
    }
   ],
   "source": [
    "!cat proc3.log | grep -P \"(Sending HTTP Request: POST https://api.openai.com/v1/chat/completions|Translated \\d+ sents for \\w\\w-\\w\\w)\" | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a12cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pt', 'da')\n",
      "start 2025-05-09 19:19:38\n",
      "end 2025-05-09 19:28:39\n",
      "duration 541.1454193592072\n",
      "\n",
      "('sv', 'es')\n",
      "start 2025-05-09 21:21:34\n",
      "end 2025-05-09 21:24:14\n",
      "duration 160.7068531513214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "from datetime import datetime\n",
    "\n",
    "with open(join('tasks', 'proc3.jsonl'), 'r') as f:\n",
    "    logs = [json.loads(ln) for ln in f.readlines()]\n",
    "\n",
    "pairs = [('sv', 'es'), ('pt', 'da')]\n",
    "\n",
    "for log in logs:\n",
    "    pair = (log['src_lang'], log['tgt_lang'])\n",
    "    if pair in pairs:\n",
    "        print(pair)\n",
    "        start = datetime.fromtimestamp(\n",
    "            log['start']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        end = datetime.fromtimestamp(log['end']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('start', start)\n",
    "        print('end', end)\n",
    "        print('duration', log['end'] - log['start'])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda0327",
   "metadata": {},
   "source": [
    "* For some cases, the structured logs from `proc3.jsonl` got the time right because the automtic retries exceeded OpenAI's limit of 2 retries and triggered the retries implemented by us, which restarted the timing.\n",
    "* However, in other cases, such as `pt-da`, we observe that the structured logs captured start time `19:19:38` which corresponds to the first try of OpenAI's code, not the last, hence the duration is longer than it really was.\n",
    "* Our goal is to now to go through proc1 to 3 logs and store the real start and end times. We lose precision as we aren't working with Unix timestamps anymore, however, since we mainly work with seconds, it should not make a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d02feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat proc2.log proc3.log | grep -P \"(Sending HTTP Request: POST https://api.openai.com/v1/chat/completions|Translated \\d+ sents for \\w\\w-\\w\\w)\" | grep -P -B1 \"(Translated \\d+ sents for \\w\\w-\\w\\w)\" > tmp_proc2-3.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_proc2-3.log', 'r') as f:\n",
    "    logs = [ln for ln in f if ln.startswith('DEBUG') or ln.startswith('INFO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441ab579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pat = r\"Translated \\d+ sents for (\\w\\w-\\w\\w)\"\n",
    "pair2log_idx = {}\n",
    "for i, log in enumerate(logs):\n",
    "    if log.startswith('INFO'):\n",
    "        pair = re.search(pat, log).group(1)\n",
    "        pair2log_idx[pair] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14bd2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pair2time = {}\n",
    "time_pat = r\"(\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d)\"\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "for pair in pair2log_idx:\n",
    "    idx = pair2log_idx[pair]\n",
    "    start = re.search(time_pat, logs[idx-1]).group(1)\n",
    "    end = re.search(time_pat, logs[idx]).group(1)\n",
    "    start = datetime.strptime(start, fmt)\n",
    "    start_unix = time.mktime(start.timetuple())\n",
    "    end = datetime.strptime(end, fmt)\n",
    "    end_unix = time.mktime(end.timetuple())\n",
    "    pair2time[pair] = {'start': start_unix, 'end': end_unix}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35832f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "# Number of translations generated by Proc2\n",
    "!ls tasks/proc2/europarl/gpt-4.1-2025-04-14/*.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0e357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Number of translations generated by Proc 3\n",
    "!ls tasks/proc3/europarl-*/gpt-4.1-2025-04-14/*.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6826ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc2_success = 44 \n",
    "proc3_success = 42\n",
    "len(pair2time) == proc2_success + proc3_success\n",
    "proc2_3_gpt_ep = pair2time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff62e26",
   "metadata": {},
   "source": [
    "* For Proc1, we need to make it a bit smarter, since Proc1 involved EuroParl, Opus100 and Flores+ as well, so we cannot use the pair directly as the sole key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d45c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat proc1.log | grep -P \"(Sending HTTP Request: POST https://api.openai.com/v1/chat/completions|Translated \\d+ sents for \\w\\w-\\w\\w)\" | grep -P -B1 \"(Translated \\d+ sents for \\w\\w-\\w\\w)\" | grep -P -A1 \"^(DEBUG)\" > tmp_proc1.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e96fd695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 2025-05-07 13:55:46 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-07 13:59:58 - [âœ”ï¸]: Translated 398 sents for de-en\n",
      "DEBUG: 2025-05-07 13:59:58 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-07 14:03:12 - [âœ”ï¸]: Translated 400 sents for en-de\n",
      "DEBUG: 2025-05-07 14:03:12 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-07 14:05:34 - [âœ”ï¸]: Translated 400 sents for da-en\n",
      "DEBUG: 2025-05-07 14:05:34 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-07 14:08:09 - [âœ”ï¸]: Translated 400 sents for en-da\n",
      "DEBUG: 2025-05-07 14:08:09 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-07 14:12:09 - [âœ”ï¸]: Translated 400 sents for el-en\n"
     ]
    }
   ],
   "source": [
    "!cat tmp_proc1.log | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5742db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_proc1.log', 'r') as f:\n",
    "    logs = [ln for ln in f if ln.startswith('DEBUG') or ln.startswith('INFO')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e954521d",
   "metadata": {},
   "source": [
    "* We exploit the fact that the logs are in chronological order\n",
    "* We know which Dataset was used with GPT4.1 first, second and third, so we can rely on the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9813daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pat = r\"Translated \\d+ sents for (\\w\\w-\\w\\w)\"\n",
    "pair2log_idx = {}\n",
    "for i, log in enumerate(logs):\n",
    "    if log.startswith('INFO'):\n",
    "        pair = re.search(pat, log).group(1)\n",
    "        if pair not in pair2log_idx:\n",
    "            pair2log_idx[pair] = [i]\n",
    "        else:\n",
    "            pair2log_idx[pair].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02303959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pair2time = {}\n",
    "time_pat = r\"(\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d)\"\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "for pair in pair2log_idx:\n",
    "    indices = pair2log_idx[pair]\n",
    "    pair2time[pair] = []\n",
    "    for idx in indices:\n",
    "        if logs[idx-1].startswith('DEBUG'):\n",
    "            start = re.search(time_pat, logs[idx-1]).group(1)\n",
    "            end = re.search(time_pat, logs[idx]).group(1)\n",
    "            start = datetime.strptime(start, fmt)\n",
    "            start_unix = time.mktime(start.timetuple())\n",
    "            end = datetime.strptime(end, fmt)\n",
    "            end_unix = time.mktime(end.timetuple())\n",
    "            pair2time[pair].append({'start': start_unix, 'end': end_unix})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0af6c1",
   "metadata": {},
   "source": [
    "* Since Proc1 was successful throughout, we expect 3 time values for each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0611e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = [len(times) == 3 for times in pair2time.values()]\n",
    "all(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec78def3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \"task_id\": \"9549e927-4f63-4205-82bb-5c7ccabfe943\",\n",
      "    \"task_id\": \"fdbf6190-d061-4154-ae94-d7b11199d043\",\n",
      "    \"task_id\": \"fa628bc1-4f85-446d-9167-1a8d99ccc493\",\n"
     ]
    }
   ],
   "source": [
    "!cat tasks/proc1/europarl/gpt-4.1-2025-04-14/task.json | grep -P 'task_id'\n",
    "!cat tasks/proc1/flores_plus/gpt-4.1-2025-04-14/task.json | grep -P 'task_id'\n",
    "!cat tasks/proc1/opus-100/gpt-4.1-2025-04-14/task.json | grep -P 'task_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db216488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 2025-05-07 13:55:45 - [ğŸ]: Starting task 9549e927-4f63-4205-82bb-5c7ccabfe943 on commit 66ef922\n",
      "INFO: 2025-05-07 15:01:53 - [ğŸ]: Starting task fa628bc1-4f85-446d-9167-1a8d99ccc493 on commit 66ef922\n",
      "INFO: 2025-05-07 15:41:35 - [ğŸ]: Starting task fdbf6190-d061-4154-ae94-d7b11199d043 on commit 66ef922\n"
     ]
    }
   ],
   "source": [
    "!cat proc1.log | grep -P \"Starting task (9549e927-|fdbf6190-|fa628bc1-)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856dca60",
   "metadata": {},
   "source": [
    "* So we infer that the first one is EuroParl, the second is Opus100 and the third is FloresPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f9e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair2time_modified = {}\n",
    "for pair, times in pair2time.items():\n",
    "    pair2time_modified[pair] = {'ep': times[0], 'opus': times[1], 'flores': times[2]}\n",
    "\n",
    "proc1_gpt = pair2time_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126221fe",
   "metadata": {},
   "source": [
    "* For Proc 4 to 6, we can rely on structured logs as there were no automatic retries from OpenAI's side anymore.\n",
    "* We can still confirm as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "988760fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat proc4.log | grep -P \"(Sending HTTP Request: POST https://api.openai.com/v1/chat/completions|Translated \\d+ sents for \\w\\w-\\w\\w)\" | grep -P -B1 \"(Translated \\d+ sents for \\w\\w-\\w\\w)\" > tmp_proc4.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "001f0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp_proc4.log', 'r') as f:\n",
    "    logs = [ln for ln in f if ln.startswith('DEBUG') or ln.startswith('INFO')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76867064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pat = r\"Translated \\d+ sents for (\\w\\w-\\w\\w)\"\n",
    "pair2log_idx = {}\n",
    "for i, log in enumerate(logs):\n",
    "    if log.startswith('INFO'):\n",
    "        pair = re.search(pat, log).group(1)\n",
    "        pair2log_idx[pair] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e269747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pair2time = {}\n",
    "time_pat = r\"(\\d\\d\\d\\d-\\d\\d-\\d\\d \\d\\d:\\d\\d:\\d\\d)\"\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "for pair in pair2log_idx:\n",
    "    idx = pair2log_idx[pair]\n",
    "    start = re.search(time_pat, logs[idx-1]).group(1)\n",
    "    end = re.search(time_pat, logs[idx]).group(1)\n",
    "    start = datetime.strptime(start, fmt)\n",
    "    start_unix = time.mktime(start.timetuple())\n",
    "    end = datetime.strptime(end, fmt)\n",
    "    end_unix = time.mktime(end.timetuple())\n",
    "    pair2time[pair] = {'start': start_unix, 'end': end_unix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1338aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair2time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0bbc945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(join('tasks', 'proc4.jsonl'), 'r') as f:\n",
    "    logs = [json.loads(ln) for ln in f.readlines()]\n",
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d4df21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_keys_1 = set(pair2time.keys())\n",
    "pair_keys_2 = set([f'{log[\"src_lang\"]}-{log[\"tgt_lang\"]}' for log in logs])\n",
    "pair_keys_1 == pair_keys_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ee8c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diff: 0.79 s\n",
      "Min diff: -1.21 s\n",
      "Mean diff: -0.19 s\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "for log in logs:\n",
    "    pair = (log['src_lang'], log['tgt_lang'])\n",
    "    pair_key = '-'.join(pair)\n",
    "    structured_dur = log['end'] - log['start']\n",
    "    unstructured_dur = pair2time[pair_key]['end'] - pair2time[pair_key]['start']\n",
    "    diff = structured_dur - unstructured_dur\n",
    "    diffs.append(diff)\n",
    "\n",
    "print(f'Max diff: {max(diffs):.2f} s')\n",
    "print(f'Min diff: {min(diffs):.2f} s')\n",
    "print(f'Mean diff: {sum(diffs)/len(diffs):.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7d6fa",
   "metadata": {},
   "source": [
    "* Not too tragic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "940b4e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da-de\n",
      "duration (structured log) 179.83 s\n",
      "duration (unstructured log) 180.00 s\n",
      "\n",
      "de-fi\n",
      "duration (structured log) 290.98 s\n",
      "duration (unstructured log) 292.00 s\n",
      "\n",
      "el-sv\n",
      "duration (structured log) 160.37 s\n",
      "duration (unstructured log) 160.00 s\n",
      "\n",
      "it-pt\n",
      "duration (structured log) 155.24 s\n",
      "duration (unstructured log) 155.00 s\n",
      "\n",
      "it-sv\n",
      "duration (structured log) 196.79 s\n",
      "duration (unstructured log) 196.00 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "selected_pairs = sample(list(pair_keys_1), 5)\n",
    "for log in logs:\n",
    "    pair = (log['src_lang'], log['tgt_lang'])\n",
    "    pair_key = '-'.join(pair)\n",
    "    if pair_key in selected_pairs:\n",
    "        print(pair_key)\n",
    "        print('duration (structured log)', f'{log[\"end\"] - log[\"start\"]:.2f} s')\n",
    "        print('duration (unstructured log)', f'{pair2time[pair_key][\"end\"] - pair2time[pair_key][\"start\"]:.2f} s')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9903d5",
   "metadata": {},
   "source": [
    "## Preparing Files for Analysis\n",
    "* At the moment, all files are stored hierarchically in the `tasks` folder\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ proc1\n",
    "â”‚Â Â  â”œâ”€â”€ europarl\n",
    "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ deepl_document\n",
    "â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ da-en.txt\n",
    "|   |   |   |â”€â”€ ...\n",
    "â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ task.json\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”‚Â Â      â”œâ”€â”€ da-en.txt\n",
    "|   |   |   |â”€â”€ ...\n",
    "â”‚Â Â  â”‚Â Â      â””â”€â”€ task.json\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus\n",
    "â”‚Â Â  â”‚Â Â  â”œâ”€â”€ deepl_document\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â””â”€â”€ opus-100\n",
    "â”‚Â Â      â”œâ”€â”€ deepl_document\n",
    "â”‚Â Â      â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”œâ”€â”€ proc1.jsonl\n",
    "â”œâ”€â”€ proc2\n",
    "â”‚Â Â  â””â”€â”€ europarl\n",
    "â”‚Â Â      â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”œâ”€â”€ proc2.jsonl\n",
    "â”œâ”€â”€ proc3\n",
    "â”‚Â Â  â”œâ”€â”€ europarl-fr\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ europarl-it\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ europarl-nl\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ europarl-pt\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ europarl-sv\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”œâ”€â”€ proc3.jsonl\n",
    "â”œâ”€â”€ proc4\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-da\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-de\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-el\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-es\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-fi\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-fr\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-it\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-nl\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â”œâ”€â”€ flores_plus-pt\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â””â”€â”€ flores_plus-sv\n",
    "â”‚Â Â      â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”œâ”€â”€ proc4.jsonl\n",
    "â”œâ”€â”€ proc5\n",
    "â”‚Â Â  â”œâ”€â”€ europarl\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â  â””â”€â”€ flores_plus\n",
    "â”‚Â Â      â””â”€â”€ gpt-4.1-2025-04-14\n",
    "â”‚Â Â          â”œâ”€â”€ de-fi.txt\n",
    "â”‚Â Â          â””â”€â”€ task.json\n",
    "â”œâ”€â”€ proc5.jsonl\n",
    "â”œâ”€â”€ proc6\n",
    "â”‚Â Â  â”œâ”€â”€ europarl\n",
    "â”‚Â Â  â”‚Â Â  â””â”€â”€ deepl_document\n",
    "â”‚Â Â  â””â”€â”€ flores_plus\n",
    "â”‚Â Â      â””â”€â”€ deepl_document\n",
    "â””â”€â”€ proc6.jsonl\n",
    "```\n",
    "\n",
    "\n",
    "* This is not very convenient for analysis purposes, so we stored them all into a single folder preserve hierarchical information by filename prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f78e9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer 20 translations from proc1: task=ep-deepl \n",
      "\n",
      "Transfer 20 translations from proc1: task=ep-gpt \n",
      "\n",
      "Transfer 20 translations from proc1: task=flores-deepl \n",
      "\n",
      "Transfer 20 translations from proc1: task=flores-gpt \n",
      "\n",
      "Transfer 20 translations from proc1: task=opus-deepl \n",
      "\n",
      "Transfer 20 translations from proc1: task=opus-gpt \n",
      "\n",
      "Transfer 44 translations from proc2: task=ep-gpt \n",
      "\n",
      "Transfer 9 translations from proc3: task=ep-gpt (fr)\n",
      "\n",
      "Transfer 7 translations from proc3: task=ep-gpt (it)\n",
      "\n",
      "Transfer 9 translations from proc3: task=ep-gpt (nl)\n",
      "\n",
      "Transfer 9 translations from proc3: task=ep-gpt (pt)\n",
      "\n",
      "Transfer 8 translations from proc3: task=ep-gpt (sv)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (da)\n",
      "\n",
      "Skip failed entry: proc4: flores-gpt-de-fi_fail2\n",
      "Transfer 8 translations from proc4: task=flores-gpt (de)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (el)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (es)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (fi)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (fr)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (it)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (nl)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (pt)\n",
      "\n",
      "Transfer 9 translations from proc4: task=flores-gpt (sv)\n",
      "\n",
      "Transfer 3 translations from proc5: task=ep-gpt \n",
      "\n",
      "Transfer 1 translations from proc5: task=flores-gpt \n",
      "\n",
      "Transfer 90 translations from proc6: task=ep-deepl \n",
      "\n",
      "Transfer 90 translations from proc6: task=flores-deepl \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import json\n",
    "\n",
    "procs = [f'proc{i}' for i in range(1, 7)]\n",
    "\n",
    "long2short = {\n",
    "    'gpt-4.1-2025-04-14': 'gpt',\n",
    "    'deepl_document': 'deepl',\n",
    "    'opus-100': 'opus',\n",
    "    'europarl': 'ep',\n",
    "    'flores_plus': 'flores'\n",
    "}\n",
    "\n",
    "prefix2file = {}\n",
    "\n",
    "\n",
    "procs = [p for p in os.listdir('tasks') if not p.endswith('.jsonl')]\n",
    "for proc in procs:\n",
    "    with open(join('tasks', f'{proc}.jsonl'), 'r') as fi:\n",
    "        logs = [json.loads(ln) for ln in fi]\n",
    "    \n",
    "    proc_path = join('tasks', proc)\n",
    "    datasets = os.listdir(proc_path)\n",
    "    for dataset in datasets:\n",
    "        dataset_path = join(proc_path, dataset)\n",
    "        addon = None\n",
    "        \n",
    "        # Account for different procedures\n",
    "        if proc in ['proc1', 'proc2', 'proc5', 'proc6']:\n",
    "            short_ds = long2short[dataset]\n",
    "        else:\n",
    "            short_ds = long2short[dataset.split('-')[0]]\n",
    "            addon = dataset.split('-')[1]\n",
    "        \n",
    "        translators = os.listdir(dataset_path)\n",
    "        for translator in translators:\n",
    "            translator_path = join(dataset_path, translator)\n",
    "            short_tl = long2short[translator]\n",
    "\n",
    "            translations = [t for t in os.listdir(translator_path) if t.endswith('.txt')]\n",
    "            num_of_translations = len(translations)\n",
    "            if num_of_translations == 0:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            with open(join(translator_path, 'task.json')) as f:\n",
    "                task = json.load(f)\n",
    "            \n",
    "            for translation in translations:\n",
    "                pair = translation.replace('.txt', '')\n",
    "                # A failed pair is one that contains substantially more or less than 400 sentences\n",
    "                if 'fail' in pair:\n",
    "                    print(f'Skip failed entry: {proc}: {short_ds}-{short_tl}-{pair}')\n",
    "                    num_of_translations -= 1\n",
    "                    continue\n",
    "\n",
    "                prefix = f'{short_ds}-{short_tl}-{pair}'\n",
    "                prefix2file[prefix] = {'file': join(translator_path, translation), 'procedure': proc, 'task':task}\n",
    "                for log in logs:\n",
    "                    log_pair = f'{log[\"src_lang\"]}-{log[\"tgt_lang\"]}'\n",
    "                    log_translator = log['translator']\n",
    "                    log_dataset = long2short[log['dataset'].split('/')[1]]\n",
    "                    if log_pair == pair and log_translator==translator and log_dataset==short_ds:\n",
    "                        prefix2file[prefix]['log'] = log\n",
    "                    if addon:\n",
    "                        add = f'({addon})'\n",
    "                    else:\n",
    "                        add = ''\n",
    "            print(f'Transfer {num_of_translations} translations from {proc}: task={short_ds}-{short_tl} {add}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156be5fd",
   "metadata": {},
   "source": [
    "Reminder\n",
    "* proc1 had no issues, no translation was skipped\n",
    "* proc2 failed to translate `fi-el`, skipped, hence 44 instead of expected 45\n",
    "* proc3 failed to translate `it-el`, `it-fi` and `sv-el`, hence 7 and 8 instead of expected 9\n",
    "* proc4 failed to translate `de-fi`, no error, just not expected number of output sentences\n",
    "* proc5 used to trasnlate 5 skipped ones, 4 (3 ep, 1 flores) succeeded, failed `it-el`\n",
    "* proc6 had no issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350bb58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opus:40\n",
      "ep:219\n",
      "flores:220\n",
      "\n",
      "deepl:240\n",
      "gpt:239\n"
     ]
    }
   ],
   "source": [
    "opus = 0\n",
    "flores = 0\n",
    "ep = 0\n",
    "deepl = 0\n",
    "gpt = 0\n",
    "for prefix, info in prefix2file.items():\n",
    "    p1 = prefix.split('-')[0]\n",
    "    p2 = prefix.split('-')[1]\n",
    "    if p2 == 'deepl':\n",
    "        deepl+=1\n",
    "    if p2 == 'gpt':\n",
    "        gpt+=1\n",
    "    if p1 == 'opus':\n",
    "        opus+=1\n",
    "    if p1 == 'ep':\n",
    "        ep+=1\n",
    "    if p1 == 'flores':\n",
    "        flores+=1\n",
    "\n",
    "\n",
    "print(f'opus:{opus}\\nep:{ep}\\nflores:{flores}\\n')\n",
    "print(f'deepl:{deepl}\\ngpt:{gpt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f5f9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-en: 251.73s -> 252.00s \n",
      "opus-gpt-de-en: 76.07s -> 76.00s \n",
      "flores-gpt-de-en: 107.51s -> 108.00s \n",
      "ep-gpt-en-de: 193.44s -> 194.00s \n",
      "opus-gpt-en-de: 114.27s -> 114.00s \n",
      "flores-gpt-en-de: 169.91s -> 170.00s \n",
      "ep-gpt-da-en: 141.60s -> 142.00s \n",
      "opus-gpt-da-en: 98.62s -> 99.00s \n",
      "flores-gpt-da-en: 128.14s -> 129.00s \n",
      "ep-gpt-en-da: 155.34s -> 155.00s \n",
      "opus-gpt-en-da: 136.54s -> 137.00s \n",
      "flores-gpt-en-da: 186.58s -> 187.00s \n",
      "ep-gpt-el-en: 239.32s -> 240.00s \n",
      "opus-gpt-el-en: 98.73s -> 98.00s \n",
      "flores-gpt-el-en: 220.27s -> 220.00s \n",
      "ep-gpt-en-el: 238.58s -> 239.00s \n",
      "opus-gpt-en-el: 217.24s -> 217.00s \n",
      "flores-gpt-en-el: 599.17s -> 299.00s [!]\n",
      "ep-gpt-pt-en: 88.44s -> 89.00s \n",
      "opus-gpt-pt-en: 85.96s -> 86.00s \n",
      "flores-gpt-pt-en: 169.84s -> 170.00s \n",
      "ep-gpt-en-pt: 120.94s -> 121.00s \n",
      "opus-gpt-en-pt: 105.46s -> 106.00s \n",
      "flores-gpt-en-pt: 187.91s -> 188.00s \n",
      "ep-gpt-sv-en: 110.78s -> 111.00s \n",
      "opus-gpt-sv-en: 64.26s -> 64.00s \n",
      "flores-gpt-sv-en: 133.35s -> 133.00s \n",
      "ep-gpt-en-sv: 105.27s -> 105.00s \n",
      "opus-gpt-en-sv: 82.77s -> 83.00s \n",
      "flores-gpt-en-sv: 134.15s -> 134.00s \n",
      "ep-gpt-es-en: 115.95s -> 116.00s \n",
      "opus-gpt-es-en: 85.51s -> 86.00s \n",
      "flores-gpt-es-en: 102.99s -> 103.00s \n",
      "ep-gpt-en-es: 159.55s -> 159.00s \n",
      "opus-gpt-en-es: 93.92s -> 94.00s \n",
      "flores-gpt-en-es: 135.10s -> 135.00s \n",
      "ep-gpt-fi-en: 139.69s -> 139.00s \n",
      "opus-gpt-fi-en: 94.77s -> 95.00s \n",
      "flores-gpt-fi-en: 156.83s -> 157.00s \n",
      "ep-gpt-en-fi: 575.17s -> 275.00s [!]\n",
      "opus-gpt-en-fi: 179.24s -> 179.00s \n",
      "flores-gpt-en-fi: 223.18s -> 223.00s \n",
      "ep-gpt-fr-en: 145.33s -> 145.00s \n",
      "opus-gpt-fr-en: 98.14s -> 98.00s \n",
      "flores-gpt-fr-en: 121.60s -> 122.00s \n",
      "ep-gpt-en-fr: 176.46s -> 176.00s \n",
      "opus-gpt-en-fr: 181.12s -> 182.00s \n",
      "flores-gpt-en-fr: 137.28s -> 137.00s \n",
      "ep-gpt-it-en: 152.93s -> 153.00s \n",
      "opus-gpt-it-en: 82.12s -> 82.00s \n",
      "flores-gpt-it-en: 129.80s -> 130.00s \n",
      "ep-gpt-en-it: 176.88s -> 177.00s \n",
      "opus-gpt-en-it: 89.78s -> 90.00s \n",
      "flores-gpt-en-it: 184.11s -> 185.00s \n",
      "ep-gpt-nl-en: 189.70s -> 190.00s \n",
      "opus-gpt-nl-en: 63.21s -> 63.00s \n",
      "flores-gpt-nl-en: 106.15s -> 106.00s \n",
      "ep-gpt-en-nl: 207.53s -> 207.00s \n",
      "opus-gpt-en-nl: 136.40s -> 137.00s \n",
      "flores-gpt-en-nl: 148.80s -> 149.00s \n"
     ]
    }
   ],
   "source": [
    "# Update times\n",
    "for pair, datasets in proc1_gpt.items():\n",
    "    for dataset, times in datasets.items():\n",
    "        key = f'{dataset}-gpt-{pair}'\n",
    "        diff1 = prefix2file[key]['log']['end'] - prefix2file[key]['log']['start']\n",
    "        diff2 = times['end'] - times['start']\n",
    "        prefix2file[key]['log']['start'] = times['start']\n",
    "        prefix2file[key]['log']['end'] = times['end']\n",
    "        if round(diff1, 2) != round(diff2, 2):\n",
    "            if abs(diff1-diff2) > 2:\n",
    "                add = '[!]'\n",
    "            else:\n",
    "                add = ''\n",
    "            print(f'{key}: {diff1:.2f}s -> {diff2:.2f}s {add}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd513cb",
   "metadata": {},
   "source": [
    "* In theory, we could have used a more sophisticated regular expression to only account for the cases where duration would be reduced substantially but for completion sake, we did it fully for proc1 gpt tasks\n",
    "* There is a slight loss in precision since the structured logs stored in UNIX epochs directly, whereas the raw logs used timestamps\n",
    "* The important cases where reduction was substantial, greater than 2 seconds, emphasized with `[!]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd8c70fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-da-de: 156.66s -> 157.00s \n",
      "ep-gpt-da-el: 278.81s -> 279.00s \n",
      "ep-gpt-da-es: 218.03s -> 218.00s \n",
      "ep-gpt-da-fi: 588.78s -> 288.00s [!]\n",
      "ep-gpt-da-fr: 166.79s -> 167.00s \n",
      "ep-gpt-da-it: 232.04s -> 232.00s \n",
      "ep-gpt-da-nl: 244.76s -> 245.00s \n",
      "ep-gpt-da-pt: 213.71s -> 214.00s \n",
      "ep-gpt-da-sv: 202.09s -> 202.00s \n",
      "ep-gpt-de-da: 178.06s -> 178.00s \n",
      "ep-gpt-de-el: 569.56s -> 269.00s [!]\n",
      "ep-gpt-de-es: 201.55s -> 202.00s \n",
      "ep-gpt-de-fi: 205.06s -> 205.00s \n",
      "ep-gpt-de-fr: 227.59s -> 228.00s \n",
      "ep-gpt-de-it: 173.11s -> 173.00s \n",
      "ep-gpt-de-nl: 209.11s -> 209.00s \n",
      "ep-gpt-de-pt: 211.15s -> 211.00s \n",
      "ep-gpt-de-sv: 511.33s -> 192.00s [!]\n",
      "ep-gpt-el-da: 280.89s -> 281.00s \n",
      "ep-gpt-el-de: 230.38s -> 231.00s \n",
      "ep-gpt-el-es: 220.42s -> 221.00s \n",
      "ep-gpt-el-fi: 256.99s -> 257.00s \n",
      "ep-gpt-el-fr: 219.91s -> 220.00s \n",
      "ep-gpt-el-it: 278.71s -> 279.00s \n",
      "ep-gpt-el-nl: 170.33s -> 171.00s \n",
      "ep-gpt-el-pt: 236.71s -> 237.00s \n",
      "ep-gpt-el-sv: 200.67s -> 201.00s \n",
      "ep-gpt-es-da: 243.37s -> 244.00s \n",
      "ep-gpt-es-de: 194.29s -> 194.00s \n",
      "ep-gpt-es-el: 254.19s -> 255.00s \n",
      "ep-gpt-es-fi: 244.82s -> 245.00s \n",
      "ep-gpt-es-fr: 241.38s -> 242.00s \n",
      "ep-gpt-es-it: 159.30s -> 159.00s \n",
      "ep-gpt-es-nl: 214.55s -> 215.00s \n",
      "ep-gpt-es-pt: 145.63s -> 146.00s \n",
      "ep-gpt-es-sv: 216.18s -> 216.00s \n",
      "ep-gpt-fi-da: 242.88s -> 243.00s \n",
      "ep-gpt-fi-de: 241.34s -> 241.00s \n",
      "ep-gpt-fi-es: 220.12s -> 220.00s \n",
      "ep-gpt-fi-fr: 205.75s -> 206.00s \n",
      "ep-gpt-fi-it: 232.78s -> 233.00s \n",
      "ep-gpt-fi-nl: 300.36s -> 301.00s \n",
      "ep-gpt-fi-pt: 200.18s -> 200.00s \n",
      "ep-gpt-fi-sv: 269.22s -> 270.00s \n",
      "ep-gpt-fr-da: 243.23s -> 244.00s \n",
      "ep-gpt-fr-de: 271.62s -> 272.00s \n",
      "ep-gpt-fr-el: 592.28s -> 291.00s [!]\n",
      "ep-gpt-fr-es: 162.11s -> 162.00s \n",
      "ep-gpt-fr-fi: 1164.01s -> 273.00s [!]\n",
      "ep-gpt-fr-it: 221.33s -> 222.00s \n",
      "ep-gpt-fr-nl: 289.03s -> 289.00s \n",
      "ep-gpt-fr-pt: 223.50s -> 224.00s \n",
      "ep-gpt-fr-sv: 289.97s -> 290.00s \n",
      "ep-gpt-it-da: 868.21s -> 267.00s [!]\n",
      "ep-gpt-it-de: 193.62s -> 193.00s \n",
      "ep-gpt-it-es: 182.50s -> 182.00s \n",
      "ep-gpt-it-fr: 186.09s -> 186.00s \n",
      "ep-gpt-it-nl: 265.56s -> 266.00s \n",
      "ep-gpt-it-pt: 210.34s -> 211.00s \n",
      "ep-gpt-it-sv: 298.68s -> 299.00s \n",
      "ep-gpt-nl-da: 562.67s -> 263.00s [!]\n",
      "ep-gpt-nl-de: 535.17s -> 234.00s [!]\n",
      "ep-gpt-nl-el: 820.63s -> 218.00s [!]\n",
      "ep-gpt-nl-es: 214.88s -> 215.00s \n",
      "ep-gpt-nl-fi: 290.31s -> 290.00s \n",
      "ep-gpt-nl-fr: 263.76s -> 264.00s \n",
      "ep-gpt-nl-it: 267.90s -> 268.00s \n",
      "ep-gpt-nl-pt: 203.56s -> 203.00s \n",
      "ep-gpt-nl-sv: 293.55s -> 293.00s \n",
      "ep-gpt-pt-da: 541.15s -> 241.00s [!]\n",
      "ep-gpt-pt-de: 271.21s -> 271.00s \n",
      "ep-gpt-pt-el: 288.94s -> 289.00s \n",
      "ep-gpt-pt-es: 216.67s -> 217.00s \n",
      "ep-gpt-pt-fi: 894.12s -> 291.00s [!]\n",
      "ep-gpt-pt-fr: 207.93s -> 208.00s \n",
      "ep-gpt-pt-it: 220.97s -> 221.00s \n",
      "ep-gpt-pt-nl: 223.90s -> 224.00s \n",
      "ep-gpt-pt-sv: 234.47s -> 235.00s \n",
      "ep-gpt-sv-da: 227.19s -> 227.00s \n",
      "ep-gpt-sv-de: 268.01s -> 268.00s \n",
      "ep-gpt-sv-es: 160.71s -> 161.00s \n",
      "ep-gpt-sv-fi: 279.47s -> 279.00s \n",
      "ep-gpt-sv-fr: 198.13s -> 198.00s \n",
      "ep-gpt-sv-it: 170.09s -> 170.00s \n",
      "ep-gpt-sv-nl: 229.57s -> 230.00s \n",
      "ep-gpt-sv-pt: 134.98s -> 135.00s \n"
     ]
    }
   ],
   "source": [
    "for pair, times in proc2_3_gpt_ep.items():\n",
    "    key = f'ep-gpt-{pair}'\n",
    "    diff1 = prefix2file[key]['log']['end'] - prefix2file[key]['log']['start']\n",
    "    diff2 = times['end'] - times['start']\n",
    "    prefix2file[key]['log']['start'] = times['start']\n",
    "    prefix2file[key]['log']['end'] = times['end']\n",
    "    if round(diff1, 2) != round(diff2, 2):\n",
    "        if abs(diff1-diff2) > 2:\n",
    "            add = '[!]'\n",
    "        else:\n",
    "            add = ''\n",
    "        print(f'{key}: {diff1:.2f}s -> {diff2:.2f}s {add}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b79e25",
   "metadata": {},
   "source": [
    "* For proc2 and 3 it is much more noticable, more `[!]` visible\n",
    "* Updating the times does give a clearer idea of the 'true translation time', at least without any retries in-between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ab8ca",
   "metadata": {},
   "source": [
    "### Adding `it-el`\n",
    "* One pair we had to obtain with other means, see `it-el.ipynb`, the last 3 cells\n",
    "* We add this pair to `prefix2file` as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a47ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'ep-gpt-it-el'\n",
    "file_path = 'it-el.txt'\n",
    "with open(join('tmp-it-el', 'task.json')) as f:\n",
    "    task = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a77a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: 2025-05-16 10:50:52 - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO: 2025-05-16 10:55:53 - [â­ï¸]: Failed 0 times, skipping it-el...\n",
      "INFO: 2025-05-16 10:55:53 - [ğŸ]: Task took 301.63s\n"
     ]
    }
   ],
   "source": [
    "!cat it-el.log | grep -P \"(Sending HTTP Request: POST https://api.openai.com/v1/chat/completions|Failed)\"\n",
    "!cat it-el.log | grep -P \"Task took\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2df3604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "fmt = \"%Y-%m-%d %H:%M:%S\"\n",
    "start_stamp = \"2025-05-16 10:50:52\"\n",
    "end_stamp = \"2025-05-16 10:55:53\"\n",
    "start = datetime.strptime(start_stamp, fmt).timestamp()\n",
    "end = datetime.strptime(end_stamp, fmt).timestamp()\n",
    "time_entries = {'start': start, 'end': end}\n",
    "# The following is just perfectionism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7123315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot-Content-Location: https://platform.openai.com/logs/chatcmpl-BXl4IuCVnFZTSuF2Nwy7nMkqNRndr\n",
      "Subject: Logs - chatcmpl-BXl4IuCVnFZTSuF2Nwy7nMkqNRndr - OpenAI API\n",
      "edium\">Input</span></div><span class=3D\"font-medium\">17,445t</span></div><d=\n",
      "x items-center gap-1\"><span class=3D\"font-medium\">Output</span></div><span =\n",
      "class=3D\"font-medium\">24,907t</span></div><div class=3D\"SzU-2\"><div class=\n"
     ]
    }
   ],
   "source": [
    "# Single Web Page file of the log page from OpenAI Platform\n",
    "!cat it-el.mhtml | grep -P 'chatcmp' | head -n2\n",
    "!cat it-el.mhtml | grep -P 'Input'\n",
    "!cat it-el.mhtml | grep -P -A1 'Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6748b9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.util import split_sents\n",
    "from scripts.logger import TranslationLogger\n",
    "dm = EuroParlManager()\n",
    "with open('it-el.txt', 'r') as f:\n",
    "    mt_lines = [ln.strip() for ln in f]\n",
    "\n",
    "src_lines, tgt_lines = dm.get_sentence_pairs(src_lang='it', tgt_lang='el', num_of_sents=400)\n",
    "src_text = '\\n'.join(src_lines)\n",
    "mt_text = '\\n'.join(mt_lines)\n",
    "src_sents = split_sents(src_text, lang='it')\n",
    "mt_sents = split_sents(mt_text, lang='el')\n",
    "\n",
    "logger = TranslationLogger(logfile='tmp')\n",
    "\n",
    "logger.start(src_lang='it', tgt_lang='el', src_text=src_text)\n",
    "logger.finish(tgt_text=mt_text, in_model_tokens=17445, out_model_tokens=24907)\n",
    "retry = {\n",
    "    'prev_id' : None,\n",
    "    'reason': 'exceptional case; obtained through OpenAI logs, id=chatcmpl-BXl4IuCVnFZTSuF2Nwy7nMkqNRndr'\n",
    "}\n",
    "logger.add_entry(manual_retry=retry)\n",
    "logger.add_entry(translator='gpt-4.1-2025-04-14')\n",
    "logger.add_entry(dataset='Helsinki-NLP/europarl')\n",
    "log = logger.curr_log\n",
    "log.update(time_entries)\n",
    "log.update({'manual_retry':True})\n",
    "log.update({'error_msg':'504 Gateway Timeout'})\n",
    "log['end']-log['start']  # should be around 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5acef372",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix2file[prefix] = {'file':file_path, 'log':log, 'task':task}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e3ccb",
   "metadata": {},
   "source": [
    "### Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e820041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually move all files from tasks to a folder called translations\n",
    "import shutil\n",
    "os.makedirs('translations', exist_ok=True)\n",
    "for prefix, info in prefix2file.items():\n",
    "    shutil.copy(info['file'], join('translations', f'{prefix}.txt'))\n",
    "\n",
    "with open(join('translations', 'info.json'), 'w') as f:\n",
    "    json.dump(prefix2file, fp=f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e39e170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = os.listdir('translations')\n",
    "# Should contain 240 + 240 + info.json = 481\n",
    "len(check) == 481"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f061918",
   "metadata": {},
   "source": [
    "Again, all files that are required for this notebook to run will be provided to the evaluators of this project. It just explains how the `translations` folder was created, which is used for the remainder of this project for alignment and evaluation. The translations folder may be provided to the public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b4046",
   "metadata": {},
   "source": [
    "## Alignment Consideration\n",
    "* We can somewhat guess which translations may yield low BLEU score due to misalignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "859f65bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-en 398\n",
      "ep-gpt-en-fi 401\n",
      "ep-gpt-es-en 401\n",
      "opus-gpt-de-en 372\n",
      "opus-gpt-pt-en 402\n",
      "ep-gpt-da-it 399\n",
      "ep-gpt-de-fi 399\n",
      "ep-gpt-el-it 399\n",
      "ep-gpt-el-nl 399\n",
      "ep-gpt-es-el 399\n",
      "ep-gpt-es-nl 399\n",
      "ep-gpt-fi-it 399\n",
      "ep-gpt-fi-nl 399\n",
      "ep-gpt-pt-fi 401\n",
      "ep-gpt-sv-fi 399\n",
      "flores-gpt-es-el 402\n",
      "flores-gpt-fi-da 402\n",
      "flores-gpt-fi-el 402\n",
      "flores-gpt-fi-es 402\n",
      "flores-gpt-fi-nl 402\n",
      "flores-gpt-fi-pt 402\n",
      "flores-gpt-it-fr 402\n",
      "ep-gpt-it-fi 399\n",
      "23 pairs likely need to be re-aligned\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "num = 0\n",
    "for prefix, info in prefix2file.items():\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        print(prefix, outlines)\n",
    "        num += 1\n",
    "\n",
    "print(f'{num} pairs likely need to be re-aligned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
