{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4639a32",
   "metadata": {},
   "source": [
    "# Costs\n",
    "* 110 pairs the European languages used in Phillip Koehn's paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbd7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_management import FloresPlusManager, EuroParlManager, Opus100Manager\n",
    "from scripts.stats import get_deepl_cost, get_gpt41_cost\n",
    "langs = EuroParlManager.EURO_LANGS\n",
    "\n",
    "pairs = []\n",
    "for x in langs:\n",
    "    for y in langs:\n",
    "        if x != y:\n",
    "            pairs.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5a21af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 90)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_1 = []\n",
    "run_2 = []\n",
    "\n",
    "for pair in pairs:\n",
    "    if 'en' in pair:\n",
    "        run_1.append(pair)\n",
    "    else:\n",
    "        run_2.append(pair)\n",
    "\n",
    "len(run_1), len(run_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c788a73",
   "metadata": {},
   "source": [
    "## Phase 1\n",
    "* Compute translations from and into English for 10 European languages accross 3 Corpora and 2 Translators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07684df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepl Cost for Run 1: €58.42\n",
      "GPT4.1 Cost for Run 1: $6.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_ep = EuroParlManager()\n",
    "dm_flo = FloresPlusManager()\n",
    "dm_opus = Opus100Manager()\n",
    "dms = [dm_ep, dm_flo, dm_opus]\n",
    "\n",
    "deepl_cost = []\n",
    "gpt41_cost = []\n",
    "\n",
    "for pair in run_1:\n",
    "    s, t = pair\n",
    "    for dm in dms:\n",
    "        src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "        deepl_cost.append(get_deepl_cost(src_sents))\n",
    "        gpt41_cost.append(get_gpt41_cost(src_sents))\n",
    "\n",
    "print(f'Deepl Cost for Run 1: €{sum(deepl_cost):.2f}')\n",
    "print(f'GPT4.1 Cost for Run 1: ${sum(gpt41_cost):.2f}')\n",
    "len(deepl_cost), len(gpt41_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd06521",
   "metadata": {},
   "source": [
    "## Phase 2\n",
    "* Compute translations for the remaining 90 language directions to obtain a matrix of 110 BLEU scores for 2 Corpora and 2 Translators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepl Cost for Run 2: €219.94\n",
      "GPT4.1 Cost for Run 2: $27.91\n"
     ]
    }
   ],
   "source": [
    "dm_ep = EuroParlManager()\n",
    "dm_flo = FloresPlusManager()\n",
    "dm_opus = Opus100Manager()\n",
    "dms = [dm_ep, dm_flo]\n",
    "deepl_cost = []\n",
    "gpt41_cost = []\n",
    "\n",
    "for pair in run_2:\n",
    "    s, t = pair\n",
    "    for dm in dms:\n",
    "        src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "        deepl_cost.append(get_deepl_cost(src_sents))\n",
    "        gpt41_cost.append(get_gpt41_cost(src_sents))\n",
    "\n",
    "print(f'Deepl Cost for Run 2: €{sum(deepl_cost):.2f}')\n",
    "print(f'GPT4.1 Cost for Run 2: ${sum(gpt41_cost):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56f6a1",
   "metadata": {},
   "source": [
    "* Thus, cost for Deepl for the whole project would be around €280 and for GPT4.1 around $35\n",
    "* However, we use tiktoken to estimate the token counts, input token count is slightly higher due to the user prompt and system prompt additions to the input text and output token count tends to be lower than input usually. We can roughly raise our estimation by 10% and should be close to the truth, thus GPT4.1 cost would be around $40. \n",
    "* Note: Yes, I tend to round up. Over estimation of cost does no harm, as it will guarantee that the code runs and doesn't halt because we ran out of budget. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860e699",
   "metadata": {},
   "source": [
    "## Storage Cost\n",
    "* Based on `Demo.ipynb`, we observe that one pair creates `.txt` file between 7-8 KB. Let us assume that we get always 10 KB per pair (overestimate)\n",
    "* We plan to translate for 400 sentences rather than 50, so then we have 10 * 8 = 80 KB per pair \n",
    "* For Phase 1, we have 20 pairs, 3 datasets and 2 translators, so 20 * 3 * 2 = 120 files. 120 * 80 = 9600 KB.\n",
    "* For Phase 2, we have 90 pairs, 2 datasets and 2 translators, so 90 * 2 * 2 = 360 files. 360 * 80 = 28800 KB.\n",
    "* In total, we expect to store 38400 KB roughly = 38.4 MB (overestimated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
