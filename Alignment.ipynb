{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e994de5b",
   "metadata": {},
   "source": [
    "## Direct Triplets\n",
    "* No alignment is performed on the text, we just place source, reference and translation side by side based on their order (line by line) in the dataset and translation output.\n",
    "* I.e., assume that translators preserved the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "dst_path = join(triplet_folder, 'direct_triplets')\n",
    "parts = {\n",
    "    'opus': {'dm': Opus100Manager(), 'pairs': Opus100Manager.get_pairs()},\n",
    "    'ep': {'dm': EuroParlManager(), 'pairs': EuroParlManager.get_pairs()},\n",
    "    'flores': {'dm': FloresPlusManager(), 'pairs': FloresPlusManager.get_pairs()}\n",
    "}\n",
    "translators = ['gpt', 'deepl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b466a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align, load_sents_from_file\n",
    "fn2align_cnt_direct = {}\n",
    "for dataset, content in parts.items():\n",
    "    dm = content['dm']\n",
    "    pairs = content['pairs']\n",
    "    for pair in pairs:\n",
    "        s, t = pair\n",
    "        for translator in translators:\n",
    "            filename = f'{dataset}-{translator}-{s}-{t}'\n",
    "            mt_sents = load_sents_from_file(\n",
    "                folder='translations', filename=filename)\n",
    "            src_sents, tgt_sents = dm.get_sentence_pairs(\n",
    "                s, t, num_of_sents=400)\n",
    "            cnt = direct_triplet_align(\n",
    "                mt_sents=mt_sents,\n",
    "                src_sents=src_sents,\n",
    "                ref_sents=tgt_sents,\n",
    "                folder_path=dst_path,\n",
    "                filename=filename\n",
    "            )\n",
    "            fn2align_cnt_direct[filename] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2104efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1\n",
      "398 1\n",
      "399 20\n",
      "400 458\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_direct.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('direct_cnt.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_direct, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672225e",
   "metadata": {},
   "source": [
    "* Direct alignment only removes empty strings if there are any\n",
    "* Most of the time, we have 400 aligned triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae565ce",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITHOUT Sentence Splitting\n",
    "* Alignments were computed in this notebook: [Alignments_No_Sent_Split.ipynb](https://colab.research.google.com/drive/1867NBRM7ixgiVmeznqRf4oh9nYDd4D5S?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1535bc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5758495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 383\n",
      "max: 398\n",
      "mean: 396.31\n",
      "\n",
      "ep-deepl\n",
      "min: 369\n",
      "max: 398\n",
      "mean: 395.77\n",
      "\n",
      "flores-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 396.65\n",
      "\n",
      "flores-deepl\n",
      "min: 374\n",
      "max: 400\n",
      "mean: 396.61\n",
      "\n",
      "opus-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 397.85\n",
      "\n",
      "opus-deepl\n",
      "min: 395\n",
      "max: 400\n",
      "mean: 398.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split = {}\n",
    "fn2discard_no_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split[fn] = align_cnt\n",
    "    fn2discard_no_sent_split[fn] = dis\n",
    "    case2align_cnts_no_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_no_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 1\n",
      "372 2\n",
      "374 19\n",
      "383 2\n",
      "384 1\n",
      "391 1\n",
      "392 2\n",
      "393 8\n",
      "394 13\n",
      "395 38\n",
      "396 36\n",
      "397 144\n",
      "398 47\n",
      "399 32\n",
      "400 134\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_no_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c26dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_no_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_no_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d2e82",
   "metadata": {},
   "source": [
    "### Investigating Loss of Text\n",
    "* If we apply `bertalign` WITHOUT sentence splitting to all translations, we lose text in some cases.\n",
    "* The 'biggest' loss is 391-369=22 sentences for `ep-deepl-sv-de`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67e06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "!cat translations/ep-deepl-sv-de.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3076ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "!cat $src2hyp_split_fo/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28da166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "!cat $dst_path/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bcb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vi skall rösta om begäran från PPE-DE-gruppen som syftar till att stryka den muntliga frågan om kapitalskatt från föredragningslistan.',\n",
       " '(Parlamentet avslog begäran med 164 röster för, 166 emot. 7 ledamöter avstod från att rösta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering för att han just gjort reklam för denna debatt.',\n",
       " 'Tack.',\n",
       " 'Fru talman!',\n",
       " 'Jag undrar om även min röst har räknats, trots att den inte kunde avges på elektronisk väg, eftersom jag inte har något kort?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.post_process import load_aligned_sents_from_file, load_sents_from_file\n",
    "mt_sents = load_sents_from_file('ep-deepl-sv-de', 'translations')\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('sv', 'de', num_of_sents=400)\n",
    "src_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44083fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir stimmen jetzt über den Antrag der PPE/DE-Fraktion ab, die mündliche Anfrage über die Kapitalsteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 Ja-Stimmen, 166 Nein-Stimmen und 7 Enthaltungen ab.)',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering für das Rühren der Werbetrommel zugunsten dieser Aussprache danken.',\n",
       " 'Vielen Dank.',\n",
       " 'Frau Präsidentin!',\n",
       " 'Ist meine Stimme mitgezählt worden? Ich konnte sie nämlich nicht elektronisch abgeben, weil ich die Karte nicht habe.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e40454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir werden über den Antrag der Fraktion der Europäischen Volkspartei (Christdemokraten) und europäischer Demokraten abstimmen, die mündliche Anfrage zur Gesellschaftssteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering dafür danken, dass er diese Aussprache soeben angekündigt hat.',\n",
       " 'Vielen Dank, Herr Pöttering.',\n",
       " 'Frau Präsidentin, ich möchte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gezählt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00934af",
   "metadata": {},
   "source": [
    "* The direct alignment for this specific instance is correct, however, we already observe a slight difference between reference and translation\n",
    "* `Vielen Dank` vs `Vielen Dank, Herr Pöttering.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8c18a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Parlamentet avslog begäran med 164 röster för, 166 emot. 7 ledamöter avstod från att rösta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering för att han just gjort reklam för denna debatt.',\n",
       " '',\n",
       " 'Tack. Fru talman!',\n",
       " 'Jag undrar om även min röst har räknats, trots att den inte kunde avges på elektronisk väg, eftersom jag inte har något kort?',\n",
       " 'Jag röstade \"för\".',\n",
       " 'Om man lägger till de två kolleger som yttrat sig blir resultatet...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sents_ali, mt_sents_ali = load_aligned_sents_from_file('ep-deepl-sv-de', src2hyp_split_fo)\n",
    "src_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7d20d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering dafür danken, dass er diese Aussprache soeben angekündigt hat.',\n",
       " 'Vielen Dank, Herr Pöttering.',\n",
       " 'Frau Präsidentin, ich möchte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gezählt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?',\n",
       " 'Ich habe mit \"Ja\" gestimmt.',\n",
       " 'Wenn Sie die beiden Kollegen, die sich zu Wort gemeldet haben, hinzuzählen, lautet das Ergebnis...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4731f0",
   "metadata": {},
   "source": [
    "* Alignment with `bertalign` works but is dependent on the translation. It merged the source sentences together to get a 2-1 alignment with:\n",
    "```\n",
    "'Tack. Fru talman!' <->  'Vielen Dank, Herr Pöttering.',\n",
    "```\n",
    "* As a consequence, we see an empty string in the aligned source sentences\n",
    "* Furthermore, since the original source sentences do not contain the string `'Tack. Fru talman!'`, it will be discarded, as triplet alignments are created by matching the sentences from the original source strings to the aligned source strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c1cd",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITH Sentences Splitting\n",
    "* The alignments were computed in this notebook: [Alignments.ipynb](https://colab.research.google.com/drive/1xlwQPctsOGjZB2NpB9WNtzWPae_Oj4gt?usp=sharing)\n",
    "* Note: To make alignments with sentence splitting, we had to align source to reference AND source to translation, whereas before only source to translation was enough, as we could use the alignments provided by the respective datasets directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97698926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "# Aligned source to translation\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_sent_split')\n",
    "# Aligned source to reference\n",
    "src2ref_split_fo = join(aligned_folder, 'source2reference_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1cc932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 329\n",
      "max: 396\n",
      "mean: 374.74\n",
      "\n",
      "ep-deepl\n",
      "min: 328\n",
      "max: 395\n",
      "mean: 377.38\n",
      "\n",
      "flores-gpt\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.58\n",
      "\n",
      "flores-deepl\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.23\n",
      "\n",
      "opus-gpt\n",
      "min: 361\n",
      "max: 399\n",
      "mean: 382.95\n",
      "\n",
      "opus-deepl\n",
      "min: 361\n",
      "max: 398\n",
      "mean: 383.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn2align_cnt_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    src_sents_o, ref_sents_o = load_aligned_sents_from_file(\n",
    "        f'{dataset}-{s}-{t}', folder=src2ref_split_fo)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_sent_split[fn] = align_cnt\n",
    "    case2align_cnts_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a34f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 1\n",
      "329 1\n",
      "333 2\n",
      "334 1\n",
      "335 1\n",
      "336 1\n",
      "338 3\n",
      "339 5\n",
      "342 2\n",
      "343 2\n",
      "344 2\n",
      "345 1\n",
      "347 1\n",
      "348 2\n",
      "349 1\n",
      "351 2\n",
      "356 1\n",
      "357 1\n",
      "360 2\n",
      "361 4\n",
      "362 2\n",
      "363 1\n",
      "364 2\n",
      "365 1\n",
      "366 6\n",
      "367 2\n",
      "368 3\n",
      "369 4\n",
      "370 3\n",
      "371 1\n",
      "372 5\n",
      "373 2\n",
      "374 5\n",
      "375 5\n",
      "376 4\n",
      "377 11\n",
      "378 14\n",
      "379 7\n",
      "380 7\n",
      "381 7\n",
      "382 7\n",
      "383 12\n",
      "384 13\n",
      "385 4\n",
      "386 18\n",
      "387 8\n",
      "388 12\n",
      "389 11\n",
      "390 16\n",
      "391 13\n",
      "392 6\n",
      "393 4\n",
      "394 7\n",
      "395 3\n",
      "396 3\n",
      "397 3\n",
      "398 4\n",
      "399 2\n",
      "400 2\n",
      "401 1\n",
      "403 4\n",
      "404 1\n",
      "405 3\n",
      "406 4\n",
      "407 1\n",
      "408 2\n",
      "409 2\n",
      "410 1\n",
      "411 6\n",
      "412 7\n",
      "413 8\n",
      "414 4\n",
      "415 5\n",
      "416 3\n",
      "417 6\n",
      "418 10\n",
      "419 13\n",
      "420 14\n",
      "421 20\n",
      "422 13\n",
      "423 30\n",
      "424 20\n",
      "425 10\n",
      "426 8\n",
      "427 5\n",
      "428 3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0224cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aae253",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "* For all three triplet formations, no alignment, alignment without sentence splitting and alignment with sentence splitting, we compute BLUE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f85930",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = get_env_variables('TMP_RESULTS')\n",
    "!rm -rf {results_folder}\n",
    "!mkdir {results_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9f041",
   "metadata": {},
   "source": [
    "* Compute BLEU scores to show differences in alignments approaches; no final results here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f3e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "results_folder = get_env_variables('TMP_RESULTS')\n",
    "\n",
    "result_types = {'direct_results':join(triplet_folder, 'direct_triplets'), \n",
    "                'aligned_results_no_sent_split': join(triplet_folder, 'aligned_triplets_no_sent_split'),\n",
    "                'aligned_results_sent_split': join(triplet_folder, 'aligned_triplets_sent_split')}\n",
    "\n",
    "for rt in result_types:\n",
    "    files = os.listdir(result_types[rt])\n",
    "    output_path = join(results_folder, f'{rt}.csv')\n",
    "    l2f = {f.replace('.jsonl', ''): join(result_types[rt], f) for f in files}\n",
    "    rp = ResultProducer(label2files=l2f)\n",
    "    rp.compute_and_store_results(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc454065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.presentation import parse_results_from_file\n",
    "direct_df = parse_results_from_file(join(results_folder, 'direct_results.csv'))\n",
    "aligned_df_no_sent_split = parse_results_from_file(\n",
    "    join(results_folder, 'aligned_results_no_sent_split.csv'))\n",
    "aligned_df_sent_split = parse_results_from_file(\n",
    "    join(results_folder, 'aligned_results_sent_split.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e19b2",
   "metadata": {},
   "source": [
    "## Difference between Alignment WITH and WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2681f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('aligned_cnt_no_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_no_sent_split = json.load(f)\n",
    "\n",
    "with open('aligned_cnt_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_sent_split = json.load(f)\n",
    "\n",
    "with open('direct_cnt.json', 'r') as f:\n",
    "    fn2align_cnt_direct = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "373c269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_cnts = {\n",
    "    'direct':fn2align_cnt_direct, \n",
    "    'sent_split':fn2align_cnt_sent_split,\n",
    "    'no_sent_split':fn2align_cnt_no_sent_split\n",
    "}\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for d in fn_cnts:\n",
    "    data = {'dataset': [], 'translator': [], 'src_lang': [], 'tgt_lang': [], 'align_cnt': []}\n",
    "    for fn in fn_cnts[d]:\n",
    "        dataset, translator, src_lang, tgt_lang = fn.split('-')\n",
    "        data['dataset'].append(dataset)\n",
    "        data['translator'].append(translator)\n",
    "        data['src_lang'].append(src_lang)\n",
    "        data['tgt_lang'].append(tgt_lang)\n",
    "        data['align_cnt'].append(fn_cnts[d][fn])\n",
    "    df = pd.DataFrame(data)\n",
    "    dfs[d] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc30f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged = pd.merge(aligned_df_no_sent_split, aligned_df_sent_split, on=['dataset', 'translator', 'src_lang', 'tgt_lang'])\n",
    "for d in dfs:\n",
    "    if d == 'direct': continue\n",
    "    tmp = dfs[d].copy()\n",
    "    tmp[f'{d}-align_cnt'] = tmp['align_cnt']\n",
    "    tmp.drop(columns=['align_cnt'], inplace=True)\n",
    "    merged = pd.merge(merged, tmp, on=['dataset', 'translator', 'src_lang', 'tgt_lang'])\n",
    "merged['BLEU_DIFF'] = merged['BLEU_x'] - merged['BLEU_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abd9abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU_DIFF</th>\n",
       "      <th>no_sent_split-align_cnt</th>\n",
       "      <th>sent_split-align_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-3.396974</td>\n",
       "      <td>400</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-2.511440</td>\n",
       "      <td>397</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-2.482981</td>\n",
       "      <td>397</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-2.446469</td>\n",
       "      <td>400</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-2.430071</td>\n",
       "      <td>395</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-2.413389</td>\n",
       "      <td>397</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-2.409091</td>\n",
       "      <td>395</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-2.404507</td>\n",
       "      <td>400</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-2.350724</td>\n",
       "      <td>397</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-2.226007</td>\n",
       "      <td>398</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-2.190534</td>\n",
       "      <td>395</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-2.177262</td>\n",
       "      <td>397</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-2.162031</td>\n",
       "      <td>397</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-2.090055</td>\n",
       "      <td>396</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-2.046331</td>\n",
       "      <td>397</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-1.976364</td>\n",
       "      <td>397</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-1.949673</td>\n",
       "      <td>397</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-1.937530</td>\n",
       "      <td>400</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-1.935028</td>\n",
       "      <td>397</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-1.840061</td>\n",
       "      <td>400</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>-1.740180</td>\n",
       "      <td>399</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>-1.733598</td>\n",
       "      <td>400</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>-1.664564</td>\n",
       "      <td>396</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-1.660536</td>\n",
       "      <td>400</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>-1.645872</td>\n",
       "      <td>372</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-1.614495</td>\n",
       "      <td>399</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.609479</td>\n",
       "      <td>397</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-1.606200</td>\n",
       "      <td>400</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-1.592785</td>\n",
       "      <td>397</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-1.583274</td>\n",
       "      <td>395</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BLEU_DIFF  no_sent_split-align_cnt  sent_split-align_cnt\n",
       "452  -3.396974                      400                   362\n",
       "85   -2.511440                      397                   345\n",
       "80   -2.482981                      397                   343\n",
       "474  -2.446469                      400                   377\n",
       "454  -2.430071                      395                   374\n",
       "194  -2.413389                      397                   338\n",
       "199  -2.409091                      395                   333\n",
       "472  -2.404507                      400                   364\n",
       "190  -2.350724                      397                   343\n",
       "459  -2.226007                      398                   381\n",
       "89   -2.190534                      395                   333\n",
       "83   -2.177262                      397                   339\n",
       "193  -2.162031                      397                   339\n",
       "88   -2.090055                      396                   336\n",
       "84   -2.046331                      397                   338\n",
       "86   -1.976364                      397                   339\n",
       "196  -1.949673                      397                   338\n",
       "479  -1.937530                      400                   380\n",
       "81   -1.935028                      397                   342\n",
       "470  -1.840061                      400                   379\n",
       "443  -1.740180                      399                   382\n",
       "450  -1.733598                      400                   381\n",
       "445  -1.664564                      396                   372\n",
       "453  -1.660536                      400                   393\n",
       "461  -1.645872                      372                   368\n",
       "460  -1.614495                      399                   384\n",
       "197  -1.609479                      397                   329\n",
       "446  -1.606200                      400                   394\n",
       "195  -1.592785                      397                   344\n",
       "465  -1.583274                      395                   373"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = merged.sort_values(by='BLEU_DIFF', ascending=True)\n",
    "sorted_df[['BLEU_DIFF', 'no_sent_split-align_cnt', 'sent_split-align_cnt']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f61ba7",
   "metadata": {},
   "source": [
    "* Negative Differences mean that Alignment WITH Sentence Splitting yielded higher BLEU scores than WITHOUT\n",
    "* However, we can see based on alignment counts, that it may be not related to alignment but due to the fact that it works with less sentences overall.\n",
    "* Additionally, the highest difference we observe is -3.4, not too tragic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845680a9",
   "metadata": {},
   "source": [
    "## Difference between Direct and Alignment WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95b54533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "suspects = {}\n",
    "\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "    \n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        suspects[prefix] = outlines\n",
    "len(suspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49848d9",
   "metadata": {},
   "source": [
    "* We have 23 suspects that we assume to be misaligned\n",
    "* We marke the these 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9358a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged = pd.merge(direct_df, aligned_df_no_sent_split, on=['dataset', 'translator', 'src_lang', 'tgt_lang'])\n",
    "for d in dfs:\n",
    "    if d == 'sent_split': continue\n",
    "    tmp = dfs[d].copy()\n",
    "    tmp[f'{d}-align_cnt'] = tmp['align_cnt']\n",
    "    tmp.drop(columns=['align_cnt'], inplace=True)\n",
    "    merged = pd.merge(merged, tmp, on=['dataset', 'translator', 'src_lang', 'tgt_lang'])\n",
    "merged['BLEU_DIFF'] = merged['BLEU_x'] - merged['BLEU_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e2e60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['suspect'] = False\n",
    "for label in suspects:\n",
    "    dataset, translator, s, t = label.split('-')\n",
    "\n",
    "    condition = (\n",
    "        (merged['dataset'] == dataset) &\n",
    "        (merged['translator'] == translator) &\n",
    "        (merged['src_lang'] == s) &\n",
    "        (merged['tgt_lang'] == t)\n",
    "    )\n",
    "\n",
    "    merged.loc[condition, 'suspect'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67246669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU_DIFF</th>\n",
       "      <th>direct-align_cnt</th>\n",
       "      <th>no_sent_split-align_cnt</th>\n",
       "      <th>suspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.587794</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.075059</td>\n",
       "      <td>399</td>\n",
       "      <td>397</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.725260</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.679778</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-29.893950</td>\n",
       "      <td>399</td>\n",
       "      <td>398</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-25.131610</td>\n",
       "      <td>398</td>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-24.583561</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-24.301205</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-22.202973</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-20.890602</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-19.599581</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-15.615388</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-15.391110</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-15.003563</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-14.784975</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-14.328669</td>\n",
       "      <td>399</td>\n",
       "      <td>396</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-13.105936</td>\n",
       "      <td>400</td>\n",
       "      <td>397</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-12.648712</td>\n",
       "      <td>400</td>\n",
       "      <td>397</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-12.384904</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-12.297777</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-12.156236</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-4.885314</td>\n",
       "      <td>399</td>\n",
       "      <td>396</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.907476</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.958231</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.789214</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.730143</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.456981</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.390370</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.348120</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.313007</td>\n",
       "      <td>400</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BLEU_DIFF  direct-align_cnt  no_sent_split-align_cnt  suspect\n",
       "0  -37.587794               399                      400     True\n",
       "1  -34.075059               399                      397     True\n",
       "2  -32.725260               399                      400     True\n",
       "3  -31.679778               399                      400     True\n",
       "4  -29.893950               399                      398     True\n",
       "5  -25.131610               398                      394     True\n",
       "6  -24.583561               399                      400     True\n",
       "7  -24.301205               372                      372     True\n",
       "8  -22.202973               399                      400     True\n",
       "9  -20.890602               399                      400     True\n",
       "10 -19.599581               399                      400     True\n",
       "11 -15.615388               399                      394     True\n",
       "12 -15.391110               399                      395     True\n",
       "13 -15.003563               399                      395     True\n",
       "14 -14.784975               399                      394     True\n",
       "15 -14.328669               399                      396     True\n",
       "16 -13.105936               400                      397     True\n",
       "17 -12.648712               400                      397     True\n",
       "18 -12.384904               399                      394     True\n",
       "19 -12.297777               399                      395     True\n",
       "20 -12.156236               399                      395     True\n",
       "21  -4.885314               399                      396     True\n",
       "22  -1.907476               399                      395     True\n",
       "23  -0.958231               400                      374    False\n",
       "24  -0.789214               400                      374    False\n",
       "25  -0.730143               400                      374    False\n",
       "26  -0.456981               400                      374    False\n",
       "27  -0.390370               400                      374    False\n",
       "28  -0.348120               400                      374    False\n",
       "29  -0.313007               400                      374    False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = merged.sort_values(by='BLEU_DIFF', ascending=True, ignore_index=True)\n",
    "sorted_df[['BLEU_DIFF', 'direct-align_cnt', 'no_sent_split-align_cnt', 'suspect']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4204a",
   "metadata": {},
   "source": [
    "* Biggest differences occur only for the ones that we marked, the ones that we suspect to have low BLEU scores due to misalignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d607e075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU_DIFF</th>\n",
       "      <th>direct-align_cnt</th>\n",
       "      <th>no_sent_split-align_cnt</th>\n",
       "      <th>dataset</th>\n",
       "      <th>translator</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.587794</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>opus</td>\n",
       "      <td>gpt</td>\n",
       "      <td>pt</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.075059</td>\n",
       "      <td>399</td>\n",
       "      <td>397</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.725260</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>it</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.679778</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-29.893950</td>\n",
       "      <td>399</td>\n",
       "      <td>398</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-25.131610</td>\n",
       "      <td>398</td>\n",
       "      <td>394</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-24.583561</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-24.301205</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>opus</td>\n",
       "      <td>gpt</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-22.202973</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-20.890602</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-19.599581</td>\n",
       "      <td>399</td>\n",
       "      <td>400</td>\n",
       "      <td>flores</td>\n",
       "      <td>gpt</td>\n",
       "      <td>es</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-15.615388</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>de</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-15.391110</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-15.003563</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>es</td>\n",
       "      <td>el</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-14.784975</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>fi</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-14.328669</td>\n",
       "      <td>399</td>\n",
       "      <td>396</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>el</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-13.105936</td>\n",
       "      <td>400</td>\n",
       "      <td>397</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>en</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-12.648712</td>\n",
       "      <td>400</td>\n",
       "      <td>397</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>pt</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-12.384904</td>\n",
       "      <td>399</td>\n",
       "      <td>394</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>sv</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-12.297777</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>es</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-12.156236</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>el</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-4.885314</td>\n",
       "      <td>399</td>\n",
       "      <td>396</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>da</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.907476</td>\n",
       "      <td>399</td>\n",
       "      <td>395</td>\n",
       "      <td>ep</td>\n",
       "      <td>gpt</td>\n",
       "      <td>it</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BLEU_DIFF  direct-align_cnt  no_sent_split-align_cnt dataset translator  \\\n",
       "0  -37.587794               399                      400    opus        gpt   \n",
       "1  -34.075059               399                      397      ep        gpt   \n",
       "2  -32.725260               399                      400  flores        gpt   \n",
       "3  -31.679778               399                      400  flores        gpt   \n",
       "4  -29.893950               399                      398  flores        gpt   \n",
       "5  -25.131610               398                      394      ep        gpt   \n",
       "6  -24.583561               399                      400  flores        gpt   \n",
       "7  -24.301205               372                      372    opus        gpt   \n",
       "8  -22.202973               399                      400  flores        gpt   \n",
       "9  -20.890602               399                      400  flores        gpt   \n",
       "10 -19.599581               399                      400  flores        gpt   \n",
       "11 -15.615388               399                      394      ep        gpt   \n",
       "12 -15.391110               399                      395      ep        gpt   \n",
       "13 -15.003563               399                      395      ep        gpt   \n",
       "14 -14.784975               399                      394      ep        gpt   \n",
       "15 -14.328669               399                      396      ep        gpt   \n",
       "16 -13.105936               400                      397      ep        gpt   \n",
       "17 -12.648712               400                      397      ep        gpt   \n",
       "18 -12.384904               399                      394      ep        gpt   \n",
       "19 -12.297777               399                      395      ep        gpt   \n",
       "20 -12.156236               399                      395      ep        gpt   \n",
       "21  -4.885314               399                      396      ep        gpt   \n",
       "22  -1.907476               399                      395      ep        gpt   \n",
       "\n",
       "   src_lang tgt_lang  \n",
       "0        pt       en  \n",
       "1        es       en  \n",
       "2        it       fr  \n",
       "3        fi       pt  \n",
       "4        fi       da  \n",
       "5        de       en  \n",
       "6        fi       nl  \n",
       "7        de       en  \n",
       "8        fi       es  \n",
       "9        fi       el  \n",
       "10       es       el  \n",
       "11       de       fi  \n",
       "12       fi       nl  \n",
       "13       es       el  \n",
       "14       fi       it  \n",
       "15       el       it  \n",
       "16       en       fi  \n",
       "17       pt       fi  \n",
       "18       sv       fi  \n",
       "19       es       nl  \n",
       "20       el       nl  \n",
       "21       da       it  \n",
       "22       it       fi  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sus = merged[merged['suspect'] == True]\n",
    "s = sus.sort_values(by='BLEU_DIFF', ascending=True, ignore_index=True)\n",
    "s[['BLEU_DIFF', 'direct-align_cnt', 'no_sent_split-align_cnt', 'dataset', 'translator', 'src_lang', 'tgt_lang']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766cbe9",
   "metadata": {},
   "source": [
    "* If we compare Alignment WITHOUT Sentence Splitting to direct alignment, resp. no additional alignment, we observe that differences occur mainly where we assumed to a have suspect anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9bfda",
   "metadata": {},
   "source": [
    "## Consider LaBSE\n",
    "* LaBSE alignments were computed in this notebook: [Alignments_No_Sent_Split_LaBSE.ipynb](https://colab.research.google.com/drive/1ieADAugVQ2nVq0Sqr9a299rsTjs9eMsB?usp=sharing)\n",
    "* LaBSE is computationally more expensive and a bit trickier to use even with Google Colab; has issues with memory occasionally, however, since we used paraphrase-multilingual-MiniLM-L12-v2 for everything, we can now just compare it against LaBSE for the sentences that we plan to align for sure and see if it makes a big difference or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02c0bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split_LaBSE')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1811206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-fi 396 394\n",
      "ep-gpt-el-nl 396 395\n",
      "ep-gpt-sv-fi 393 394\n",
      "flores-gpt-fi-da 400 398\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split_LaBSE = {}\n",
    "fn2discard_no_sent_split_LaBSE = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split_LaBSE = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split_LaBSE[fn] = align_cnt\n",
    "\n",
    "\n",
    "for k, v in fn2align_cnt_no_sent_split_LaBSE.items():\n",
    "    other = fn2align_cnt_no_sent_split[k]\n",
    "    if v!=other:\n",
    "        print(k, v, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058df593",
   "metadata": {},
   "source": [
    "* We observe only few disagreements in terms of alignment count between LaBSE and paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffe62001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>BLEU Paraphrase</th>\n",
       "      <th>BLEU LaBSE</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ep-gpt-da-it</td>\n",
       "      <td>24.794660</td>\n",
       "      <td>24.794660</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ep-gpt-de-en</td>\n",
       "      <td>32.615184</td>\n",
       "      <td>32.615184</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ep-gpt-de-fi</td>\n",
       "      <td>20.382731</td>\n",
       "      <td>20.356405</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ep-gpt-el-it</td>\n",
       "      <td>25.871847</td>\n",
       "      <td>25.871847</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ep-gpt-el-nl</td>\n",
       "      <td>25.018855</td>\n",
       "      <td>25.031535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ep-gpt-en-fi</td>\n",
       "      <td>18.983600</td>\n",
       "      <td>18.983600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ep-gpt-es-el</td>\n",
       "      <td>30.406654</td>\n",
       "      <td>30.406654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ep-gpt-es-en</td>\n",
       "      <td>36.493097</td>\n",
       "      <td>36.493097</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ep-gpt-es-nl</td>\n",
       "      <td>27.348489</td>\n",
       "      <td>27.348489</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ep-gpt-fi-it</td>\n",
       "      <td>22.024560</td>\n",
       "      <td>22.024560</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ep-gpt-fi-nl</td>\n",
       "      <td>22.120704</td>\n",
       "      <td>22.120704</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ep-gpt-it-fi</td>\n",
       "      <td>15.083129</td>\n",
       "      <td>15.083129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ep-gpt-pt-fi</td>\n",
       "      <td>18.495256</td>\n",
       "      <td>18.495256</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ep-gpt-sv-fi</td>\n",
       "      <td>19.018249</td>\n",
       "      <td>18.983193</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flores-gpt-es-el</td>\n",
       "      <td>19.829690</td>\n",
       "      <td>19.829690</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flores-gpt-fi-da</td>\n",
       "      <td>30.188757</td>\n",
       "      <td>30.123895</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flores-gpt-fi-el</td>\n",
       "      <td>21.109056</td>\n",
       "      <td>21.109056</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>flores-gpt-fi-es</td>\n",
       "      <td>22.856539</td>\n",
       "      <td>22.857882</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flores-gpt-fi-nl</td>\n",
       "      <td>25.185672</td>\n",
       "      <td>25.185672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flores-gpt-fi-pt</td>\n",
       "      <td>32.266250</td>\n",
       "      <td>32.265111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>flores-gpt-it-fr</td>\n",
       "      <td>33.347416</td>\n",
       "      <td>33.347416</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>opus-gpt-de-en</td>\n",
       "      <td>34.955918</td>\n",
       "      <td>34.955918</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>opus-gpt-pt-en</td>\n",
       "      <td>37.694071</td>\n",
       "      <td>37.694071</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label  BLEU Paraphrase  BLEU LaBSE  Difference\n",
       "0       ep-gpt-da-it        24.794660   24.794660       False\n",
       "1       ep-gpt-de-en        32.615184   32.615184       False\n",
       "2       ep-gpt-de-fi        20.382731   20.356405        True\n",
       "3       ep-gpt-el-it        25.871847   25.871847       False\n",
       "4       ep-gpt-el-nl        25.018855   25.031535        True\n",
       "5       ep-gpt-en-fi        18.983600   18.983600       False\n",
       "6       ep-gpt-es-el        30.406654   30.406654       False\n",
       "7       ep-gpt-es-en        36.493097   36.493097       False\n",
       "8       ep-gpt-es-nl        27.348489   27.348489       False\n",
       "9       ep-gpt-fi-it        22.024560   22.024560       False\n",
       "10      ep-gpt-fi-nl        22.120704   22.120704       False\n",
       "11      ep-gpt-it-fi        15.083129   15.083129       False\n",
       "12      ep-gpt-pt-fi        18.495256   18.495256       False\n",
       "13      ep-gpt-sv-fi        19.018249   18.983193        True\n",
       "14  flores-gpt-es-el        19.829690   19.829690       False\n",
       "15  flores-gpt-fi-da        30.188757   30.123895        True\n",
       "16  flores-gpt-fi-el        21.109056   21.109056       False\n",
       "17  flores-gpt-fi-es        22.856539   22.857882        True\n",
       "18  flores-gpt-fi-nl        25.185672   25.185672       False\n",
       "19  flores-gpt-fi-pt        32.266250   32.265111        True\n",
       "20  flores-gpt-it-fr        33.347416   33.347416       False\n",
       "21    opus-gpt-de-en        34.955918   34.955918       False\n",
       "22    opus-gpt-pt-en        37.694071   37.694071       False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import load_aligned_sents_from_file\n",
    "from scripts.scoring import compute_bleu\n",
    "from scripts.util import get_env_variables\n",
    "import pandas as pd\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "paraphrase = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "laBSE = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "data = {'Label': [], 'BLEU Paraphrase': [], 'BLEU LaBSE': [], 'Difference': []}\n",
    "for fn in sorted(suspects):\n",
    "    ref_sents_p, mt_sents_p = load_aligned_sents_from_file(\n",
    "        fn, folder=paraphrase, src_label='ref', tgt_label='mt')\n",
    "    ref_sents_l, mt_sents_l = load_aligned_sents_from_file(fn, folder=laBSE,\n",
    "                                                           src_label='ref', tgt_label='mt')\n",
    "    bleu_p = compute_bleu(ref_sents_p, mt_sents_p)\n",
    "    bleu_l = compute_bleu(ref_sents_l, mt_sents_l)\n",
    "    diff = (not bleu_l==bleu_p)\n",
    "    data['Label'].append(fn)\n",
    "    data['BLEU Paraphrase'].append(bleu_p)\n",
    "    data['BLEU LaBSE'].append(bleu_l)\n",
    "    data['Difference'].append(diff)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "#print(df.to_latex(index=False, float_format=\"%.3f\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a8df72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['Difference']==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae03dd7",
   "metadata": {},
   "source": [
    "* 6 out of 23 alignments yielded slightly different BLEU scores.\n",
    "* 4 out of 6 alignments were likely different because LaBSE aligned differently\n",
    "* **OVERALL CONCLUSION**: Using paraphrase-multilingual-MiniLM-L12-v2 for alignment instead of LaBSE should not be an issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c37cc",
   "metadata": {},
   "source": [
    "## Final Triplets\n",
    "* After doing these various alignment experiments, we can finally create our final triplets that we use for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb1aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "suspects = {}\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        suspects[prefix] = outlines\n",
    "len(suspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e70380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "from scripts.post_process import direct_triplet_align, load_sents_from_file, post_triplet_align, load_aligned_sents_from_file\n",
    "\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "dst_path = join(triplet_folder, 'final_triplets')\n",
    "\n",
    "# Direct Triplets\n",
    "fn2align_cnt = {}\n",
    "parts = {\n",
    "    'opus': {'dm': Opus100Manager(), 'pairs': Opus100Manager.get_pairs()},\n",
    "    'ep': {'dm': EuroParlManager(), 'pairs': EuroParlManager.get_pairs()},\n",
    "    'flores': {'dm': FloresPlusManager(), 'pairs': FloresPlusManager.get_pairs()}\n",
    "}\n",
    "translators = ['gpt', 'deepl']\n",
    "for dataset, content in parts.items():\n",
    "    dm = content['dm']\n",
    "    pairs = content['pairs']\n",
    "    for pair in pairs:\n",
    "        s, t = pair\n",
    "        for translator in translators:\n",
    "            filename = f'{dataset}-{translator}-{s}-{t}'\n",
    "            if filename in suspects:\n",
    "                continue\n",
    "            mt_sents = load_sents_from_file(folder='translations', filename=filename)\n",
    "            src_sents, tgt_sents = dm.get_sentence_pairs(\n",
    "                s, t, num_of_sents=400)\n",
    "            cnt = direct_triplet_align(\n",
    "                mt_sents=mt_sents,\n",
    "                src_sents=src_sents,\n",
    "                ref_sents=tgt_sents,\n",
    "                folder_path=dst_path,\n",
    "                filename=filename\n",
    "            )\n",
    "            fn2align_cnt[filename] = cnt\n",
    "\n",
    "# Aligned Triplets for Suspects\n",
    "src2hyp_no_split_fo = join(aligned_folder, 'source2translations_no_sent_split')\n",
    "for fn in suspects:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    dm = parts[dataset]['dm']\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_no_split_fo)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "    fn2align_cnt[fn] = align_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bc6fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1\n",
      "394 4\n",
      "395 5\n",
      "396 2\n",
      "397 3\n",
      "398 1\n",
      "399 1\n",
      "400 463\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(fn2align_cnt.values())\n",
    "for k, v in sorted(counts.items()):\n",
    "    print(k, v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
