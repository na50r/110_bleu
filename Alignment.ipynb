{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e994de5b",
   "metadata": {},
   "source": [
    "## Direct Triplets\n",
    "* No alignment is performed on the text, we just place source, reference and translation side by side based on their order (line by line) in the dataset and translation output.\n",
    "* I.e., assume that translators preserved the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "dst_path = join(triplet_folder, 'direct_triplets')\n",
    "parts = {\n",
    "    'opus': {'dm': Opus100Manager(), 'pairs': Opus100Manager.get_pairs()},\n",
    "    'ep': {'dm': EuroParlManager(), 'pairs': EuroParlManager.get_pairs()},\n",
    "    'flores': {'dm': FloresPlusManager(), 'pairs': FloresPlusManager.get_pairs()}\n",
    "}\n",
    "translators = ['gpt', 'deepl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b466a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align, load_sents_from_file\n",
    "fn2align_cnt_direct = {}\n",
    "for dataset, content in parts.items():\n",
    "    dm = content['dm']\n",
    "    pairs = content['pairs']\n",
    "    for pair in pairs:\n",
    "        s, t = pair\n",
    "        for translator in translators:\n",
    "            filename = f'{dataset}-{translator}-{s}-{t}'\n",
    "            mt_sents = load_sents_from_file(\n",
    "                folder='translations', filename=filename)\n",
    "            src_sents, tgt_sents = dm.get_sentence_pairs(\n",
    "                s, t, num_of_sents=400)\n",
    "            cnt = direct_triplet_align(\n",
    "                mt_sents=mt_sents,\n",
    "                src_sents=src_sents,\n",
    "                ref_sents=tgt_sents,\n",
    "                folder_path=dst_path,\n",
    "                filename=filename\n",
    "            )\n",
    "            fn2align_cnt_direct[filename] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2104efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1\n",
      "398 1\n",
      "399 20\n",
      "400 458\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_direct.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('direct_cnt.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_direct, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672225e",
   "metadata": {},
   "source": [
    "* Direct alignment only removes empty strings if there are any\n",
    "* Most of the time, we have 400 aligned triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae565ce",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITHOUT Sentence Splitting\n",
    "* Alignments were computed in this notebook: [Alignments_No_Sent_Split.ipynb](https://colab.research.google.com/drive/1867NBRM7ixgiVmeznqRf4oh9nYDd4D5S?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1535bc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5758495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 383\n",
      "max: 398\n",
      "mean: 396.31\n",
      "\n",
      "ep-deepl\n",
      "min: 369\n",
      "max: 398\n",
      "mean: 395.77\n",
      "\n",
      "flores-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 396.65\n",
      "\n",
      "flores-deepl\n",
      "min: 374\n",
      "max: 400\n",
      "mean: 396.61\n",
      "\n",
      "opus-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 397.85\n",
      "\n",
      "opus-deepl\n",
      "min: 395\n",
      "max: 400\n",
      "mean: 398.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split = {}\n",
    "fn2discard_no_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split[fn] = align_cnt\n",
    "    fn2discard_no_sent_split[fn] = dis\n",
    "    case2align_cnts_no_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_no_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 1\n",
      "372 2\n",
      "374 19\n",
      "383 2\n",
      "384 1\n",
      "391 1\n",
      "392 2\n",
      "393 8\n",
      "394 13\n",
      "395 38\n",
      "396 36\n",
      "397 144\n",
      "398 47\n",
      "399 32\n",
      "400 134\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_no_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c26dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_no_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_no_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d2e82",
   "metadata": {},
   "source": [
    "### Investigating Loss of Text\n",
    "* If we apply `bertalign` WITHOUT sentence splitting to all translations, we lose text in some cases.\n",
    "* The 'biggest' loss is 391-369=22 sentences for `ep-deepl-sv-de`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67e06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "!cat translations/ep-deepl-sv-de.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3076ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "!cat $src2hyp_split_fo/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28da166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "!cat $dst_path/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bcb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vi skall r칬sta om beg칛ran fr친n PPE-DE-gruppen som syftar till att stryka den muntliga fr친gan om kapitalskatt fr친n f칬redragningslistan.',\n",
       " '(Parlamentet avslog beg칛ran med 164 r칬ster f칬r, 166 emot. 7 ledam칬ter avstod fr친n att r칬sta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering f칬r att han just gjort reklam f칬r denna debatt.',\n",
       " 'Tack.',\n",
       " 'Fru talman!',\n",
       " 'Jag undrar om 칛ven min r칬st har r칛knats, trots att den inte kunde avges p친 elektronisk v칛g, eftersom jag inte har n친got kort?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.post_process import load_aligned_sents_from_file, load_sents_from_file\n",
    "mt_sents = load_sents_from_file('ep-deepl-sv-de', 'translations')\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('sv', 'de', num_of_sents=400)\n",
    "src_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44083fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir stimmen jetzt 칲ber den Antrag der PPE/DE-Fraktion ab, die m칲ndliche Anfrage 칲ber die Kapitalsteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 Ja-Stimmen, 166 Nein-Stimmen und 7 Enthaltungen ab.)',\n",
       " 'Frau Pr칛sidentin, ich m칬chte Herrn Poettering f칲r das R칲hren der Werbetrommel zugunsten dieser Aussprache danken.',\n",
       " 'Vielen Dank.',\n",
       " 'Frau Pr칛sidentin!',\n",
       " 'Ist meine Stimme mitgez칛hlt worden? Ich konnte sie n칛mlich nicht elektronisch abgeben, weil ich die Karte nicht habe.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e40454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir werden 칲ber den Antrag der Fraktion der Europ칛ischen Volkspartei (Christdemokraten) und europ칛ischer Demokraten abstimmen, die m칲ndliche Anfrage zur Gesellschaftssteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Pr칛sidentin, ich m칬chte Herrn Poettering daf칲r danken, dass er diese Aussprache soeben angek칲ndigt hat.',\n",
       " 'Vielen Dank, Herr P칬ttering.',\n",
       " 'Frau Pr칛sidentin, ich m칬chte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gez칛hlt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00934af",
   "metadata": {},
   "source": [
    "* The direct alignment for this specific instance is correct, however, we already observe a slight difference between reference and translation\n",
    "* `Vielen Dank` vs `Vielen Dank, Herr P칬ttering.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8c18a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Parlamentet avslog beg칛ran med 164 r칬ster f칬r, 166 emot. 7 ledam칬ter avstod fr친n att r칬sta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering f칬r att han just gjort reklam f칬r denna debatt.',\n",
       " '',\n",
       " 'Tack. Fru talman!',\n",
       " 'Jag undrar om 칛ven min r칬st har r칛knats, trots att den inte kunde avges p친 elektronisk v칛g, eftersom jag inte har n친got kort?',\n",
       " 'Jag r칬stade \"f칬r\".',\n",
       " 'Om man l칛gger till de tv친 kolleger som yttrat sig blir resultatet...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sents_ali, mt_sents_ali = load_aligned_sents_from_file('ep-deepl-sv-de', src2hyp_split_fo)\n",
    "src_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7d20d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Pr칛sidentin, ich m칬chte Herrn Poettering daf칲r danken, dass er diese Aussprache soeben angek칲ndigt hat.',\n",
       " 'Vielen Dank, Herr P칬ttering.',\n",
       " 'Frau Pr칛sidentin, ich m칬chte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gez칛hlt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?',\n",
       " 'Ich habe mit \"Ja\" gestimmt.',\n",
       " 'Wenn Sie die beiden Kollegen, die sich zu Wort gemeldet haben, hinzuz칛hlen, lautet das Ergebnis...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4731f0",
   "metadata": {},
   "source": [
    "* Alignment with `bertalign` works but is dependent on the translation. It merged the source sentences together to get a 2-1 alignment with:\n",
    "```\n",
    "'Tack. Fru talman!' <->  'Vielen Dank, Herr P칬ttering.',\n",
    "```\n",
    "* As a consequence, we see an empty string in the aligned source sentences\n",
    "* Furthermore, since the original source sentences do not contain the string `'Tack. Fru talman!'`, it will be discarded, as triplet alignments are created by matching the sentences from the original source strings to the aligned source strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c1cd",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITH Sentences Splitting\n",
    "* The alignments were computed in this notebook: [Alignments.ipynb](https://colab.research.google.com/drive/1xlwQPctsOGjZB2NpB9WNtzWPae_Oj4gt?usp=sharing)\n",
    "* Note: To make alignments with sentence splitting, we had to align source to reference AND source to translation, whereas before only source to translation was enough, as we could use the alignments provided by the respective datasets directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97698926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "# Aligned source to translation\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_sent_split')\n",
    "# Aligned source to reference\n",
    "src2ref_split_fo = join(aligned_folder, 'source2reference_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1cc932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 329\n",
      "max: 396\n",
      "mean: 374.74\n",
      "\n",
      "ep-deepl\n",
      "min: 328\n",
      "max: 395\n",
      "mean: 377.38\n",
      "\n",
      "flores-gpt\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.58\n",
      "\n",
      "flores-deepl\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.23\n",
      "\n",
      "opus-gpt\n",
      "min: 361\n",
      "max: 399\n",
      "mean: 382.95\n",
      "\n",
      "opus-deepl\n",
      "min: 361\n",
      "max: 398\n",
      "mean: 383.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn2align_cnt_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    src_sents_o, ref_sents_o = load_aligned_sents_from_file(\n",
    "        f'{dataset}-{s}-{t}', folder=src2ref_split_fo)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_sent_split[fn] = align_cnt\n",
    "    case2align_cnts_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a34f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 1\n",
      "329 1\n",
      "333 2\n",
      "334 1\n",
      "335 1\n",
      "336 1\n",
      "338 3\n",
      "339 5\n",
      "342 2\n",
      "343 2\n",
      "344 2\n",
      "345 1\n",
      "347 1\n",
      "348 2\n",
      "349 1\n",
      "351 2\n",
      "356 1\n",
      "357 1\n",
      "360 2\n",
      "361 4\n",
      "362 2\n",
      "363 1\n",
      "364 2\n",
      "365 1\n",
      "366 6\n",
      "367 2\n",
      "368 3\n",
      "369 4\n",
      "370 3\n",
      "371 1\n",
      "372 5\n",
      "373 2\n",
      "374 5\n",
      "375 5\n",
      "376 4\n",
      "377 11\n",
      "378 14\n",
      "379 7\n",
      "380 7\n",
      "381 7\n",
      "382 7\n",
      "383 12\n",
      "384 13\n",
      "385 4\n",
      "386 18\n",
      "387 8\n",
      "388 12\n",
      "389 11\n",
      "390 16\n",
      "391 13\n",
      "392 6\n",
      "393 4\n",
      "394 7\n",
      "395 3\n",
      "396 3\n",
      "397 3\n",
      "398 4\n",
      "399 2\n",
      "400 2\n",
      "401 1\n",
      "403 4\n",
      "404 1\n",
      "405 3\n",
      "406 4\n",
      "407 1\n",
      "408 2\n",
      "409 2\n",
      "410 1\n",
      "411 6\n",
      "412 7\n",
      "413 8\n",
      "414 4\n",
      "415 5\n",
      "416 3\n",
      "417 6\n",
      "418 10\n",
      "419 13\n",
      "420 14\n",
      "421 20\n",
      "422 13\n",
      "423 30\n",
      "424 20\n",
      "425 10\n",
      "426 8\n",
      "427 5\n",
      "428 3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0224cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aae253",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "* For all three triplet formations, no alignment, alignment without sentence splitting and alignment with sentence splitting, we compute BLUE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f3e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "results_folder = get_env_variables('RESULTS')\n",
    "\n",
    "result_types = {'direct_results':join(triplet_folder, 'direct_triplets'), \n",
    "                'aligned_results_no_sent_split': join(triplet_folder, 'aligned_triplets_no_sent_split'),\n",
    "                'aligned_results_sent_split': join(triplet_folder, 'aligned_triplets_sent_split')}\n",
    "\n",
    "for rt in result_types:\n",
    "    files = os.listdir(result_types[rt])\n",
    "    folder_path = join(results_folder, rt)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "             'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "    for case in cases:\n",
    "        l2f = {f.replace(f'{case}-', '').replace('.jsonl', '')\n",
    "                         : join(result_types[rt], f) for f in files if f.startswith(case)}\n",
    "        rp = ResultProducer(label2files=l2f)\n",
    "        rp.compute_results()\n",
    "        rp.store_results(join(folder_path, f'{case}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc454065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.presentation import Presenter\n",
    "p_direct = Presenter(results_folder=join(results_folder, 'direct_results'))\n",
    "p_no_sent_split = Presenter(results_folder=join(results_folder, 'aligned_results_no_sent_split'))\n",
    "p_sent_split = Presenter(results_folder=join(results_folder, 'aligned_results_sent_split'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e19b2",
   "metadata": {},
   "source": [
    "## Difference between Alignment WITH and WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2681f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload cnts \n",
    "import json\n",
    "with open('aligned_cnt_no_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_no_sent_split = json.load(f)\n",
    "\n",
    "with open('aligned_cnt_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_sent_split = json.load(f)\n",
    "\n",
    "with open('direct_cnt.json', 'r') as f:\n",
    "    fn2align_cnt_direct = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abd9abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "da-es: 0.9 (395->383)\n",
      "fr-fi: 0.4 (397->390)\n",
      "fi-es: 0.3 (395->388)\n",
      "fr-it: 0.3 (397->372)\n",
      "es-da: 0.2 (396->390)\n",
      "fr-el: 0.2 (396->381)\n",
      "fr-de: 0.1 (397->391)\n",
      "sv-fi: 0.1 (393->376)\n",
      "es-fr: 0.1 (396->389)\n",
      "fr-da: 0.1 (397->389)\n",
      "pt-es: 0.1 (397->386)\n",
      "da-el: 0.1 (395->385)\n",
      "en-it: 0.1 (397->366)\n",
      "fr-es: 0.1 (397->387)\n",
      "pt-de: 0.1 (397->384)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "nl-fi: -2.5 (397->345)\n",
      "nl-da: -2.5 (397->343)\n",
      "nl-sv: -2.2 (395->333)\n",
      "nl-en: -2.2 (397->339)\n",
      "nl-pt: -2.1 (396->336)\n",
      "nl-es: -2.0 (397->338)\n",
      "nl-fr: -2.0 (397->339)\n",
      "nl-de: -1.9 (397->342)\n",
      "nl-it: -1.5 (397->328)\n",
      "nl-el: -1.3 (397->339)\n",
      "it-pt: -0.9 (398->370)\n",
      "it-fr: -0.9 (398->378)\n",
      "it-de: -0.8 (398->378)\n",
      "it-es: -0.7 (398->380)\n",
      "it-en: -0.7 (398->378)\n",
      "\n",
      "ep-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "sv-fr: 0.5 (395->351)\n",
      "fr-fi: 0.4 (397->390)\n",
      "fi-en: 0.3 (397->383)\n",
      "en-it: 0.3 (397->366)\n",
      "fi-pt: 0.3 (397->384)\n",
      "da-el: 0.2 (397->387)\n",
      "fr-el: 0.2 (397->382)\n",
      "fi-el: 0.2 (397->384)\n",
      "sv-pt: 0.2 (395->348)\n",
      "da-es: 0.2 (397->386)\n",
      "de-pt: 0.2 (397->360)\n",
      "fi-fr: 0.2 (397->387)\n",
      "fr-de: 0.1 (397->391)\n",
      "fr-it: 0.1 (397->372)\n",
      "pt-es: 0.1 (397->386)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "nl-es: -2.4 (397->338)\n",
      "nl-sv: -2.4 (395->333)\n",
      "nl-da: -2.4 (397->343)\n",
      "nl-en: -2.2 (397->339)\n",
      "nl-fr: -1.9 (397->338)\n",
      "nl-it: -1.6 (397->329)\n",
      "nl-fi: -1.6 (397->344)\n",
      "nl-pt: -1.5 (396->335)\n",
      "nl-el: -1.4 (397->339)\n",
      "nl-de: -1.3 (397->342)\n",
      "en-sv: -0.7 (397->378)\n",
      "de-it: -0.7 (397->347)\n",
      "it-es: -0.7 (398->380)\n",
      "it-pt: -0.7 (398->370)\n",
      "it-fr: -0.6 (398->378)\n",
      "\n",
      "flores-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "fr-sv: 0.9 (374->423)\n",
      "fr-en: 0.7 (374->423)\n",
      "sv-fi: 0.4 (397->423)\n",
      "fr-da: 0.2 (374->423)\n",
      "da-fi: 0.2 (394->428)\n",
      "da-sv: 0.2 (394->418)\n",
      "it-de: 0.2 (400->425)\n",
      "nl-de: 0.2 (400->403)\n",
      "sv-de: 0.2 (397->423)\n",
      "da-en: 0.2 (396->420)\n",
      "en-fi: 0.2 (400->427)\n",
      "sv-da: 0.2 (397->423)\n",
      "da-de: 0.2 (396->426)\n",
      "sv-en: 0.1 (397->424)\n",
      "it-sv: 0.1 (400->425)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "fi-en: -0.7 (400->406)\n",
      "de-fr: -0.6 (399->412)\n",
      "fi-pt: -0.5 (400->403)\n",
      "de-en: -0.5 (399->411)\n",
      "da-fr: -0.4 (396->420)\n",
      "nl-fi: -0.4 (399->406)\n",
      "nl-pt: -0.4 (400->397)\n",
      "de-sv: -0.4 (399->412)\n",
      "de-fi: -0.4 (399->421)\n",
      "fi-el: -0.3 (398->398)\n",
      "fi-nl: -0.3 (400->410)\n",
      "de-it: -0.3 (399->411)\n",
      "es-nl: -0.3 (400->412)\n",
      "fi-fr: -0.2 (400->406)\n",
      "da-es: -0.2 (396->417)\n",
      "\n",
      "flores-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "fr-en: 0.6 (374->423)\n",
      "fr-sv: 0.3 (374->423)\n",
      "sv-fi: 0.3 (397->424)\n",
      "sv-de: 0.3 (397->425)\n",
      "nl-de: 0.3 (400->403)\n",
      "fr-nl: 0.3 (374->419)\n",
      "sv-da: 0.3 (397->426)\n",
      "nl-sv: 0.2 (400->393)\n",
      "sv-en: 0.2 (397->425)\n",
      "nl-da: 0.2 (400->401)\n",
      "da-de: 0.2 (396->428)\n",
      "fr-pt: 0.2 (374->421)\n",
      "nl-it: 0.2 (400->400)\n",
      "de-pt: 0.2 (399->415)\n",
      "it-de: 0.2 (400->424)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "de-fr: -0.6 (399->412)\n",
      "fi-en: -0.6 (400->408)\n",
      "fr-el: -0.5 (374->418)\n",
      "nl-fi: -0.5 (400->409)\n",
      "fi-pt: -0.4 (400->408)\n",
      "de-fi: -0.4 (399->421)\n",
      "fi-fr: -0.3 (398->409)\n",
      "it-en: -0.3 (400->423)\n",
      "da-fr: -0.3 (396->420)\n",
      "de-el: -0.3 (399->413)\n",
      "nl-pt: -0.3 (400->398)\n",
      "de-es: -0.3 (399->413)\n",
      "de-sv: -0.3 (399->411)\n",
      "nl-en: -0.3 (400->394)\n",
      "fi-da: -0.3 (398->414)\n",
      "\n",
      "opus-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "it-en: -0.2 (400->395)\n",
      "fr-en: -0.8 (400->397)\n",
      "en-fr: -0.9 (399->390)\n",
      "en-de: -0.9 (400->398)\n",
      "de-en: -1.1 (400->394)\n",
      "da-en: -1.2 (399->383)\n",
      "nl-en: -1.2 (400->388)\n",
      "pt-en: -1.3 (399->389)\n",
      "en-fi: -1.3 (395->361)\n",
      "el-en: -1.4 (395->378)\n",
      "en-it: -1.5 (400->383)\n",
      "en-pt: -1.5 (399->382)\n",
      "en-es: -1.6 (400->394)\n",
      "es-en: -1.7 (400->393)\n",
      "en-el: -1.7 (396->372)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "en-sv: -3.4 (400->362)\n",
      "fi-en: -2.4 (395->374)\n",
      "sv-en: -2.2 (398->381)\n",
      "en-da: -1.7 (399->382)\n",
      "en-nl: -1.7 (400->381)\n",
      "en-el: -1.7 (396->372)\n",
      "es-en: -1.7 (400->393)\n",
      "en-es: -1.6 (400->394)\n",
      "en-pt: -1.5 (399->382)\n",
      "en-it: -1.5 (400->383)\n",
      "el-en: -1.4 (395->378)\n",
      "en-fi: -1.3 (395->361)\n",
      "pt-en: -1.3 (399->389)\n",
      "nl-en: -1.2 (400->388)\n",
      "da-en: -1.2 (399->383)\n",
      "\n",
      "opus-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "it-en: -0.2 (400->395)\n",
      "en-de: -0.6 (400->399)\n",
      "fr-en: -0.8 (400->397)\n",
      "en-fi: -0.8 (397->361)\n",
      "nl-en: -0.8 (400->388)\n",
      "en-fr: -0.9 (399->390)\n",
      "en-it: -1.2 (400->383)\n",
      "pt-en: -1.2 (400->390)\n",
      "en-es: -1.2 (400->393)\n",
      "es-en: -1.4 (400->394)\n",
      "el-en: -1.5 (397->380)\n",
      "en-da: -1.5 (399->384)\n",
      "en-pt: -1.5 (399->380)\n",
      "en-el: -1.6 (395->373)\n",
      "da-en: -1.6 (399->384)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: 풊BLEU (no sent split cnt-> sent split cnt)\n",
      "fi-en: -2.4 (400->377)\n",
      "en-sv: -2.4 (400->364)\n",
      "sv-en: -1.9 (400->380)\n",
      "en-nl: -1.8 (400->379)\n",
      "de-en: -1.6 (372->368)\n",
      "da-en: -1.6 (399->384)\n",
      "en-el: -1.6 (395->373)\n",
      "en-pt: -1.5 (399->380)\n",
      "en-da: -1.5 (399->384)\n",
      "el-en: -1.5 (397->380)\n",
      "es-en: -1.4 (400->394)\n",
      "en-es: -1.2 (400->393)\n",
      "pt-en: -1.2 (400->390)\n",
      "en-it: -1.2 (400->383)\n",
      "en-fr: -0.9 (399->390)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in p_no_sent_split.cases:\n",
    "    df1 = p_no_sent_split.cases[x]['BLEU']\n",
    "    df2 = p_sent_split.cases[x]['BLEU']\n",
    "    diff = df1 - df2\n",
    "    print(x)\n",
    "    diff_mean = diff.values.mean()\n",
    "\n",
    "    diff_flat = diff.stack()\n",
    "    top3_max = diff_flat.nlargest(15)\n",
    "    print('Largest Positive Differences (Sent Splits made things worse)')\n",
    "    print('Label: 풊BLEU (no sent split cnt-> sent split cnt)')\n",
    "    for (s, t), score in top3_max.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        sent_split = fn2align_cnt_sent_split[fn]\n",
    "        print(f'{s}-{t}: {score:.1f} ({no_sent_split}->{sent_split})')\n",
    "\n",
    "    top3_min = diff_flat.nsmallest(15)\n",
    "    print('Largest Negative Differences (Sent Splits made things better)')\n",
    "    print('Label: 풊BLEU (no sent split cnt-> sent split cnt)')\n",
    "    for (s, t), score in top3_min.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        sent_split = fn2align_cnt_sent_split[fn]\n",
    "        print(f'{s}-{t}: {score:.1f} ({no_sent_split}->{sent_split})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f61ba7",
   "metadata": {},
   "source": [
    "* In this case, Negative Differences refer to the case where Alignment WITH Sentence Splitting yielded higher BLEU scores than WITHOUT\n",
    "* However, we can see based on alignment counts, that it may be not related to alignment but due to the fact that it works with less sentences overall.\n",
    "* Additionally, the highest difference we observe is -3.4, not too tragic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845680a9",
   "metadata": {},
   "source": [
    "## Difference between Direct and Alignment WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95b54533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "mismatches = {}\n",
    "\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "    \n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        mismatches[prefix] = outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9358a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "da-fi: 0.2 (400->395) \n",
      "sv-es: 0.2 (400->393) \n",
      "nl-sv: 0.1 (400->395) \n",
      "sv-fr: 0.1 (400->393) \n",
      "da-de: 0.1 (400->395) \n",
      "fr-fi: 0.1 (400->397) \n",
      "pt-fi: 0.1 (400->397) \n",
      "fr-pt: 0.1 (400->397) \n",
      "da-en: 0.1 (400->395) \n",
      "de-fr: 0.1 (400->397) \n",
      "el-sv: 0.1 (400->394) \n",
      "de-da: 0.1 (400->397) \n",
      "en-fr: 0.1 (400->397) \n",
      "nl-pt: 0.1 (400->396) \n",
      "pt-da: 0.1 (400->395) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "da-el: -0.1 (400->395) \n",
      "sv-de: -0.0 (400->369) \n",
      "el-en: 0.0 (400->397) \n",
      "el-it: 0.0 (400->398) \n",
      "it-el: 0.0 (400->398) \n",
      "fi-el: 0.0 (400->397) \n",
      "es-en: 0.0 (400->396) \n",
      "de-el: 0.0 (400->397) \n",
      "\n",
      "ep-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "fr-nl: 0.1 (400->395) \n",
      "sv-de: 0.1 (400->383) \n",
      "de-sv: 0.1 (400->384) \n",
      "nl-pt: 0.1 (400->396) \n",
      "it-de: 0.1 (400->398) \n",
      "el-de: 0.1 (400->397) \n",
      "nl-fi: 0.1 (400->397) \n",
      "pt-nl: 0.1 (400->397) \n",
      "en-de: 0.1 (400->397) \n",
      "it-nl: 0.1 (400->398) \n",
      "fi-de: 0.1 (400->396) \n",
      "es-fi: 0.1 (400->395) \n",
      "da-de: 0.1 (400->397) \n",
      "nl-fr: 0.1 (400->397) \n",
      "en-nl: 0.1 (400->397) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "es-en: -34.1 (399->397) 游꿢\n",
      "de-en: -25.1 (398->394) 游꿢\n",
      "de-fi: -15.6 (399->394) 游꿢\n",
      "fi-nl: -15.4 (399->395) 游꿢\n",
      "es-el: -15.0 (399->395) 游꿢\n",
      "fi-it: -14.8 (399->394) 游꿢\n",
      "el-it: -14.3 (399->396) 游꿢\n",
      "en-fi: -13.1 (400->397) 游꿢\n",
      "pt-fi: -12.6 (400->397) 游꿢\n",
      "sv-fi: -12.4 (399->394) 游꿢\n",
      "es-nl: -12.3 (399->395) 游꿢\n",
      "el-nl: -12.2 (399->395) 游꿢\n",
      "da-it: -4.9 (399->396) 游꿢\n",
      "it-fi: -1.9 (399->395) 游꿢\n",
      "sv-en: -0.0 (400->395) \n",
      "\n",
      "flores-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "da-fr: 0.1 (400->396) \n",
      "sv-pt: 0.1 (400->397) \n",
      "da-de: 0.1 (400->396) \n",
      "fi-el: 0.1 (400->398) \n",
      "da-nl: 0.1 (400->396) \n",
      "da-es: 0.0 (400->396) \n",
      "sv-fr: 0.0 (400->397) \n",
      "fr-it: 0.0 (400->374) \n",
      "de-es: 0.0 (400->399) \n",
      "es-de: 0.0 (400->398) \n",
      "nl-fi: 0.0 (400->399) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "fr-sv: -1.0 (400->374) \n",
      "fr-en: -0.8 (400->374) \n",
      "fr-da: -0.5 (400->374) \n",
      "fr-nl: -0.3 (400->374) \n",
      "pt-en: -0.3 (400->398) \n",
      "fr-pt: -0.3 (400->374) \n",
      "pt-da: -0.2 (400->398) \n",
      "sv-fi: -0.2 (400->397) \n",
      "pt-fr: -0.2 (400->398) \n",
      "da-fi: -0.2 (400->394) \n",
      "fr-es: -0.2 (400->374) \n",
      "fr-fi: -0.2 (400->374) \n",
      "pt-nl: -0.2 (400->398) \n",
      "sv-nl: -0.2 (400->397) \n",
      "sv-de: -0.1 (400->397) \n",
      "\n",
      "flores-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "fr-el: 0.3 (400->374) \n",
      "da-fr: 0.1 (400->396) \n",
      "fr-fi: 0.1 (400->372) \n",
      "de-fr: 0.1 (400->399) \n",
      "sv-pt: 0.1 (400->397) \n",
      "de-en: 0.0 (400->399) \n",
      "da-pt: 0.0 (400->396) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "it-fr: -32.7 (399->400) 游꿢\n",
      "fi-pt: -31.7 (399->400) 游꿢\n",
      "fi-da: -29.9 (399->398) 游꿢\n",
      "fi-nl: -24.6 (399->400) 游꿢\n",
      "fi-es: -22.2 (399->400) 游꿢\n",
      "fi-el: -20.9 (399->400) 游꿢\n",
      "es-el: -19.6 (399->400) 游꿢\n",
      "fr-en: -0.7 (400->374) \n",
      "fr-sv: -0.4 (400->374) \n",
      "fr-pt: -0.3 (400->374) \n",
      "fr-de: -0.3 (400->374) \n",
      "fr-da: -0.3 (400->374) \n",
      "fr-nl: -0.3 (400->374) \n",
      "pt-fr: -0.2 (400->398) \n",
      "sv-fi: -0.2 (400->397) \n",
      "\n",
      "opus-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "en-da: -0.0 (400->399) \n",
      "sv-en: -0.0 (400->398) \n",
      "en-pt: -0.0 (400->399) \n",
      "pt-en: -0.0 (400->399) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "el-en: -0.2 (400->395) \n",
      "fi-en: -0.2 (400->395) \n",
      "en-fi: -0.1 (400->395) \n",
      "en-fr: -0.1 (400->399) \n",
      "da-en: -0.1 (400->399) \n",
      "pt-en: -0.0 (400->399) \n",
      "en-pt: -0.0 (400->399) \n",
      "sv-en: -0.0 (400->398) \n",
      "en-da: -0.0 (400->399) \n",
      "\n",
      "opus-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "en-pt: 0.1 (400->399) \n",
      "en-el: 0.1 (400->395) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "pt-en: -37.6 (399->400) 游꿢\n",
      "de-en: -24.3 (372->372) 游꿢\n",
      "en-fi: -0.1 (400->397) \n",
      "en-fr: -0.0 (400->399) \n",
      "da-en: -0.0 (400->399) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mismatch_stats = {}\n",
    "\n",
    "\n",
    "\n",
    "for x in p_direct.cases:\n",
    "    df1 = p_direct.cases[x]['BLEU']\n",
    "    df2 = p_no_sent_split.cases[x]['BLEU']\n",
    "    \n",
    "    diff = df1 - df2 \n",
    "    print(x)\n",
    "    diff_mean = diff.values.mean()\n",
    "    \n",
    "    diff_flat = diff.stack()\n",
    "    top3_max = diff_flat.nlargest(15)\n",
    "    print('Largest Positive Differences (Alignment made things worse)')\n",
    "    for (s, t), score in top3_max.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        direct = fn2align_cnt_direct[fn]\n",
    "        mark = ''\n",
    "        if fn in mismatches:\n",
    "            mismatch_stats[fn] = [score, direct, no_sent_split]\n",
    "            mark = \"游꿢\"\n",
    "        if abs(score) > 0.01:\n",
    "            print(f'{s}-{t}: {score:.1f} ({direct}->{no_sent_split}) {mark}')\n",
    "        \n",
    "    top3_min = diff_flat.nsmallest(15)\n",
    "    print('Largest Negative Differences (Alignment made things better)')\n",
    "    for (s, t), score in top3_min.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        direct = fn2align_cnt_direct[fn]\n",
    "        mark = ''\n",
    "        if fn in mismatches:\n",
    "            mismatch_stats[fn] = [score, direct, no_sent_split]\n",
    "            mark = \"游꿢\"\n",
    "        if abs(score) > 0.01:\n",
    "            print(f'{s}-{t}: {score:.1f} ({direct}->{no_sent_split}) {mark}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4204a",
   "metadata": {},
   "source": [
    "* Biggest differences occur only for the ones that we marked, the ones that we suspect to have low BLEU scores due to misalignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d607e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 풊BLEU (direct_cnt->no_sent_split_cnt)\n",
      "ep-gpt-es-en: -34.1 (399->397)\n",
      "ep-gpt-de-en: -25.1 (398->394)\n",
      "ep-gpt-de-fi: -15.6 (399->394)\n",
      "ep-gpt-fi-nl: -15.4 (399->395)\n",
      "ep-gpt-es-el: -15.0 (399->395)\n",
      "ep-gpt-fi-it: -14.8 (399->394)\n",
      "ep-gpt-el-it: -14.3 (399->396)\n",
      "ep-gpt-en-fi: -13.1 (400->397)\n",
      "ep-gpt-pt-fi: -12.6 (400->397)\n",
      "ep-gpt-sv-fi: -12.4 (399->394)\n",
      "ep-gpt-es-nl: -12.3 (399->395)\n",
      "ep-gpt-el-nl: -12.2 (399->395)\n",
      "ep-gpt-da-it: -4.9 (399->396)\n",
      "ep-gpt-it-fi: -1.9 (399->395)\n",
      "flores-gpt-it-fr: -32.7 (399->400)\n",
      "flores-gpt-fi-pt: -31.7 (399->400)\n",
      "flores-gpt-fi-da: -29.9 (399->398)\n",
      "flores-gpt-fi-nl: -24.6 (399->400)\n",
      "flores-gpt-fi-es: -22.2 (399->400)\n",
      "flores-gpt-fi-el: -20.9 (399->400)\n",
      "flores-gpt-es-el: -19.6 (399->400)\n",
      "opus-gpt-pt-en: -37.6 (399->400)\n",
      "opus-gpt-de-en: -24.3 (372->372)\n"
     ]
    }
   ],
   "source": [
    "print('Label: 풊BLEU (direct_cnt->no_sent_split_cnt)')\n",
    "for k, v in mismatch_stats.items():\n",
    "    print(f'{k}: {v[0]:.1f} ({v[1]}->{v[2]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766cbe9",
   "metadata": {},
   "source": [
    "* If we compare Alignment WITHOUT Sentence Splitting to direct alignment, resp. no additional alignment, we observe that differences occur mainly where we assumed to a have mismatch anyway. \n",
    "* It is noteworthy that we see things like `399->400`, this occurs because `direct_alignment` excludes triplets where either source, reference or translation are missing. It means that after alignment, there was not anything that was missing because the alignment managed to fix that, the true counts from `translations` are added as well.\n",
    "* It is also noteworthy that the biggest difference in aligned sent cnt, `sv-de: 400->369`,  had no difference in BLEU scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9bfda",
   "metadata": {},
   "source": [
    "## Consider LaBSE\n",
    "* LaBSE alignments were computed in this notebook: [Alignments_No_Sent_Split_LaBSE.ipynb](https://colab.research.google.com/drive/1ieADAugVQ2nVq0Sqr9a299rsTjs9eMsB?usp=sharing)\n",
    "* LaBSE is computationally more expensive and a bit trickier to use even with Google Colab; has issues with memory occasionally, however, since we used paraphrase-multilingual-MiniLM-L12-v2 for everything, we can now just compare it against LaBSE for the sentences that we plan to align for sure and see if it makes a big difference or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c0bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split_LaBSE')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1811206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-fi 396 394\n",
      "ep-gpt-el-nl 396 395\n",
      "ep-gpt-sv-fi 393 394\n",
      "flores-gpt-fi-da 400 398\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split_LaBSE = {}\n",
    "fn2discard_no_sent_split_LaBSE = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split_LaBSE = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split_LaBSE[fn] = align_cnt\n",
    "\n",
    "\n",
    "for k, v in fn2align_cnt_no_sent_split_LaBSE.items():\n",
    "    other = fn2align_cnt_no_sent_split[k]\n",
    "    if v!=other:\n",
    "        print(k, v, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058df593",
   "metadata": {},
   "source": [
    "* We observe only few disagreements in terms of alignment count between LaBSE and paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abefc707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-fi\n",
      "BLEU Paraphrase: 20.383\n",
      "BLEU LaBSE: 20.356 仇\n",
      "\n",
      "ep-gpt-el-nl\n",
      "BLEU Paraphrase: 25.019\n",
      "BLEU LaBSE: 25.032 仇\n",
      "\n",
      "ep-gpt-sv-fi\n",
      "BLEU Paraphrase: 19.018\n",
      "BLEU LaBSE: 18.983 仇\n",
      "\n",
      "flores-gpt-fi-da\n",
      "BLEU Paraphrase: 30.189\n",
      "BLEU LaBSE: 30.124 仇\n",
      "\n",
      "flores-gpt-fi-es\n",
      "BLEU Paraphrase: 22.857\n",
      "BLEU LaBSE: 22.858 仇\n",
      "\n",
      "flores-gpt-fi-pt\n",
      "BLEU Paraphrase: 32.266\n",
      "BLEU LaBSE: 32.265 仇\n",
      "\n",
      "\n",
      "Mean Difference: 0.024\n",
      "Max Difference: 0.065\n",
      "Min Difference: 0.001\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import load_aligned_sents_from_file\n",
    "from scripts.scoring import compute_bleu\n",
    "from scripts.util import get_env_variables\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "paraphrase = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "laBSE = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(laBSE)]\n",
    "diff_cnt = 0\n",
    "total_diff = 0\n",
    "max_diff = 0\n",
    "min_diff = 100\n",
    "for fn in filenames:\n",
    "    ref_sents_p, mt_sents_p = load_aligned_sents_from_file(\n",
    "        fn, folder=paraphrase, src_label='ref', tgt_label='mt')\n",
    "    ref_sents_l, mt_sents_l = load_aligned_sents_from_file(fn, folder=laBSE,\n",
    "                                                           src_label='ref', tgt_label='mt')\n",
    "    bleu_p = compute_bleu(ref_sents_p, mt_sents_p)\n",
    "    bleu_l = compute_bleu(ref_sents_l, mt_sents_l)\n",
    "    no_diff = bleu_l == bleu_p\n",
    "    if no_diff:\n",
    "        continue\n",
    "    else:\n",
    "        mark = '仇'\n",
    "        diff_cnt += 1\n",
    "        total_diff += abs(bleu_l - bleu_p)\n",
    "        max_diff = max(max_diff, abs(bleu_l - bleu_p))\n",
    "        min_diff = min(min_diff, abs(bleu_l - bleu_p))\n",
    "        print(fn)\n",
    "        print(f'BLEU Paraphrase: {bleu_p:.3f}')\n",
    "        print(f'BLEU LaBSE: {bleu_l:.3f} {mark}')\n",
    "        print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(f'Mean Difference: {total_diff/diff_cnt:.3f}')\n",
    "print(f'Max Difference: {max_diff:.3f}')\n",
    "print(f'Min Difference: {min_diff:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0657cf",
   "metadata": {},
   "source": [
    "* 6 out of 23 alignments yielded slightly different BLEU scores.\n",
    "* 4 out of 6 alignments were likely different because LaBSE aligned differently\n",
    "* **OVERALL CONCLUSION**: Using paraphrase-multilingual-MiniLM-L12-v2 for alignment instead of LaBSE should not be an issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c37cc",
   "metadata": {},
   "source": [
    "## Final Triplets\n",
    "* After doing these various alignment experiments, we can finally create our final triplets that we use for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb1aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d139a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "from scripts.util import get_env_variables\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "\n",
    "direct_folder = join(triplet_folder, 'direct_triplets')\n",
    "direct_files = os.listdir(direct_folder)\n",
    "aligned_folder = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "dst_folder = join(triplet_folder, 'final_triplets')\n",
    "\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "case2cnt = {c: [] for c in cases}\n",
    "os.makedirs(dst_folder, exist_ok=True)\n",
    "for fn in direct_files:\n",
    "    name = fn.replace('.jsonl', '')\n",
    "    if name not in mismatches:\n",
    "        src_file = join(direct_folder, fn)\n",
    "    else:\n",
    "        src_file = join(aligned_folder, fn)\n",
    "\n",
    "    with open(src_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        key = re.search(r'\\w+-\\w+', fn).group(0)\n",
    "        case2cnt[key].append(len(lines))\n",
    "\n",
    "    dst_file = join(dst_folder, fn)\n",
    "    shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04e70380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "Counter({400: 96, 395: 5, 394: 4, 397: 3, 396: 2})\n",
      "\n",
      "ep-deepl\n",
      "Counter({400: 110})\n",
      "\n",
      "flores-gpt\n",
      "Counter({400: 109, 398: 1})\n",
      "\n",
      "flores-deepl\n",
      "Counter({400: 109, 399: 1})\n",
      "\n",
      "opus-gpt\n",
      "Counter({400: 19, 372: 1})\n",
      "\n",
      "opus-deepl\n",
      "Counter({400: 20})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for c, cnts in case2cnt.items():\n",
    "    print(c)\n",
    "    print(Counter(cnts))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
