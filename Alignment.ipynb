{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e994de5b",
   "metadata": {},
   "source": [
    "## Direct Triplets\n",
    "* No alignment is performed on the text, we just place source, reference and translation side by side based on their order (line by line) in the dataset and translation output.\n",
    "* I.e., assume that translators preserved the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "dst_path = join(triplet_folder, 'direct_triplets')\n",
    "parts = {\n",
    "    'opus': {'dm': Opus100Manager(), 'pairs': Opus100Manager.get_pairs()},\n",
    "    'ep': {'dm': EuroParlManager(), 'pairs': EuroParlManager.get_pairs()},\n",
    "    'flores': {'dm': FloresPlusManager(), 'pairs': FloresPlusManager.get_pairs()}\n",
    "}\n",
    "translators = ['gpt', 'deepl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b466a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align, load_sents_from_file\n",
    "fn2align_cnt_direct = {}\n",
    "for dataset, content in parts.items():\n",
    "    dm = content['dm']\n",
    "    pairs = content['pairs']\n",
    "    for pair in pairs:\n",
    "        s, t = pair\n",
    "        for translator in translators:\n",
    "            filename = f'{dataset}-{translator}-{s}-{t}'\n",
    "            mt_sents = load_sents_from_file(\n",
    "                folder='translations', filename=filename)\n",
    "            src_sents, tgt_sents = dm.get_sentence_pairs(\n",
    "                s, t, num_of_sents=400)\n",
    "            cnt = direct_triplet_align(\n",
    "                mt_sents=mt_sents,\n",
    "                src_sents=src_sents,\n",
    "                ref_sents=tgt_sents,\n",
    "                folder_path=dst_path,\n",
    "                filename=filename\n",
    "            )\n",
    "            fn2align_cnt_direct[filename] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2104efc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1\n",
      "398 1\n",
      "399 20\n",
      "400 458\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_direct.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aef2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('direct_cnt.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_direct, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672225e",
   "metadata": {},
   "source": [
    "* Direct alignment only removes empty strings if there are any\n",
    "* Most of the time, we have 400 aligned triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae565ce",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITHOUT Sentence Splitting\n",
    "* Alignments were computed in this notebook: [Alignments_No_Sent_Split.ipynb](https://colab.research.google.com/drive/1867NBRM7ixgiVmeznqRf4oh9nYDd4D5S?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1535bc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5758495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 383\n",
      "max: 398\n",
      "mean: 396.31\n",
      "\n",
      "ep-deepl\n",
      "min: 369\n",
      "max: 398\n",
      "mean: 395.77\n",
      "\n",
      "flores-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 396.65\n",
      "\n",
      "flores-deepl\n",
      "min: 374\n",
      "max: 400\n",
      "mean: 396.61\n",
      "\n",
      "opus-gpt\n",
      "min: 372\n",
      "max: 400\n",
      "mean: 397.85\n",
      "\n",
      "opus-deepl\n",
      "min: 395\n",
      "max: 400\n",
      "mean: 398.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split = {}\n",
    "fn2discard_no_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split[fn] = align_cnt\n",
    "    fn2discard_no_sent_split[fn] = dis\n",
    "    case2align_cnts_no_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_no_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd51a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369 1\n",
      "372 2\n",
      "374 19\n",
      "383 2\n",
      "384 1\n",
      "391 1\n",
      "392 2\n",
      "393 8\n",
      "394 13\n",
      "395 38\n",
      "396 36\n",
      "397 144\n",
      "398 47\n",
      "399 32\n",
      "400 134\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_no_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c26dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_no_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_no_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d2e82",
   "metadata": {},
   "source": [
    "### Investigating Loss of Text\n",
    "* If we apply `bertalign` WITHOUT sentence splitting to all translations, we lose text in some cases.\n",
    "* The 'biggest' loss is 391-369=22 sentences for `ep-deepl-sv-de`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67e06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "!cat translations/ep-deepl-sv-de.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3076ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "!cat $src2hyp_split_fo/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28da166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "!cat $dst_path/ep-deepl-sv-de.jsonl | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bcb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vi skall rösta om begäran från PPE-DE-gruppen som syftar till att stryka den muntliga frågan om kapitalskatt från föredragningslistan.',\n",
       " '(Parlamentet avslog begäran med 164 röster för, 166 emot. 7 ledamöter avstod från att rösta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering för att han just gjort reklam för denna debatt.',\n",
       " 'Tack.',\n",
       " 'Fru talman!',\n",
       " 'Jag undrar om även min röst har räknats, trots att den inte kunde avges på elektronisk väg, eftersom jag inte har något kort?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.post_process import load_aligned_sents_from_file, load_sents_from_file\n",
    "mt_sents = load_sents_from_file('ep-deepl-sv-de', 'translations')\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('sv', 'de', num_of_sents=400)\n",
    "src_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44083fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir stimmen jetzt über den Antrag der PPE/DE-Fraktion ab, die mündliche Anfrage über die Kapitalsteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 Ja-Stimmen, 166 Nein-Stimmen und 7 Enthaltungen ab.)',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering für das Rühren der Werbetrommel zugunsten dieser Aussprache danken.',\n",
       " 'Vielen Dank.',\n",
       " 'Frau Präsidentin!',\n",
       " 'Ist meine Stimme mitgezählt worden? Ich konnte sie nämlich nicht elektronisch abgeben, weil ich die Karte nicht habe.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sents[100:106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e40454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wir werden über den Antrag der Fraktion der Europäischen Volkspartei (Christdemokraten) und europäischer Demokraten abstimmen, die mündliche Anfrage zur Gesellschaftssteuer von der Tagesordnung abzusetzen.',\n",
       " '(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering dafür danken, dass er diese Aussprache soeben angekündigt hat.',\n",
       " 'Vielen Dank, Herr Pöttering.',\n",
       " 'Frau Präsidentin, ich möchte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gezählt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00934af",
   "metadata": {},
   "source": [
    "* The direct alignment for this specific instance is correct, however, we already observe a slight difference between reference and translation\n",
    "* `Vielen Dank` vs `Vielen Dank, Herr Pöttering.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8c18a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Parlamentet avslog begäran med 164 röster för, 166 emot. 7 ledamöter avstod från att rösta.)',\n",
       " 'Fru talman! Jag skulle vilja tacka Poettering för att han just gjort reklam för denna debatt.',\n",
       " '',\n",
       " 'Tack. Fru talman!',\n",
       " 'Jag undrar om även min röst har räknats, trots att den inte kunde avges på elektronisk väg, eftersom jag inte har något kort?',\n",
       " 'Jag röstade \"för\".',\n",
       " 'Om man lägger till de två kolleger som yttrat sig blir resultatet...']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sents_ali, mt_sents_ali = load_aligned_sents_from_file('ep-deepl-sv-de', src2hyp_split_fo)\n",
    "src_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7d20d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Das Parlament lehnt den Antrag mit 164 gegen 166 Stimmen ab. 7 Abgeordnete enthalten sich der Stimme).',\n",
       " 'Frau Präsidentin, ich möchte Herrn Poettering dafür danken, dass er diese Aussprache soeben angekündigt hat.',\n",
       " 'Vielen Dank, Herr Pöttering.',\n",
       " 'Frau Präsidentin, ich möchte Folgendes fragen',\n",
       " 'Ich frage mich, ob meine Stimme auch gezählt worden ist, obwohl sie nicht elektronisch abgegeben werden konnte, weil ich keine Karte habe?',\n",
       " 'Ich habe mit \"Ja\" gestimmt.',\n",
       " 'Wenn Sie die beiden Kollegen, die sich zu Wort gemeldet haben, hinzuzählen, lautet das Ergebnis...']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_sents_ali[100:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4731f0",
   "metadata": {},
   "source": [
    "* Alignment with `bertalign` works but is dependent on the translation. It merged the source sentences together to get a 2-1 alignment with:\n",
    "```\n",
    "'Tack. Fru talman!' <->  'Vielen Dank, Herr Pöttering.',\n",
    "```\n",
    "* As a consequence, we see an empty string in the aligned source sentences\n",
    "* Furthermore, since the original source sentences do not contain the string `'Tack. Fru talman!'`, it will be discarded, as triplet alignments are created by matching the sentences from the original source strings to the aligned source strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c1cd",
   "metadata": {},
   "source": [
    "## Aligned Triplets WITH Sentences Splitting\n",
    "* The alignments were computed in this notebook: [Alignments.ipynb](https://colab.research.google.com/drive/1xlwQPctsOGjZB2NpB9WNtzWPae_Oj4gt?usp=sharing)\n",
    "* Note: To make alignments with sentence splitting, we had to align source to reference AND source to translation, whereas before only source to translation was enough, as we could use the alignments provided by the respective datasets directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97698926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "# Aligned source to translation\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_sent_split')\n",
    "# Aligned source to reference\n",
    "src2ref_split_fo = join(aligned_folder, 'source2reference_sent_split')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_sent_split')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c1cc932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "min: 329\n",
      "max: 396\n",
      "mean: 374.74\n",
      "\n",
      "ep-deepl\n",
      "min: 328\n",
      "max: 395\n",
      "mean: 377.38\n",
      "\n",
      "flores-gpt\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.58\n",
      "\n",
      "flores-deepl\n",
      "min: 390\n",
      "max: 428\n",
      "mean: 417.23\n",
      "\n",
      "opus-gpt\n",
      "min: 361\n",
      "max: 399\n",
      "mean: 382.95\n",
      "\n",
      "opus-deepl\n",
      "min: 361\n",
      "max: 398\n",
      "mean: 383.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn2align_cnt_sent_split = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_sent_split = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    src_sents_o, ref_sents_o = load_aligned_sents_from_file(\n",
    "        f'{dataset}-{s}-{t}', folder=src2ref_split_fo)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_sent_split[fn] = align_cnt\n",
    "    case2align_cnts_sent_split[f'{dataset}-{translator}'].append(align_cnt)\n",
    "\n",
    "for t, ac in case2align_cnts_sent_split.items():\n",
    "    max_cnt = max(ac)\n",
    "    min_cnt = min(ac)\n",
    "    mean = sum(ac) / len(ac)\n",
    "    print(t)\n",
    "    print(f'min: {min_cnt}')\n",
    "    print(f'max: {max_cnt}')\n",
    "    print(f'mean: {mean:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a34f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 1\n",
      "329 1\n",
      "333 2\n",
      "334 1\n",
      "335 1\n",
      "336 1\n",
      "338 3\n",
      "339 5\n",
      "342 2\n",
      "343 2\n",
      "344 2\n",
      "345 1\n",
      "347 1\n",
      "348 2\n",
      "349 1\n",
      "351 2\n",
      "356 1\n",
      "357 1\n",
      "360 2\n",
      "361 4\n",
      "362 2\n",
      "363 1\n",
      "364 2\n",
      "365 1\n",
      "366 6\n",
      "367 2\n",
      "368 3\n",
      "369 4\n",
      "370 3\n",
      "371 1\n",
      "372 5\n",
      "373 2\n",
      "374 5\n",
      "375 5\n",
      "376 4\n",
      "377 11\n",
      "378 14\n",
      "379 7\n",
      "380 7\n",
      "381 7\n",
      "382 7\n",
      "383 12\n",
      "384 13\n",
      "385 4\n",
      "386 18\n",
      "387 8\n",
      "388 12\n",
      "389 11\n",
      "390 16\n",
      "391 13\n",
      "392 6\n",
      "393 4\n",
      "394 7\n",
      "395 3\n",
      "396 3\n",
      "397 3\n",
      "398 4\n",
      "399 2\n",
      "400 2\n",
      "401 1\n",
      "403 4\n",
      "404 1\n",
      "405 3\n",
      "406 4\n",
      "407 1\n",
      "408 2\n",
      "409 2\n",
      "410 1\n",
      "411 6\n",
      "412 7\n",
      "413 8\n",
      "414 4\n",
      "415 5\n",
      "416 3\n",
      "417 6\n",
      "418 10\n",
      "419 13\n",
      "420 14\n",
      "421 20\n",
      "422 13\n",
      "423 30\n",
      "424 20\n",
      "425 10\n",
      "426 8\n",
      "427 5\n",
      "428 3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cnt_freq = defaultdict(int)\n",
    "for k, v in fn2align_cnt_sent_split.items():\n",
    "    cnt_freq[v] += 1\n",
    "\n",
    "for k in sorted(cnt_freq):\n",
    "    print(k, cnt_freq[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0224cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('aligned_cnt_sent_split.json', 'w') as f:\n",
    "    json.dump(fn2align_cnt_sent_split, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aae253",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "* For all three triplet formations, no alignment, alignment without sentence splitting and alignment with sentence splitting, we compute BLUE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f3e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "from scripts.util import get_env_variables\n",
    "import os\n",
    "from os.path import join\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "results_folder = get_env_variables('RESULTS')\n",
    "\n",
    "result_types = {'direct_results':join(triplet_folder, 'direct_triplets'), \n",
    "                'aligned_results_no_sent_split': join(triplet_folder, 'aligned_triplets_no_sent_split'),\n",
    "                'aligned_results_sent_split': join(triplet_folder, 'aligned_triplets_sent_split')}\n",
    "\n",
    "for rt in result_types:\n",
    "    files = os.listdir(result_types[rt])\n",
    "    folder_path = join(results_folder, rt)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "             'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "    for case in cases:\n",
    "        l2f = {f.replace(f'{case}-', '').replace('.jsonl', '')\n",
    "                         : join(result_types[rt], f) for f in files if f.startswith(case)}\n",
    "        rp = ResultProducer(label2files=l2f)\n",
    "        rp.compute_results()\n",
    "        rp.store_results(join(folder_path, f'{case}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc454065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.presentation import Presenter\n",
    "p_direct = Presenter(results_folder=join(results_folder, 'direct_results'))\n",
    "p_no_sent_split = Presenter(results_folder=join(results_folder, 'aligned_results_no_sent_split'))\n",
    "p_sent_split = Presenter(results_folder=join(results_folder, 'aligned_results_sent_split'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e19b2",
   "metadata": {},
   "source": [
    "## Difference between Alignment WITH and WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2681f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload cnts \n",
    "import json\n",
    "with open('aligned_cnt_no_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_no_sent_split = json.load(f)\n",
    "\n",
    "with open('aligned_cnt_sent_split.json', 'r') as f:\n",
    "    fn2align_cnt_sent_split = json.load(f)\n",
    "\n",
    "with open('direct_cnt.json', 'r') as f:\n",
    "    fn2align_cnt_direct = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abd9abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "da-es: 0.9 (395->383)\n",
      "fr-fi: 0.4 (397->390)\n",
      "fi-es: 0.3 (395->388)\n",
      "fr-it: 0.3 (397->372)\n",
      "es-da: 0.2 (396->390)\n",
      "fr-el: 0.2 (396->381)\n",
      "fr-de: 0.1 (397->391)\n",
      "sv-fi: 0.1 (393->376)\n",
      "es-fr: 0.1 (396->389)\n",
      "fr-da: 0.1 (397->389)\n",
      "pt-es: 0.1 (397->386)\n",
      "da-el: 0.1 (395->385)\n",
      "en-it: 0.1 (397->366)\n",
      "fr-es: 0.1 (397->387)\n",
      "pt-de: 0.1 (397->384)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "nl-fi: -2.5 (397->345)\n",
      "nl-da: -2.5 (397->343)\n",
      "nl-sv: -2.2 (395->333)\n",
      "nl-en: -2.2 (397->339)\n",
      "nl-pt: -2.1 (396->336)\n",
      "nl-es: -2.0 (397->338)\n",
      "nl-fr: -2.0 (397->339)\n",
      "nl-de: -1.9 (397->342)\n",
      "nl-it: -1.5 (397->328)\n",
      "nl-el: -1.3 (397->339)\n",
      "it-pt: -0.9 (398->370)\n",
      "it-fr: -0.9 (398->378)\n",
      "it-de: -0.8 (398->378)\n",
      "it-es: -0.7 (398->380)\n",
      "it-en: -0.7 (398->378)\n",
      "\n",
      "ep-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "sv-fr: 0.5 (395->351)\n",
      "fr-fi: 0.4 (397->390)\n",
      "fi-en: 0.3 (397->383)\n",
      "en-it: 0.3 (397->366)\n",
      "fi-pt: 0.3 (397->384)\n",
      "da-el: 0.2 (397->387)\n",
      "fr-el: 0.2 (397->382)\n",
      "fi-el: 0.2 (397->384)\n",
      "sv-pt: 0.2 (395->348)\n",
      "da-es: 0.2 (397->386)\n",
      "de-pt: 0.2 (397->360)\n",
      "fi-fr: 0.2 (397->387)\n",
      "fr-de: 0.1 (397->391)\n",
      "fr-it: 0.1 (397->372)\n",
      "pt-es: 0.1 (397->386)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "nl-es: -2.4 (397->338)\n",
      "nl-sv: -2.4 (395->333)\n",
      "nl-da: -2.4 (397->343)\n",
      "nl-en: -2.2 (397->339)\n",
      "nl-fr: -1.9 (397->338)\n",
      "nl-it: -1.6 (397->329)\n",
      "nl-fi: -1.6 (397->344)\n",
      "nl-pt: -1.5 (396->335)\n",
      "nl-el: -1.4 (397->339)\n",
      "nl-de: -1.3 (397->342)\n",
      "en-sv: -0.7 (397->378)\n",
      "de-it: -0.7 (397->347)\n",
      "it-es: -0.7 (398->380)\n",
      "it-pt: -0.7 (398->370)\n",
      "it-fr: -0.6 (398->378)\n",
      "\n",
      "flores-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "fr-sv: 0.9 (374->423)\n",
      "fr-en: 0.7 (374->423)\n",
      "sv-fi: 0.4 (397->423)\n",
      "fr-da: 0.2 (374->423)\n",
      "da-fi: 0.2 (394->428)\n",
      "da-sv: 0.2 (394->418)\n",
      "it-de: 0.2 (400->425)\n",
      "nl-de: 0.2 (400->403)\n",
      "sv-de: 0.2 (397->423)\n",
      "da-en: 0.2 (396->420)\n",
      "en-fi: 0.2 (400->427)\n",
      "sv-da: 0.2 (397->423)\n",
      "da-de: 0.2 (396->426)\n",
      "sv-en: 0.1 (397->424)\n",
      "it-sv: 0.1 (400->425)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "fi-en: -0.7 (400->406)\n",
      "de-fr: -0.6 (399->412)\n",
      "fi-pt: -0.5 (400->403)\n",
      "de-en: -0.5 (399->411)\n",
      "da-fr: -0.4 (396->420)\n",
      "nl-fi: -0.4 (399->406)\n",
      "nl-pt: -0.4 (400->397)\n",
      "de-sv: -0.4 (399->412)\n",
      "de-fi: -0.4 (399->421)\n",
      "fi-el: -0.3 (398->398)\n",
      "fi-nl: -0.3 (400->410)\n",
      "de-it: -0.3 (399->411)\n",
      "es-nl: -0.3 (400->412)\n",
      "fi-fr: -0.2 (400->406)\n",
      "da-es: -0.2 (396->417)\n",
      "\n",
      "flores-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "fr-en: 0.6 (374->423)\n",
      "fr-sv: 0.3 (374->423)\n",
      "sv-fi: 0.3 (397->424)\n",
      "sv-de: 0.3 (397->425)\n",
      "nl-de: 0.3 (400->403)\n",
      "fr-nl: 0.3 (374->419)\n",
      "sv-da: 0.3 (397->426)\n",
      "nl-sv: 0.2 (400->393)\n",
      "sv-en: 0.2 (397->425)\n",
      "nl-da: 0.2 (400->401)\n",
      "da-de: 0.2 (396->428)\n",
      "fr-pt: 0.2 (374->421)\n",
      "nl-it: 0.2 (400->400)\n",
      "de-pt: 0.2 (399->415)\n",
      "it-de: 0.2 (400->424)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "de-fr: -0.6 (399->412)\n",
      "fi-en: -0.6 (400->408)\n",
      "fr-el: -0.5 (374->418)\n",
      "nl-fi: -0.5 (400->409)\n",
      "fi-pt: -0.4 (400->408)\n",
      "de-fi: -0.4 (399->421)\n",
      "fi-fr: -0.3 (398->409)\n",
      "it-en: -0.3 (400->423)\n",
      "da-fr: -0.3 (396->420)\n",
      "de-el: -0.3 (399->413)\n",
      "nl-pt: -0.3 (400->398)\n",
      "de-es: -0.3 (399->413)\n",
      "de-sv: -0.3 (399->411)\n",
      "nl-en: -0.3 (400->394)\n",
      "fi-da: -0.3 (398->414)\n",
      "\n",
      "opus-deepl\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "it-en: -0.2 (400->395)\n",
      "fr-en: -0.8 (400->397)\n",
      "en-fr: -0.9 (399->390)\n",
      "en-de: -0.9 (400->398)\n",
      "de-en: -1.1 (400->394)\n",
      "da-en: -1.2 (399->383)\n",
      "nl-en: -1.2 (400->388)\n",
      "pt-en: -1.3 (399->389)\n",
      "en-fi: -1.3 (395->361)\n",
      "el-en: -1.4 (395->378)\n",
      "en-it: -1.5 (400->383)\n",
      "en-pt: -1.5 (399->382)\n",
      "en-es: -1.6 (400->394)\n",
      "es-en: -1.7 (400->393)\n",
      "en-el: -1.7 (396->372)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "en-sv: -3.4 (400->362)\n",
      "fi-en: -2.4 (395->374)\n",
      "sv-en: -2.2 (398->381)\n",
      "en-da: -1.7 (399->382)\n",
      "en-nl: -1.7 (400->381)\n",
      "en-el: -1.7 (396->372)\n",
      "es-en: -1.7 (400->393)\n",
      "en-es: -1.6 (400->394)\n",
      "en-pt: -1.5 (399->382)\n",
      "en-it: -1.5 (400->383)\n",
      "el-en: -1.4 (395->378)\n",
      "en-fi: -1.3 (395->361)\n",
      "pt-en: -1.3 (399->389)\n",
      "nl-en: -1.2 (400->388)\n",
      "da-en: -1.2 (399->383)\n",
      "\n",
      "opus-gpt\n",
      "Largest Positive Differences (Sent Splits made things worse)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "it-en: -0.2 (400->395)\n",
      "en-de: -0.6 (400->399)\n",
      "fr-en: -0.8 (400->397)\n",
      "en-fi: -0.8 (397->361)\n",
      "nl-en: -0.8 (400->388)\n",
      "en-fr: -0.9 (399->390)\n",
      "en-it: -1.2 (400->383)\n",
      "pt-en: -1.2 (400->390)\n",
      "en-es: -1.2 (400->393)\n",
      "es-en: -1.4 (400->394)\n",
      "el-en: -1.5 (397->380)\n",
      "en-da: -1.5 (399->384)\n",
      "en-pt: -1.5 (399->380)\n",
      "en-el: -1.6 (395->373)\n",
      "da-en: -1.6 (399->384)\n",
      "Largest Negative Differences (Sent Splits made things better)\n",
      "Label: ΔBLEU (no sent split cnt-> sent split cnt)\n",
      "fi-en: -2.4 (400->377)\n",
      "en-sv: -2.4 (400->364)\n",
      "sv-en: -1.9 (400->380)\n",
      "en-nl: -1.8 (400->379)\n",
      "de-en: -1.6 (372->368)\n",
      "da-en: -1.6 (399->384)\n",
      "en-el: -1.6 (395->373)\n",
      "en-pt: -1.5 (399->380)\n",
      "en-da: -1.5 (399->384)\n",
      "el-en: -1.5 (397->380)\n",
      "es-en: -1.4 (400->394)\n",
      "en-es: -1.2 (400->393)\n",
      "pt-en: -1.2 (400->390)\n",
      "en-it: -1.2 (400->383)\n",
      "en-fr: -0.9 (399->390)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in p_no_sent_split.cases:\n",
    "    df1 = p_no_sent_split.cases[x]['BLEU']\n",
    "    df2 = p_sent_split.cases[x]['BLEU']\n",
    "    diff = df1 - df2\n",
    "    print(x)\n",
    "    diff_mean = diff.values.mean()\n",
    "\n",
    "    diff_flat = diff.stack()\n",
    "    top3_max = diff_flat.nlargest(15)\n",
    "    print('Largest Positive Differences (Sent Splits made things worse)')\n",
    "    print('Label: ΔBLEU (no sent split cnt-> sent split cnt)')\n",
    "    for (s, t), score in top3_max.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        sent_split = fn2align_cnt_sent_split[fn]\n",
    "        print(f'{s}-{t}: {score:.1f} ({no_sent_split}->{sent_split})')\n",
    "\n",
    "    top3_min = diff_flat.nsmallest(15)\n",
    "    print('Largest Negative Differences (Sent Splits made things better)')\n",
    "    print('Label: ΔBLEU (no sent split cnt-> sent split cnt)')\n",
    "    for (s, t), score in top3_min.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        sent_split = fn2align_cnt_sent_split[fn]\n",
    "        print(f'{s}-{t}: {score:.1f} ({no_sent_split}->{sent_split})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f61ba7",
   "metadata": {},
   "source": [
    "* In this case, Negative Differences refer to the case where Alignment WITH Sentence Splitting yielded higher BLEU scores than WITHOUT\n",
    "* However, we can see based on alignment counts, that it may be not related to alignment but due to the fact that it works with less sentences overall.\n",
    "* Additionally, the highest difference we observe is -3.4, not too tragic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845680a9",
   "metadata": {},
   "source": [
    "## Difference between Direct and Alignment WITHOUT Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95b54533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "mismatches = {}\n",
    "\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "    \n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        mismatches[prefix] = outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9358a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "da-fi: 0.2 (400->395) \n",
      "sv-es: 0.2 (400->393) \n",
      "nl-sv: 0.1 (400->395) \n",
      "sv-fr: 0.1 (400->393) \n",
      "da-de: 0.1 (400->395) \n",
      "fr-fi: 0.1 (400->397) \n",
      "pt-fi: 0.1 (400->397) \n",
      "fr-pt: 0.1 (400->397) \n",
      "da-en: 0.1 (400->395) \n",
      "de-fr: 0.1 (400->397) \n",
      "el-sv: 0.1 (400->394) \n",
      "de-da: 0.1 (400->397) \n",
      "en-fr: 0.1 (400->397) \n",
      "nl-pt: 0.1 (400->396) \n",
      "pt-da: 0.1 (400->395) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "da-el: -0.1 (400->395) \n",
      "sv-de: -0.0 (400->369) \n",
      "el-en: 0.0 (400->397) \n",
      "el-it: 0.0 (400->398) \n",
      "it-el: 0.0 (400->398) \n",
      "fi-el: 0.0 (400->397) \n",
      "es-en: 0.0 (400->396) \n",
      "de-el: 0.0 (400->397) \n",
      "\n",
      "ep-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "fr-nl: 0.1 (400->395) \n",
      "sv-de: 0.1 (400->383) \n",
      "de-sv: 0.1 (400->384) \n",
      "nl-pt: 0.1 (400->396) \n",
      "it-de: 0.1 (400->398) \n",
      "el-de: 0.1 (400->397) \n",
      "nl-fi: 0.1 (400->397) \n",
      "pt-nl: 0.1 (400->397) \n",
      "en-de: 0.1 (400->397) \n",
      "it-nl: 0.1 (400->398) \n",
      "fi-de: 0.1 (400->396) \n",
      "es-fi: 0.1 (400->395) \n",
      "da-de: 0.1 (400->397) \n",
      "nl-fr: 0.1 (400->397) \n",
      "en-nl: 0.1 (400->397) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "es-en: -34.1 (399->397) 🎯\n",
      "de-en: -25.1 (398->394) 🎯\n",
      "de-fi: -15.6 (399->394) 🎯\n",
      "fi-nl: -15.4 (399->395) 🎯\n",
      "es-el: -15.0 (399->395) 🎯\n",
      "fi-it: -14.8 (399->394) 🎯\n",
      "el-it: -14.3 (399->396) 🎯\n",
      "en-fi: -13.1 (400->397) 🎯\n",
      "pt-fi: -12.6 (400->397) 🎯\n",
      "sv-fi: -12.4 (399->394) 🎯\n",
      "es-nl: -12.3 (399->395) 🎯\n",
      "el-nl: -12.2 (399->395) 🎯\n",
      "da-it: -4.9 (399->396) 🎯\n",
      "it-fi: -1.9 (399->395) 🎯\n",
      "sv-en: -0.0 (400->395) \n",
      "\n",
      "flores-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "da-fr: 0.1 (400->396) \n",
      "sv-pt: 0.1 (400->397) \n",
      "da-de: 0.1 (400->396) \n",
      "fi-el: 0.1 (400->398) \n",
      "da-nl: 0.1 (400->396) \n",
      "da-es: 0.0 (400->396) \n",
      "sv-fr: 0.0 (400->397) \n",
      "fr-it: 0.0 (400->374) \n",
      "de-es: 0.0 (400->399) \n",
      "es-de: 0.0 (400->398) \n",
      "nl-fi: 0.0 (400->399) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "fr-sv: -1.0 (400->374) \n",
      "fr-en: -0.8 (400->374) \n",
      "fr-da: -0.5 (400->374) \n",
      "fr-nl: -0.3 (400->374) \n",
      "pt-en: -0.3 (400->398) \n",
      "fr-pt: -0.3 (400->374) \n",
      "pt-da: -0.2 (400->398) \n",
      "sv-fi: -0.2 (400->397) \n",
      "pt-fr: -0.2 (400->398) \n",
      "da-fi: -0.2 (400->394) \n",
      "fr-es: -0.2 (400->374) \n",
      "fr-fi: -0.2 (400->374) \n",
      "pt-nl: -0.2 (400->398) \n",
      "sv-nl: -0.2 (400->397) \n",
      "sv-de: -0.1 (400->397) \n",
      "\n",
      "flores-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "fr-el: 0.3 (400->374) \n",
      "da-fr: 0.1 (400->396) \n",
      "fr-fi: 0.1 (400->372) \n",
      "de-fr: 0.1 (400->399) \n",
      "sv-pt: 0.1 (400->397) \n",
      "de-en: 0.0 (400->399) \n",
      "da-pt: 0.0 (400->396) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "it-fr: -32.7 (399->400) 🎯\n",
      "fi-pt: -31.7 (399->400) 🎯\n",
      "fi-da: -29.9 (399->398) 🎯\n",
      "fi-nl: -24.6 (399->400) 🎯\n",
      "fi-es: -22.2 (399->400) 🎯\n",
      "fi-el: -20.9 (399->400) 🎯\n",
      "es-el: -19.6 (399->400) 🎯\n",
      "fr-en: -0.7 (400->374) \n",
      "fr-sv: -0.4 (400->374) \n",
      "fr-pt: -0.3 (400->374) \n",
      "fr-de: -0.3 (400->374) \n",
      "fr-da: -0.3 (400->374) \n",
      "fr-nl: -0.3 (400->374) \n",
      "pt-fr: -0.2 (400->398) \n",
      "sv-fi: -0.2 (400->397) \n",
      "\n",
      "opus-deepl\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "en-da: -0.0 (400->399) \n",
      "sv-en: -0.0 (400->398) \n",
      "en-pt: -0.0 (400->399) \n",
      "pt-en: -0.0 (400->399) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "el-en: -0.2 (400->395) \n",
      "fi-en: -0.2 (400->395) \n",
      "en-fi: -0.1 (400->395) \n",
      "en-fr: -0.1 (400->399) \n",
      "da-en: -0.1 (400->399) \n",
      "pt-en: -0.0 (400->399) \n",
      "en-pt: -0.0 (400->399) \n",
      "sv-en: -0.0 (400->398) \n",
      "en-da: -0.0 (400->399) \n",
      "\n",
      "opus-gpt\n",
      "Largest Positive Differences (Alignment made things worse)\n",
      "en-pt: 0.1 (400->399) \n",
      "en-el: 0.1 (400->395) \n",
      "Largest Negative Differences (Alignment made things better)\n",
      "pt-en: -37.6 (399->400) 🎯\n",
      "de-en: -24.3 (372->372) 🎯\n",
      "en-fi: -0.1 (400->397) \n",
      "en-fr: -0.0 (400->399) \n",
      "da-en: -0.0 (400->399) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mismatch_stats = {}\n",
    "\n",
    "\n",
    "\n",
    "for x in p_direct.cases:\n",
    "    df1 = p_direct.cases[x]['BLEU']\n",
    "    df2 = p_no_sent_split.cases[x]['BLEU']\n",
    "    \n",
    "    diff = df1 - df2 \n",
    "    print(x)\n",
    "    diff_mean = diff.values.mean()\n",
    "    \n",
    "    diff_flat = diff.stack()\n",
    "    top3_max = diff_flat.nlargest(15)\n",
    "    print('Largest Positive Differences (Alignment made things worse)')\n",
    "    for (s, t), score in top3_max.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        direct = fn2align_cnt_direct[fn]\n",
    "        mark = ''\n",
    "        if fn in mismatches:\n",
    "            mismatch_stats[fn] = [score, direct, no_sent_split]\n",
    "            mark = \"🎯\"\n",
    "        if abs(score) > 0.01:\n",
    "            print(f'{s}-{t}: {score:.1f} ({direct}->{no_sent_split}) {mark}')\n",
    "        \n",
    "    top3_min = diff_flat.nsmallest(15)\n",
    "    print('Largest Negative Differences (Alignment made things better)')\n",
    "    for (s, t), score in top3_min.items():\n",
    "        fn = f'{x}-{s}-{t}'\n",
    "        no_sent_split = fn2align_cnt_no_sent_split[fn]\n",
    "        direct = fn2align_cnt_direct[fn]\n",
    "        mark = ''\n",
    "        if fn in mismatches:\n",
    "            mismatch_stats[fn] = [score, direct, no_sent_split]\n",
    "            mark = \"🎯\"\n",
    "        if abs(score) > 0.01:\n",
    "            print(f'{s}-{t}: {score:.1f} ({direct}->{no_sent_split}) {mark}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4204a",
   "metadata": {},
   "source": [
    "* Biggest differences occur only for the ones that we marked, the ones that we suspect to have low BLEU scores due to misalignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d607e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ΔBLEU (direct_cnt->no_sent_split_cnt)\n",
      "ep-gpt-es-en: -34.1 (399->397)\n",
      "ep-gpt-de-en: -25.1 (398->394)\n",
      "ep-gpt-de-fi: -15.6 (399->394)\n",
      "ep-gpt-fi-nl: -15.4 (399->395)\n",
      "ep-gpt-es-el: -15.0 (399->395)\n",
      "ep-gpt-fi-it: -14.8 (399->394)\n",
      "ep-gpt-el-it: -14.3 (399->396)\n",
      "ep-gpt-en-fi: -13.1 (400->397)\n",
      "ep-gpt-pt-fi: -12.6 (400->397)\n",
      "ep-gpt-sv-fi: -12.4 (399->394)\n",
      "ep-gpt-es-nl: -12.3 (399->395)\n",
      "ep-gpt-el-nl: -12.2 (399->395)\n",
      "ep-gpt-da-it: -4.9 (399->396)\n",
      "ep-gpt-it-fi: -1.9 (399->395)\n",
      "flores-gpt-it-fr: -32.7 (399->400)\n",
      "flores-gpt-fi-pt: -31.7 (399->400)\n",
      "flores-gpt-fi-da: -29.9 (399->398)\n",
      "flores-gpt-fi-nl: -24.6 (399->400)\n",
      "flores-gpt-fi-es: -22.2 (399->400)\n",
      "flores-gpt-fi-el: -20.9 (399->400)\n",
      "flores-gpt-es-el: -19.6 (399->400)\n",
      "opus-gpt-pt-en: -37.6 (399->400)\n",
      "opus-gpt-de-en: -24.3 (372->372)\n"
     ]
    }
   ],
   "source": [
    "print('Label: ΔBLEU (direct_cnt->no_sent_split_cnt)')\n",
    "for k, v in mismatch_stats.items():\n",
    "    print(f'{k}: {v[0]:.1f} ({v[1]}->{v[2]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766cbe9",
   "metadata": {},
   "source": [
    "* If we compare Alignment WITHOUT Sentence Splitting to direct alignment, resp. no additional alignment, we observe that differences occur mainly where we assumed to a have mismatch anyway. \n",
    "* It is noteworthy that we see things like `399->400`, this occurs because `direct_alignment` excludes triplets where either source, reference or translation are missing. It means that after alignment, there was not anything that was missing because the alignment managed to fix that, the true counts from `translations` are added as well.\n",
    "* It is also noteworthy that the biggest difference in aligned sent cnt, `sv-de: 400->369`,  had no difference in BLEU scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9bfda",
   "metadata": {},
   "source": [
    "## Consider LaBSE\n",
    "* LaBSE alignments were computed in this notebook: [Alignments_No_Sent_Split_LaBSE.ipynb](https://colab.research.google.com/drive/1ieADAugVQ2nVq0Sqr9a299rsTjs9eMsB?usp=sharing)\n",
    "* LaBSE is computationally more expensive and a bit trickier to use even with Google Colab; has issues with memory occasionally, however, since we used paraphrase-multilingual-MiniLM-L12-v2 for everything, we can now just compare it against LaBSE for the sentences that we plan to align for sure and see if it makes a big difference or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c0bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from scripts.util import get_env_variables\n",
    "from os.path import join\n",
    "aligned_folder = get_env_variables('ALIGNMENTS')\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "src2hyp_split_fo = join(aligned_folder, 'source2translations_no_sent_split_LaBSE')\n",
    "dst_path = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_split_fo)]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1811206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-fi 396 394\n",
      "ep-gpt-el-nl 396 395\n",
      "ep-gpt-sv-fi 393 394\n",
      "flores-gpt-fi-da 400 398\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "\n",
    "dms = {\n",
    "    'ep': EuroParlManager(),\n",
    "    'flores': FloresPlusManager(),\n",
    "    'opus': Opus100Manager()\n",
    "}\n",
    "\n",
    "fn2align_cnt_no_sent_split_LaBSE = {}\n",
    "fn2discard_no_sent_split_LaBSE = {}\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "case2align_cnts_no_sent_split_LaBSE = {c: [] for c in cases}\n",
    "\n",
    "for fn in filenames:\n",
    "    dataset, translator, s, t = fn.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(\n",
    "        fn, folder=src2hyp_split_fo)\n",
    "    dm = dms[dataset]\n",
    "    src_sents_o, ref_sents_o = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    align_cnt, dis = post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        folder_path=dst_path,\n",
    "        filename=fn)\n",
    "\n",
    "    fn2align_cnt_no_sent_split_LaBSE[fn] = align_cnt\n",
    "\n",
    "\n",
    "for k, v in fn2align_cnt_no_sent_split_LaBSE.items():\n",
    "    other = fn2align_cnt_no_sent_split[k]\n",
    "    if v!=other:\n",
    "        print(k, v, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058df593",
   "metadata": {},
   "source": [
    "* We observe only few disagreements in terms of alignment count between LaBSE and paraphrase-multilingual-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abefc707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt-de-fi\n",
      "BLEU Paraphrase: 20.383\n",
      "BLEU LaBSE: 20.356 ❌\n",
      "\n",
      "ep-gpt-el-nl\n",
      "BLEU Paraphrase: 25.019\n",
      "BLEU LaBSE: 25.032 ❌\n",
      "\n",
      "ep-gpt-sv-fi\n",
      "BLEU Paraphrase: 19.018\n",
      "BLEU LaBSE: 18.983 ❌\n",
      "\n",
      "flores-gpt-fi-da\n",
      "BLEU Paraphrase: 30.189\n",
      "BLEU LaBSE: 30.124 ❌\n",
      "\n",
      "flores-gpt-fi-es\n",
      "BLEU Paraphrase: 22.857\n",
      "BLEU LaBSE: 22.858 ❌\n",
      "\n",
      "flores-gpt-fi-pt\n",
      "BLEU Paraphrase: 32.266\n",
      "BLEU LaBSE: 32.265 ❌\n",
      "\n",
      "\n",
      "Mean Difference: 0.024\n",
      "Max Difference: 0.065\n",
      "Min Difference: 0.001\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import load_aligned_sents_from_file\n",
    "from scripts.scoring import compute_bleu\n",
    "from scripts.util import get_env_variables\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "paraphrase = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "laBSE = join(triplet_folder, 'aligned_triplets_no_sent_split_LaBSE')\n",
    "filenames = [f.replace('.jsonl', '') for f in os.listdir(laBSE)]\n",
    "diff_cnt = 0\n",
    "total_diff = 0\n",
    "max_diff = 0\n",
    "min_diff = 100\n",
    "for fn in filenames:\n",
    "    ref_sents_p, mt_sents_p = load_aligned_sents_from_file(\n",
    "        fn, folder=paraphrase, src_label='ref', tgt_label='mt')\n",
    "    ref_sents_l, mt_sents_l = load_aligned_sents_from_file(fn, folder=laBSE,\n",
    "                                                           src_label='ref', tgt_label='mt')\n",
    "    bleu_p = compute_bleu(ref_sents_p, mt_sents_p)\n",
    "    bleu_l = compute_bleu(ref_sents_l, mt_sents_l)\n",
    "    no_diff = bleu_l == bleu_p\n",
    "    if no_diff:\n",
    "        continue\n",
    "    else:\n",
    "        mark = '❌'\n",
    "        diff_cnt += 1\n",
    "        total_diff += abs(bleu_l - bleu_p)\n",
    "        max_diff = max(max_diff, abs(bleu_l - bleu_p))\n",
    "        min_diff = min(min_diff, abs(bleu_l - bleu_p))\n",
    "        print(fn)\n",
    "        print(f'BLEU Paraphrase: {bleu_p:.3f}')\n",
    "        print(f'BLEU LaBSE: {bleu_l:.3f} {mark}')\n",
    "        print()\n",
    "\n",
    "\n",
    "print()\n",
    "print(f'Mean Difference: {total_diff/diff_cnt:.3f}')\n",
    "print(f'Max Difference: {max_diff:.3f}')\n",
    "print(f'Min Difference: {min_diff:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0657cf",
   "metadata": {},
   "source": [
    "* 6 out of 23 alignments yielded slightly different BLEU scores.\n",
    "* 4 out of 6 alignments were likely different because LaBSE aligned differently\n",
    "* **OVERALL CONCLUSION**: Using paraphrase-multilingual-MiniLM-L12-v2 for alignment instead of LaBSE should not be an issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c37cc",
   "metadata": {},
   "source": [
    "## Final Triplets\n",
    "* After doing these various alignment experiments, we can finally create our final triplets that we use for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb1aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d139a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "from scripts.util import get_env_variables\n",
    "triplet_folder = get_env_variables('TRIPLETS')\n",
    "\n",
    "direct_folder = join(triplet_folder, 'direct_triplets')\n",
    "direct_files = os.listdir(direct_folder)\n",
    "aligned_folder = join(triplet_folder, 'aligned_triplets_no_sent_split')\n",
    "dst_folder = join(triplet_folder, 'final_triplets')\n",
    "\n",
    "cases = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "         'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "case2cnt = {c: [] for c in cases}\n",
    "os.makedirs(dst_folder, exist_ok=True)\n",
    "for fn in direct_files:\n",
    "    name = fn.replace('.jsonl', '')\n",
    "    if name not in mismatches:\n",
    "        src_file = join(direct_folder, fn)\n",
    "    else:\n",
    "        src_file = join(aligned_folder, fn)\n",
    "\n",
    "    with open(src_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        key = re.search(r'\\w+-\\w+', fn).group(0)\n",
    "        case2cnt[key].append(len(lines))\n",
    "\n",
    "    dst_file = join(dst_folder, fn)\n",
    "    shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04e70380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "Counter({400: 96, 395: 5, 394: 4, 397: 3, 396: 2})\n",
      "\n",
      "ep-deepl\n",
      "Counter({400: 110})\n",
      "\n",
      "flores-gpt\n",
      "Counter({400: 109, 398: 1})\n",
      "\n",
      "flores-deepl\n",
      "Counter({400: 109, 399: 1})\n",
      "\n",
      "opus-gpt\n",
      "Counter({400: 19, 372: 1})\n",
      "\n",
      "opus-deepl\n",
      "Counter({400: 20})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for c, cnts in case2cnt.items():\n",
    "    print(c)\n",
    "    print(Counter(cnts))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
