{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b46162d",
   "metadata": {},
   "source": [
    "# Example \n",
    "* One possible way how the translation process can be conducted\n",
    "* `some_pairs` were chosen arbitarily, it shows that we can either try to translate all 110 pairs or we do it in batches, using multiple cells in the JupyterNotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9194c1",
   "metadata": {},
   "source": [
    "## Translation Task\n",
    "* Code used for translation, namely from `data_management`, `util`, `translators` and `task` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40a7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EPManager\n",
    "from scripts.translators import GPT4Client\n",
    "from scripts.util import MyLogger\n",
    "from os.path import join\n",
    "\n",
    "some_pairs = [\n",
    "    ('en', 'de'),\n",
    "    ('de', 'en'),\n",
    "]\n",
    "\n",
    "example_folder = 'exmpl' \n",
    "mt_folder = join(example_folder, 'gpt41') # store translation of specified translator\n",
    "dm = EPManager() # choose dataset, in this case EuroParl \n",
    "logger = MyLogger(logfile=join('exmpl', 'log.jsonl')) # setup logger\n",
    "client = GPT4Client(logger=logger)  # choose translator\n",
    "\n",
    "task = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder,\n",
    "    num_of_sents=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d456f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 translated from en to de\n",
      "50 translated from de to en\n"
     ]
    }
   ],
   "source": [
    "task.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f82345",
   "metadata": {},
   "source": [
    "### Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbce40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"en\", \"tgt_lang\": \"de\", \"start\": 1745406813.9225166, \"id\": \"bd108883-8a62-4471-be35-f07d8f34def4\", \"in_lines\": 50, \"in_sents\": 51, \"stamp\": \"2025-04-23 13:13:33.936517+02:00\", \"in_chars\": 6527, \"in_tiktoks\": 1329, \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"out_chars\": 7259, \"out_tiktoks\": 1589, \"out_sents\": 51, \"in_toks\": 1378, \"out_toks\": 1590, \"out_lines\": 50, \"end\": 1745406839.1053126, \"error\": null, \"error_msg\": null, \"time\": 25.182796001434326}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"de\", \"tgt_lang\": \"en\", \"start\": 1745406839.1353137, \"id\": \"656f6da5-024a-475c-a1bf-3e959f77e00c\", \"in_lines\": 50, \"in_sents\": 54, \"stamp\": \"2025-04-23 13:13:59.147312+02:00\", \"in_chars\": 7023, \"in_tiktoks\": 1546, \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"out_chars\": 6353, \"out_tiktoks\": 1325, \"out_sents\": 54, \"in_toks\": 1594, \"out_toks\": 1326, \"out_lines\": 50, \"end\": 1745406859.2175977, \"error\": null, \"error_msg\": null, \"time\": 20.082283973693848}\n"
     ]
    }
   ],
   "source": [
    "!cat $example_folder/log.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f80016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en de\n",
      "Estimated Cost:\t0.01537\n",
      "Real Cost:\t0.01548\n",
      "Ratio\t0.99315\n",
      "Est Difference Input\t-49\n",
      "Est Difference Output\t-1\n",
      "\n",
      "de en\n",
      "Estimated Cost:\t0.01369\n",
      "Real Cost:\t0.01380\n",
      "Ratio\t0.99246\n",
      "Est Difference Input\t-48\n",
      "Est Difference Output\t-1\n",
      "\n",
      "Total estimated cost:\t0.029061999999999998\n",
      "Total real cost:\t0.029272\n",
      "Ratio\t0.992825908718229\n"
     ]
    }
   ],
   "source": [
    "from scripts.stats import GPT41_RATE\n",
    "import json\n",
    "with open(join(example_folder, 'log.jsonl')) as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "total_est_cost = 0\n",
    "total_real_cost = 0\n",
    "for log in log_data:\n",
    "    print(log['src_lang'], log['tgt_lang'])\n",
    "    est_cost = GPT41_RATE[0]*log['in_tiktoks'] + GPT41_RATE[1]*log['out_tiktoks']\n",
    "    real_cost = GPT41_RATE[0]*log['in_toks']+GPT41_RATE[1]*log['out_toks']\n",
    "    ratio = est_cost / real_cost\n",
    "    total_est_cost+=est_cost\n",
    "    total_real_cost+=real_cost\n",
    "    \n",
    "    print(f'Estimated Cost:\\t{est_cost:.5f}')\n",
    "    print(f'Real Cost:\\t{real_cost:.5f}')\n",
    "    print(f'Ratio\\t{ratio:.5f}')\n",
    "    print(f'Est Difference Input\\t{log['in_tiktoks']-log['in_toks']}')\n",
    "    print(f'Est Difference Output\\t{log['out_tiktoks']-log['out_toks']}\\n')\n",
    "\n",
    "print(f'Total estimated cost:\\t{total_est_cost}')\n",
    "print(f'Total real cost:\\t{total_real_cost}')\n",
    "print(f'Ratio\\t{total_est_cost/total_real_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2321e",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7aae276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=100)\n",
    "    mt_sents = load_sents(mt_folder, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path=mt_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9a63b",
   "metadata": {},
   "source": [
    "## Eval\n",
    "* The eval code I use requires files in COMET format, i.e. JSONL with each object of format: \n",
    "    ```json\n",
    "    {\"mt\" : \"sent\", \"ref\" : \"sent\", \"src\" : \"sent\"}\n",
    "    ```\n",
    "* Locally, we only compute BLEU and chrF scores but we can later uploud these files on Colab and compute COMET and BERT-F1 scores as well.\n",
    "* Similar to post-processing, code can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aed6292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  de-en  30.641867  56.657114\n",
      "1  en-de  22.436096  54.381047\n"
     ]
    }
   ],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f = {f.replace('.jsonl', ''): join(mt_folder, f) for f in os.listdir(mt_folder) if f.endswith('.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
