{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1daa3d1",
   "metadata": {},
   "source": [
    "# Example Run\n",
    "* One possible way how the translation task can be conducted\n",
    "* In the real run, pairs will be chosen with reason and depending on the translator, we may run on batches of pairs or on all of them\n",
    "* In this Demo, we randomly choose some pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6228123",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ee179",
   "metadata": {},
   "source": [
    "* Code used for translation, namely from `data_management`, `util`, `translators` and `task` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPT4Client, DeeplClient\n",
    "from scripts.util import MyLogger\n",
    "from os.path import join\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "possible = [tuple(pair.split('-')) for pair in EuroParlManager.EP_PAIRS]\n",
    "extended = [(pair[1], pair[0]) for pair in possible]\n",
    "possible = possible + extended\n",
    "some_pairs = sample(sorted(possible), k=8)\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "mt_folder_gpt = join(example_folder, 'gpt41')\n",
    "mt_folder_deepl = join(example_folder, 'deepl')\n",
    "\n",
    "dm = EuroParlManager()  \n",
    "logger = MyLogger(logfile=join('exmpl', 'log.jsonl')) \n",
    "client_gpt = GPT4Client(logger=logger)  \n",
    "client_deepl = DeeplClient(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3ea07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nl', 'de'),\n",
       " ('de', 'fi'),\n",
       " ('da', 'es'),\n",
       " ('pt', 'es'),\n",
       " ('en', 'fr'),\n",
       " ('en', 'de'),\n",
       " ('el', 'pt'),\n",
       " ('de', 'nl')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=50\n",
    ")\n",
    "\n",
    "task_deepl = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_deepl,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_deepl,\n",
    "    num_of_sents=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576c84d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair nl-de has been translated already.\n",
      "50 translated from nl to de\n",
      "Document for pair de-fi has been translated already.\n",
      "50 translated from de to fi\n",
      "Document for pair da-es has been translated already.\n",
      "50 translated from da to es\n",
      "Document for pair pt-es has been translated already.\n",
      "50 translated from pt to es\n",
      "Document for pair en-fr has been translated already.\n",
      "50 translated from en to fr\n",
      "Document for pair en-de has been translated already.\n",
      "50 translated from en to de\n",
      "Document for pair el-pt has been translated already.\n",
      "50 translated from el to pt\n",
      "Document for pair de-nl has been translated already.\n",
      "50 translated from de to nl\n"
     ]
    }
   ],
   "source": [
    "task_deepl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair nl-de has been translated already.\n",
      "50 translated from nl to de\n",
      "Document for pair de-fi has been translated already.\n",
      "50 translated from de to fi\n",
      "Document for pair da-es has been translated already.\n",
      "50 translated from da to es\n",
      "Document for pair pt-es has been translated already.\n",
      "50 translated from pt to es\n",
      "Document for pair en-fr has been translated already.\n",
      "50 translated from en to fr\n",
      "Document for pair en-de has been translated already.\n",
      "50 translated from en to de\n",
      "Document for pair el-pt has been translated already.\n",
      "50 translated from el to pt\n",
      "Document for pair de-nl has been translated already.\n",
      "50 translated from de to nl\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f630ea4",
   "metadata": {},
   "source": [
    "* \"has been translated already\" shows up because the code checks the `mt_folder` for existing files and if it finds them, it will not make the API call\n",
    "* Makes it overall safer to run API-call code within Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a44ae",
   "metadata": {},
   "source": [
    "## Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9fc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"translator\": \"deepl_document\", \"src_lang\": \"nl\", \"tgt_lang\": \"de\", \"start\": 1745503704.618983, \"id\": \"56b7f065-4230-4cc4-99aa-54aa00e459b2\", \"in_lines\": 50, \"in_sents\": 56, \"timestamp\": \"2025-04-24 16:08:24.635019+02:00\", \"in_chars\": 7097, \"in_tokens\": 1561, \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"end\": 1745503710.2351432, \"time\": 5.616160154342651, \"out_chars\": 7092, \"out_lines\": 50, \"out_sents\": 56, \"out_tokens\": 1533, \"status\": \"done\", \"error_msg\": null}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"de\", \"tgt_lang\": \"nl\", \"start\": 1745503943.4546154, \"id\": \"63441a16-ae9d-433b-8a44-e7adf2ed54fc\", \"in_lines\": 50, \"in_sents\": 53, \"timestamp\": \"2025-04-24 16:12:23.465651+02:00\", \"in_chars\": 6889, \"in_tokens\": 1516, \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"end\": 1745503963.2170389, \"time\": 19.762423515319824, \"out_chars\": 6836, \"out_lines\": 50, \"out_sents\": 53, \"out_tokens\": 1542, \"in_model_tokens\": 1565, \"out_model_tokens\": 1543, \"finish_reason\": \"stop\"}\n"
     ]
    }
   ],
   "source": [
    "!cat $example_folder/log.jsonl | head -n 1\n",
    "!cat $example_folder/log.jsonl | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaec3a2",
   "metadata": {},
   "source": [
    "* Logs for DeepL and GPT4.1 can differ based on what the respective API provides in the response body.\n",
    "* DeepL provides a `\"status\"` field that contains values such as `done`, indicating us that the request has been processed fully.\n",
    "* GPT4.1's response body contains the actual tokens it used, we estimate them using tiktoken, and also a `\"finish_reason\"`, which tells us that the output came from a request that was processed fully. If the value was `\"length\"` instead of `\"stop\"`, then that would mean the output was likely cut off due to the rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad7e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total est. cost:\t0.1289\n",
      "Total real cost:\t0.1298\n",
      "Ratio\t0.9934\n"
     ]
    }
   ],
   "source": [
    "from scripts.stats import GPT41_RATE\n",
    "import json\n",
    "with open(join(example_folder, 'log.jsonl')) as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "total_est_cost = 0\n",
    "total_real_cost = 0\n",
    "for log in log_data:\n",
    "    if log['translator'] == 'gpt-4.1':\n",
    "        est_cost = GPT41_RATE[0]*log['in_tokens'] + GPT41_RATE[1]*log['out_tokens']\n",
    "        real_cost = GPT41_RATE[0]*log['in_model_tokens'] + \\\n",
    "            GPT41_RATE[1]*log['out_model_tokens']\n",
    "        ratio = est_cost / real_cost\n",
    "        total_est_cost += est_cost\n",
    "        total_real_cost += real_cost\n",
    "print(f'Total est. cost:\\t{total_est_cost:.4f}')\n",
    "print(f'Total real cost:\\t{total_real_cost:.4f}')\n",
    "print(f'Ratio\\t{total_est_cost/total_real_cost:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3509b",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=50)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=50)\n",
    "    mt_sents = load_sents(mt_folder_deepl, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_deepl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53338f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mt\": \"Istunnon jatkaminen\", \"ref\": \"Istuntokauden uudelleenavaaminen\", \"src\": \"Wiederaufnahme der Sitzungsperiode\"}\n"
     ]
    }
   ],
   "source": [
    "# Example of direct aligned sentences and translaitons\n",
    "!cat tmp_deepl/de-fi.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c350b",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_deepl = {f.replace('.jsonl', ''): join('tmp_deepl', f) for f in os.listdir('tmp_deepl') if f.endswith('.jsonl')}\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "\n",
    "rp_deepl = ResultProducer(label2files=l2f_deepl)\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_deepl.compute_results()\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  da-es  33.483544  58.715067\n",
      "1  de-fi  22.054097  55.634523\n",
      "2  de-nl  28.670945  55.509332\n",
      "3  el-pt  34.546446  59.584432\n",
      "4  en-de  26.702647  57.385844\n",
      "5  en-fr  39.130502  63.101555\n",
      "6  nl-de  22.364264  52.949496\n",
      "7  pt-es  37.786870  62.199097\n",
      "\n",
      "   Label       BLEU       chrF\n",
      "0  da-es  30.808541  57.883883\n",
      "1  de-fi  16.372493  51.396547\n",
      "2  de-nl  21.865457  51.125152\n",
      "3  el-pt  33.344611  58.294434\n",
      "4  en-de  22.727958  54.300195\n",
      "5  en-fr  32.233153  59.738210\n",
      "6  nl-de  18.566548  52.401442\n",
      "7  pt-es  33.013480  61.545275\n"
     ]
    }
   ],
   "source": [
    "rp_deepl.display_results()\n",
    "print()\n",
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71372b03",
   "metadata": {},
   "source": [
    "## Effect of Bertalign\n",
    "* In the following, we show a case were Bertalign is used to fix alignments\n",
    "* In this example this is redundant but we can still observe an effect nevertheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79784934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('de', 'fi', num_of_sents=50)\n",
    "\n",
    "with open(join(mt_folder_gpt, 'de-fi.txt'), 'r') as f:\n",
    "    mt_sents = [ln.strip() for ln in f]\n",
    "\n",
    "len(mt_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20720ff3",
   "metadata": {},
   "source": [
    "* `mt_sents` is 50 because the GPT translator's output was good. In some cases, it can go wrong and in those cases, bertalign may be required.\n",
    "* Here, we just re-align something that is already considered aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8d3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language: de, Number of sentences: 55\n",
      "Target language: fi, Number of sentences: 55\n",
      "Embedding source and target text using paraphrase-multilingual-MiniLM-L12-v2 ...\n",
      "Performing first-step alignment ...\n",
      "Performing second-step alignment ...\n",
      "Finished! Successfully aligned 55 de sentences to 55 fi sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import align_src_mt_sents\n",
    "_ = align_src_mt_sents(\n",
    "    src_lang='de',\n",
    "    mt_lang='fi',\n",
    "    src_sents=src_sents,\n",
    "    mt_sents=mt_sents,\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3f2f8",
   "metadata": {},
   "source": [
    "* Bertalign detected 55 sentences, this is because one **line** can contain multiple sentences\n",
    "* Can be either because many-to-one alignments or corpus authors made blunders\n",
    "* For evaluation, the impact of this should not be too severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf929327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 sents aligned for de and fi\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "\n",
    "with open(join('tmp', 'de-fi.de'), 'r') as f:\n",
    "    src_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp', 'de-fi.fi'), 'r') as f:\n",
    "    mt_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    src_lang='de',\n",
    "    ref_lang='fi',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1d7b",
   "metadata": {},
   "source": [
    "* Bertalign detected 55 sentences in both languages but when we tried to re-align the triplets, there were sentences that were left empty\n",
    "* Those sentences were removed, resulting only in 47 aligned sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f57e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  de-fi  15.560334  50.320907\n"
     ]
    }
   ],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "l2f = {'de-fi' : join('tmp', 'de-fi.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d0b9",
   "metadata": {},
   "source": [
    "* There is a visible impact on BLEU score but this is also because we're working only with 47-55 sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
