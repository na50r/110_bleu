{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b46162d",
   "metadata": {},
   "source": [
    "# Example \n",
    "* One possible way how the translation process can be conducted\n",
    "* `some_pairs` were chosen arbitarily, it shows that we can either try to translate all 110 pairs or we do it in batches, using multiple cells in the JupyterNotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9194c1",
   "metadata": {},
   "source": [
    "## Translation Task\n",
    "* Code used for translation, namely from `data_management`, `util` and `translators` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40a7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_management import EPManager\n",
    "from scripts.util import MyLogger, load_sents\n",
    "from scripts.translators import translate_document\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "os.makedirs(example_folder, exist_ok=True)\n",
    "logger = MyLogger(logfile=join('exmpl', 'log.jsonl'))\n",
    "dm = EPManager()\n",
    "\n",
    "def translation_loop(target_pairs, translator, mt_folder):\n",
    "    for pair in target_pairs:\n",
    "        src_lang, tgt_lang = pair\n",
    "        src_sents, _ = dm.get_sentence_pairs(\n",
    "            src_lang, tgt_lang, num_of_sents=100)\n",
    "        logger.add_dataset_info(name='ep', num_of_sents=100)\n",
    "        try:\n",
    "            translate_document(\n",
    "                text=src_sents,\n",
    "                src_lang=src_lang,\n",
    "                tgt_lang=tgt_lang,\n",
    "                logger=logger,\n",
    "                mt_folder=mt_folder,\n",
    "                translator=translator\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.log_error(\n",
    "                error=e,\n",
    "                src_lang=src_lang,\n",
    "                tgt_lang=tgt_lang,\n",
    "                translator=translator\n",
    "            )\n",
    "            print(str(e))\n",
    "            continue\n",
    "        mt_sents = load_sents(mt_folder, src_lang, tgt_lang)\n",
    "        print(f'{len(mt_sents)} translated from {src_lang} to {tgt_lang}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9db77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_pairs = [\n",
    "    ('en', 'de'),\n",
    "    ('de', 'en'),\n",
    "    ('el', 'de'),\n",
    "    ('es', 'en'),\n",
    "    ('fi', 'fr')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25dc7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair en-de has been translated already.\n",
      "100 translated from en to de\n",
      "Document for pair de-en has been translated already.\n",
      "100 translated from de to en\n",
      "Document for pair el-de has been translated already.\n",
      "100 translated from el to de\n",
      "Document for pair es-en has been translated already.\n",
      "100 translated from es to en\n",
      "Document for pair fi-fr has been translated already.\n",
      "100 translated from fi to fr\n"
     ]
    }
   ],
   "source": [
    "mt_folder = join(example_folder, 'gpt41')\n",
    "os.makedirs(mt_folder, exist_ok=True)\n",
    "\n",
    "translation_loop(\n",
    "    target_pairs=some_pairs,\n",
    "    translator='gpt-4.1',\n",
    "    mt_folder=mt_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f82345",
   "metadata": {},
   "source": [
    "### Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbce40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"en\", \"tgt_lang\": \"de\", \"start\": 1745152481.7342436, \"id\": \"9406b04b-f88f-45fe-a6bb-3fa46c5c210c\", \"in_lines\": 100, \"in_sents\": 105, \"stamp\": \"2025-04-20 14:34:41.760207+02:00\", \"in_chars\": 13477, \"in_tiktoks\": 2714, \"dataset\": {\"name\": \"ep\", \"num_of_sents\": 100, \"start_idx\": 0}, \"out_chars\": 14872, \"out_tiktoks\": 3202, \"out_sents\": 106, \"in_toks\": 2763, \"out_toks\": 3203, \"out_lines\": 100, \"end\": 1745152527.4710276, \"error\": null, \"error_msg\": null, \"time\": 45.73678398132324}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"de\", \"tgt_lang\": \"en\", \"start\": 1745152527.7747035, \"id\": \"386a77fe-0582-45fe-a67e-5c40fd448f52\", \"in_lines\": 100, \"in_sents\": 107, \"stamp\": \"2025-04-20 14:35:27.798743+02:00\", \"in_chars\": 14815, \"in_tiktoks\": 3199, \"dataset\": {\"name\": \"ep\", \"num_of_sents\": 100, \"start_idx\": 0}, \"out_chars\": 13403, \"out_tiktoks\": 2743, \"out_sents\": 107, \"in_toks\": 3247, \"out_toks\": 2744, \"out_lines\": 100, \"end\": 1745152566.1485453, \"error\": null, \"error_msg\": null, \"time\": 38.373841762542725}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"el\", \"tgt_lang\": \"de\", \"start\": 1745152566.4454925, \"id\": \"4c97831c-1669-49b8-a3b5-6bbef20f9019\", \"in_lines\": 100, \"in_sents\": 101, \"stamp\": \"2025-04-20 14:36:06.484494+02:00\", \"in_chars\": 16175, \"in_tiktoks\": 5637, \"dataset\": {\"name\": \"ep\", \"num_of_sents\": 100, \"start_idx\": 0}, \"out_chars\": 16549, \"out_tiktoks\": 3587, \"out_sents\": 102, \"in_toks\": 5686, \"out_toks\": 3588, \"out_lines\": 100, \"end\": 1745152603.320562, \"error\": null, \"error_msg\": null, \"time\": 36.87506937980652}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"es\", \"tgt_lang\": \"en\", \"start\": 1745152603.6457317, \"id\": \"a3b55cf2-e256-4298-a804-9fe75948a34f\", \"in_lines\": 100, \"in_sents\": 104, \"stamp\": \"2025-04-20 14:36:43.670733+02:00\", \"in_chars\": 15806, \"in_tiktoks\": 3385, \"dataset\": {\"name\": \"ep\", \"num_of_sents\": 100, \"start_idx\": 0}, \"out_chars\": 14740, \"out_tiktoks\": 2949, \"out_sents\": 102, \"in_toks\": 3433, \"out_toks\": 2950, \"out_lines\": 100, \"end\": 1745152641.3910103, \"error\": null, \"error_msg\": null, \"time\": 37.74527859687805}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"fi\", \"tgt_lang\": \"fr\", \"start\": 1745152641.6745286, \"id\": \"1f783255-320b-45bd-8dc1-a6f10311b7c3\", \"in_lines\": 100, \"in_sents\": 102, \"stamp\": \"2025-04-20 14:37:21.695562+02:00\", \"in_chars\": 15909, \"in_tiktoks\": 4533, \"dataset\": {\"name\": \"ep\", \"num_of_sents\": 100, \"start_idx\": 0}, \"out_chars\": 17025, \"out_tiktoks\": 3676, \"out_sents\": 102, \"in_toks\": 4582, \"out_toks\": 3677, \"out_lines\": 100, \"end\": 1745152686.2374272, \"error\": null, \"error_msg\": null, \"time\": 44.56289863586426}\n"
     ]
    }
   ],
   "source": [
    "!cat $example_folder/log.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f80016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en de\n",
      "Estimated Cost:\t0.03104\n",
      "Real Cost:\t0.03115\n",
      "Ratio\t0.99660\n",
      "Est Difference Input\t-49\n",
      "Est Difference Output\t-1\n",
      "\n",
      "de en\n",
      "Estimated Cost:\t0.02834\n",
      "Real Cost:\t0.02845\n",
      "Ratio\t0.99634\n",
      "Est Difference Input\t-48\n",
      "Est Difference Output\t-1\n",
      "\n",
      "el de\n",
      "Estimated Cost:\t0.03997\n",
      "Real Cost:\t0.04008\n",
      "Ratio\t0.99736\n",
      "Est Difference Input\t-49\n",
      "Est Difference Output\t-1\n",
      "\n",
      "es en\n",
      "Estimated Cost:\t0.03036\n",
      "Real Cost:\t0.03047\n",
      "Ratio\t0.99659\n",
      "Est Difference Input\t-48\n",
      "Est Difference Output\t-1\n",
      "\n",
      "fi fr\n",
      "Estimated Cost:\t0.03847\n",
      "Real Cost:\t0.03858\n",
      "Ratio\t0.99725\n",
      "Est Difference Input\t-49\n",
      "Est Difference Output\t-1\n",
      "\n",
      "Total estimated cost:\t0.168192\n",
      "Total real cost:\t0.168718\n",
      "Ratio\t0.9968823717682761\n"
     ]
    }
   ],
   "source": [
    "from scripts.stats import GPT41_RATE\n",
    "import json\n",
    "with open(join(example_folder, 'log.jsonl')) as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "total_est_cost = 0\n",
    "total_real_cost = 0\n",
    "for log in log_data:\n",
    "    print(log['src_lang'], log['tgt_lang'])\n",
    "    est_cost = GPT41_RATE[0]*log['in_tiktoks'] + GPT41_RATE[1]*log['out_tiktoks']\n",
    "    real_cost = GPT41_RATE[0]*log['in_toks']+GPT41_RATE[1]*log['out_toks']\n",
    "    ratio = est_cost / real_cost\n",
    "    total_est_cost+=est_cost\n",
    "    total_real_cost+=real_cost\n",
    "    \n",
    "    print(f'Estimated Cost:\\t{est_cost:.5f}')\n",
    "    print(f'Real Cost:\\t{real_cost:.5f}')\n",
    "    print(f'Ratio\\t{ratio:.5f}')\n",
    "    print(f'Est Difference Input\\t{log['in_tiktoks']-log['in_toks']}')\n",
    "    print(f'Est Difference Output\\t{log['out_tiktoks']-log['out_toks']}\\n')\n",
    "\n",
    "print(f'Total estimated cost:\\t{total_est_cost}')\n",
    "print(f'Total real cost:\\t{total_real_cost}')\n",
    "print(f'Ratio\\t{total_est_cost/total_real_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d2321e",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7aae276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=100)\n",
    "    mt_sents = load_sents(mt_folder, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path=mt_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9a63b",
   "metadata": {},
   "source": [
    "## Eval\n",
    "* The eval code I use requires files in COMET format, i.e. JSONL with each object of format: \n",
    "    ```json\n",
    "    {\"mt\" : \"sent\", \"ref\" : \"sent\", \"src\" : \"sent\"}\n",
    "    ```\n",
    "* Locally, we only compute BLEU and chrF scores but we can later uploud these files on Colab and compute COMET and BERT-F1 scores as well.\n",
    "* Similar to post-processing, code can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aed6292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  de-en  31.044467  58.292028\n",
      "1  el-de  28.888493  60.285039\n",
      "2  en-de  23.492979  56.414147\n",
      "3  es-en  37.936680  64.139182\n",
      "4  fi-fr  29.306910  58.440390\n"
     ]
    }
   ],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "l2f = {f.replace('.jsonl', ''): join(mt_folder, f) for f in os.listdir(mt_folder) if f.endswith('.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
