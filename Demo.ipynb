{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b8a97",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3a84",
   "metadata": {},
   "source": [
    "* Shows possible translation process using GPTClient\n",
    "* Some failures occured while making this Demo, act as good guideline on how to deal with failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6038e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt:\n",
      "You are a professional translation system.\n",
      "\n",
      "User Prompt:\n",
      "Translate the following $src_lang sentences into $tgt_lang.\n",
      "Please make sure to keep the same formatting, do not add more newlines.\n",
      "You are not allowed to omit anything.\n",
      "Here is the text:\n",
      "$text\n"
     ]
    }
   ],
   "source": [
    "from scripts.translators import GPTClient\n",
    "gpt = GPTClient()\n",
    "gpt.print_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fe3a8",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536aa0b7",
   "metadata": {},
   "source": [
    "* Setup the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient\n",
    "from scripts.logger import MyLogger\n",
    "from os.path import join\n",
    "\n",
    "some_pairs = [('en', 'de'), ('nl', 'da'), ('de', 'en'), ('fi', 'it')]\n",
    "\n",
    "example_folder = 'exampl'\n",
    "logfile = join(example_folder, 'log.jsonl')\n",
    "\n",
    "\n",
    "dm = EuroParlManager()\n",
    "logger = MyLogger(logfile=logfile)\n",
    "client_gpt = GPTClient(logger=logger)\n",
    "\n",
    "mt_folder_gpt = join(example_folder, client_gpt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=400,\n",
    "    acceptable_range=(360, 480)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔️]: 400 translated from en to de\n",
      "[✔️]: 400 translated from nl to da\n",
      "[✔️]: 400 translated from de to en\n",
      "[✔️]: 399 translated from fi to it\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215213f",
   "metadata": {},
   "source": [
    "* The selected pairs were not random; based on experiments with GPT4.1, we knew that they illustrate rather interesting cases\n",
    "* `fi-it` tends to return as 399 instead of 400. We consider this still sufficient for our purposes, hence we post-process it ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f3c89",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "* Phase1 and Phase2 will not involve Post-Processing directly, both are translation Phases.\n",
    "* In this Demo, we demonstrate how the Post-Processing process will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb2a69",
   "metadata": {},
   "source": [
    "### Dealing with Malformatted Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c192444",
   "metadata": {},
   "source": [
    "* The pair `fi-it` has 399 sentences, which is still sufficient for evaluation but cannot be directly aligned. \n",
    "* We use bertalign to correct the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2f6846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import align_sents\n",
    "from scripts.util import load_sents\n",
    "mt_sents = load_sents(mt_folder_gpt, 'fi', 'it')\n",
    "print(len(mt_sents))\n",
    "\n",
    "mt_sents = mt_sents[:50]\n",
    "# For demonstration, we run bertalign only on the first 50\n",
    "len(mt_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ad798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language: fi, Number of sentences: 53\n",
      "Target language: it, Number of sentences: 53\n",
      "Embedding source and target text using paraphrase-multilingual-MiniLM-L12-v2 ...\n",
      "Performing first-step alignment ...\n",
      "Performing second-step alignment ...\n",
      "Finished! Successfully aligned 53 fi sentences to 53 it sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('fi', 'it', num_of_sents=50)\n",
    "\n",
    "src_sents_a, mt_sents_a = align_sents(\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=mt_sents,\n",
    "    src_lang='fi',\n",
    "    tgt_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709009e",
   "metadata": {},
   "source": [
    "* Observe that 50 sents from the EuroParl corpus can refer 53 sents in reality\n",
    "* Can be caused due to 1-to-many alignments or author blunders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ccc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21af7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 sents aligned for fi and it\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_a,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    mt_sents_ali=mt_sents_a,\n",
    "    src_lang='fi',\n",
    "    ref_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f609abd",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd0caf",
   "metadata": {},
   "source": [
    "* Evaluation is done on JSONL files that are in COMET format, containing machine translation, reference and source text.\n",
    "* In this notebook we compute only BLEU scores but the format allows us to compute COMET scores as well (will be done on Google Colab due to requiremnt of GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4494fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mt\": \"Wiederaufnahme der Sitzung\", \"ref\": \"Wiederaufnahme der Sitzungsperiode\", \"src\": \"Resumption of the session\"}\n"
     ]
    }
   ],
   "source": [
    "!cat tmp_gpt/en-de.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "l2f_gpt['fi-it-fixed'] = join('tmp', 'fi-it.jsonl')\n",
    "\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Label       BLEU       chrF\n",
      "0        de-en  31.677294  58.751052\n",
      "1        en-de  27.283838  58.488010\n",
      "2        fi-it   7.446603  30.697216\n",
      "3        nl-da  28.834680  55.331243\n",
      "4  fi-it-fixed  19.624437  52.142536\n"
     ]
    }
   ],
   "source": [
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f6895",
   "metadata": {},
   "source": [
    "* We observed that the re-alignment will improve the BLEU score\n",
    "* It may be still low due to running it only on the first 50 rather than all roughly 400 sents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
