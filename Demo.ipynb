{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b8a97",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3a84",
   "metadata": {},
   "source": [
    "* Shows possible translation process using GPTClient\n",
    "* Some failures occured while making this Demo, act as good guideline on how to deal with failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6038e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following English sentences into German.\n",
      "Please make sure to keep the same formatting, do not add more newlines.\n",
      "You are not allowed to omit anything.\n",
      "Here is the text:\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "from scripts.translators import GPTClient\n",
    "gpt = GPTClient()\n",
    "print(gpt.user_prompt('en', 'de', 'Hello World'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fe3a8",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536aa0b7",
   "metadata": {},
   "source": [
    "* Setup the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient\n",
    "from scripts.logger import MyLogger\n",
    "from os.path import join\n",
    "from random import sample, seed\n",
    "\n",
    "some_pairs = [('da', 'en'), ('de', 'fr'), ('de', 'pt'), ('fi', 'it'), \n",
    "              ('fr', 'da'), ('it', 'pt'), ('nl', 'da'), ('sv', 'es')]\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "logfile = join(example_folder, 'log.jsonl')\n",
    "\n",
    "\n",
    "dm = EuroParlManager()\n",
    "logger = MyLogger(logfile=logfile)\n",
    "client_gpt = GPTClient(logger=logger)\n",
    "\n",
    "mt_folder_gpt = join(example_folder, client_gpt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair da-en has been translated already.\n",
      "400 translated from da to en\n",
      "Document for pair de-fr has been translated already.\n",
      "400 translated from de to fr\n",
      "Document for pair de-pt has been translated already.\n",
      "400 translated from de to pt\n",
      "Document for pair fi-it has been translated already.\n",
      "399 translated from fi to it\n",
      "Document for pair fr-da has been translated already.\n",
      "400 translated from fr to da\n",
      "Document for pair it-pt has been translated already.\n",
      "400 translated from it to pt\n",
      "Document for pair nl-da has been translated already.\n",
      "400 translated from nl to da\n",
      "Document for pair sv-es has been translated already.\n",
      "400 translated from sv to es\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()\n",
    "# This cell has be run in the past multiple times with provided input\n",
    "# See logs in log.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f3c89",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "* Phase1 and Phase2 will not involve Post-Processing directly, both are translation Phases.\n",
    "* In this Demo, we demonstrate how the Post-Processing process will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb2a69",
   "metadata": {},
   "source": [
    "### Dealing with Malformatted Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c192444",
   "metadata": {},
   "source": [
    "* The pair `fi-it` has 399 sentences, which is still sufficient for evaluation but cannot be directly aligned. \n",
    "* We use bertalign to correct the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2f6846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import align_sents\n",
    "from scripts.util import load_sents\n",
    "mt_sents = load_sents(mt_folder_gpt, 'fi', 'it')\n",
    "print(len(mt_sents))\n",
    "\n",
    "mt_sents = mt_sents[:50]\n",
    "# For demonstration, we run bertalign only on the first 50\n",
    "len(mt_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ad798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language: fi, Number of sentences: 53\n",
      "Target language: it, Number of sentences: 53\n",
      "Embedding source and target text using paraphrase-multilingual-MiniLM-L12-v2 ...\n",
      "Performing first-step alignment ...\n",
      "Performing second-step alignment ...\n",
      "Finished! Successfully aligned 53 fi sentences to 53 it sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('fi', 'it', num_of_sents=50)\n",
    "\n",
    "src_sents_a, mt_sents_a = align_sents(\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=mt_sents,\n",
    "    src_lang='fi',\n",
    "    tgt_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709009e",
   "metadata": {},
   "source": [
    "* Observe that 50 sents from the EuroParl corpus can refer 53 sents in reality\n",
    "* Can be caused due to 1-to-many alignments or author blunders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ccc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21af7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 sents aligned for fi and it\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_a,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    mt_sents_ali=mt_sents_a,\n",
    "    src_lang='fi',\n",
    "    ref_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f609abd",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd0caf",
   "metadata": {},
   "source": [
    "* Evaluation is done on JSONL files that are in COMET format, containing machine translation, reference and source text.\n",
    "* In this notebook we compute only BLEU scores but the format allows us to compute COMET scores as well (will be done on Google Colab due to requiremnt of GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mt\": \"Reprise de la p\\u00e9riode de session\", \"ref\": \"Reprise de la session\", \"src\": \"Wiederaufnahme der Sitzungsperiode\"}\n"
     ]
    }
   ],
   "source": [
    "!cat tmp_gpt/de-fr.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "l2f_gpt['fi-it-fixed'] = join('tmp', 'fi-it.jsonl')\n",
    "\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Label       BLEU       chrF\n",
      "0        da-en  34.999449  61.202820\n",
      "1        de-fr  30.537712  58.877412\n",
      "2        de-pt  26.598626  54.204422\n",
      "3        fi-it   7.331725  30.730069\n",
      "4        fr-da  32.340128  59.683924\n",
      "5        it-pt  26.317238  55.412811\n",
      "6        nl-da  29.005539  55.651123\n",
      "7        sv-es  31.480298  58.966272\n",
      "8  fi-it-fixed  20.754495  52.785338\n"
     ]
    }
   ],
   "source": [
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f6895",
   "metadata": {},
   "source": [
    "* We observed that the re-alignment will improve the BLEU score\n",
    "* It may be still low due to running it only on the first 50 rather than all roughly 400 sents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
