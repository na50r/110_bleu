{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1daa3d1",
   "metadata": {},
   "source": [
    "# Example Run\n",
    "* One possible way how the translation task can be conducted\n",
    "* In the real run, pairs will be chosen with reason and depending on the translator, we may run on batches of pairs or on all of them\n",
    "* In this Demo, we randomly choose some pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6228123",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ee179",
   "metadata": {},
   "source": [
    "* Code used for translation, namely from `data_management`, `util`, `translators` and `task` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient, DeeplClient\n",
    "from scripts.logger import MyLogger\n",
    "from os.path import join\n",
    "from random import sample, seed\n",
    "seed(64)\n",
    "possible = [tuple(pair.split('-')) for pair in EuroParlManager.EP_PAIRS]\n",
    "extended = [(pair[1], pair[0]) for pair in possible]\n",
    "possible = possible + extended\n",
    "some_pairs = sample(sorted(possible), k=4)\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "logfile = join(example_folder, 'log.jsonl')\n",
    "\n",
    "\n",
    "dm = EuroParlManager()\n",
    "logger = MyLogger(logfile=logfile)\n",
    "client_gpt = GPTClient(logger=logger)\n",
    "client_deepl = DeeplClient(logger=logger)\n",
    "\n",
    "mt_folder_gpt = join(example_folder, client_gpt.model)\n",
    "mt_folder_deepl = join(example_folder, client_deepl.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63eaa5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fr', 'da'), ('de', 'fr'), ('nl', 'da'), ('it', 'pt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=400\n",
    ")\n",
    "\n",
    "task_deepl = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_deepl,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_deepl,\n",
    "    num_of_sents=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576c84d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair fr-da has been translated already.\n",
      "400 translated from fr to da\n",
      "Document for pair de-fr has been translated already.\n",
      "400 translated from de to fr\n",
      "Document for pair nl-da has been translated already.\n",
      "400 translated from nl to da\n",
      "Document for pair it-pt has been translated already.\n",
      "400 translated from it to pt\n"
     ]
    }
   ],
   "source": [
    "task_deepl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair fr-da has been translated already.\n",
      "400 translated from fr to da\n",
      "Document for pair de-fr has been translated already.\n",
      "400 translated from de to fr\n",
      "Document for pair nl-da has been translated already.\n",
      "125 translated from nl to da\n",
      "Document for pair it-pt has been translated already.\n",
      "400 translated from it to pt\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f630ea4",
   "metadata": {},
   "source": [
    "* *Document for pair {src_lang}-{tgt_lang} has been translated already* shows up because the code checks the `mt_folder` for existing files and if it finds them, it will not call the API\n",
    "* Makes it overall safer to run API-calling code within Jupyter Notebooks, the notebook is re-runnable\n",
    "* **The choice of language pairs was actually non-trivial, we observed that occasionally, GPT4.1 does not return 400 sentences for pair nl-da, in such cases, we have to either check if 400 sentences are still present within 125 or run the task again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a44ae",
   "metadata": {},
   "source": [
    "## Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9fc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"git_hash\": \"3c7d40c\", \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 400, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"translation\": {\"translator\": \"gpt-4.1\", \"src_lang\": \"nl\", \"tgt_lang\": \"da\", \"start\": 1745938912.6919239, \"id\": \"c1328927-1072-457c-b64f-f02097d04639\", \"in_lines\": 400, \"in_sents\": 460, \"start_timestamp\": \"2025-04-29 17:01:52.804929+02:00\", \"in_chars\": 67089, \"in_tokens\": 14372, \"end\": 1745938977.7328722, \"end_timestamp\": \"2025-04-29 17:02:57.732872+02:00\", \"time\": 65.0409483909607, \"out_chars\": 17276, \"out_lines\": 125, \"out_sents\": 152, \"out_tokens\": 4627, \"in_model_tokens\": 14421, \"out_model_tokens\": 4628, \"finish_reason\": \"stop\"}}\n",
      "{\"git_hash\": \"3c7d40c\", \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 400, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"translation\": {\"translator\": \"gpt-4.1\", \"src_lang\": \"it\", \"tgt_lang\": \"pt\", \"start\": 1745938977.7837636, \"id\": \"7d87d2a8-8062-4c29-accf-21a35e0fb2c2\", \"in_lines\": 400, \"in_sents\": 431, \"start_timestamp\": \"2025-04-29 17:02:57.897768+02:00\", \"in_chars\": 71473, \"in_tokens\": 16921, \"end\": 1745939180.9423304, \"end_timestamp\": \"2025-04-29 17:06:20.942330+02:00\", \"time\": 203.15856671333313, \"out_chars\": 67985, \"out_lines\": 400, \"out_sents\": 431, \"out_tokens\": 14135, \"in_model_tokens\": 16971, \"out_model_tokens\": 14136, \"finish_reason\": \"stop\"}}\n"
     ]
    }
   ],
   "source": [
    "!cat $example_folder/log.jsonl | tail -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7da4a6",
   "metadata": {},
   "source": [
    "* Logs for DeepL and GPT4.1 can differ based on what the respective API provides in the response body.\n",
    "* DeepL provides a `\"status\"` field that contains values such as `done`, indicating us that the request has been processed fully.\n",
    "* GPT4.1's response body contains the actual tokens it used, we estimate them using tiktoken, and also a `\"finish_reason\"`, which tells us that the output came from a request that was processed fully. If the value was `\"length\"` instead of `\"stop\"`, then that would mean the output was likely cut off due to the rate lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d65a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 460, 125, 152, 'stop', 'c1328927-1072-457c-b64f-f02097d04639')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(logfile, 'r') as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "tl_log = log_data[-2]['translation']\n",
    "tl_log['in_lines'], tl_log['in_sents'], tl_log['out_lines'], tl_log['out_sents'], tl_log['finish_reason'], tl_log['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494cb3d",
   "metadata": {},
   "source": [
    "* `out_sents` contains the \"real number of sentences\" per \"sentence entry\" in the dataset. I.e., one sentence in the dataset can refer to multiple actual sentences if we apply a sentence splitter. \n",
    "* This can occur because the dataset authors made a mistake (usuing multiple sentences in one entry) or because of 1-to-many alignments.\n",
    "* Regardless, we observe that the 125 \"lines\" did not contain roughly 400 (+/-) sentences, which means GPT4.1 provided incomplete output and we have no choice but to re-run the translation. \n",
    "* This is somewhat of a mystery as well, as the finish reason should be `length` rather than `stop`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6e702",
   "metadata": {},
   "source": [
    "## Re-Running\n",
    "* In the following we demonstrate how the re-running practice is conducted. \n",
    "* In general, we re-run only AFTER all tasks have been completed rather than directly after the first completed task. \n",
    "* We do it directly here because it is a demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce8df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.logger import ReRun\n",
    "new_logger = MyLogger(logfile=logfile, rerun=ReRun(pairs=[('nl', 'da')], reasons=['output too small'], log_ids=[tl_log['id']]))\n",
    "client = GPTClient(logger=new_logger)\n",
    "task = TranslationTask(\n",
    "    target_pairs=[('nl', 'da')],\n",
    "    dm=dm,\n",
    "    client=client,\n",
    "    logger=new_logger,\n",
    "    mt_folder=join(mt_folder_gpt, 'rerun'),\n",
    "    num_of_sents=400,\n",
    "    rerun=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c932a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 translated from nl to da\n"
     ]
    }
   ],
   "source": [
    "task.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8558da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'log_id': 'c1328927-1072-457c-b64f-f02097d04639',\n",
       "  'reason': 'output too small'},\n",
       " {'translator': 'gpt-4.1',\n",
       "  'src_lang': 'nl',\n",
       "  'tgt_lang': 'da',\n",
       "  'start': 1745940064.5667317,\n",
       "  'id': 'de6e754d-35a8-4fb1-8950-7d8d527434b7',\n",
       "  'in_lines': 400,\n",
       "  'in_sents': 460,\n",
       "  'start_timestamp': '2025-04-29 17:21:04.743725+02:00',\n",
       "  'in_chars': 67089,\n",
       "  'in_tokens': 14372,\n",
       "  'end': 1745940158.0418706,\n",
       "  'end_timestamp': '2025-04-29 17:22:38.041870+02:00',\n",
       "  'time': 93.47513890266418,\n",
       "  'out_chars': 17345,\n",
       "  'out_lines': 126,\n",
       "  'out_sents': 153,\n",
       "  'out_tokens': 4651,\n",
       "  'in_model_tokens': 14421,\n",
       "  'out_model_tokens': 4652,\n",
       "  'finish_reason': 'stop'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(logfile, 'r') as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "log_data[-1]['rerun'], log_data[-1]['translation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3509b",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_deepl, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_deepl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53338f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of direct aligned sentences and translations in COMET format\n",
    "!cat tmp_deepl/de-fr.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c350b",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_deepl = {f.replace('.jsonl', ''): join('tmp_deepl', f) for f in os.listdir('tmp_deepl') if f.endswith('.jsonl')}\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "\n",
    "rp_deepl = ResultProducer(label2files=l2f_deepl)\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_deepl.compute_results()\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_deepl.display_results()\n",
    "print()\n",
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71372b03",
   "metadata": {},
   "source": [
    "## Effect of Bertalign\n",
    "* In the following, we show a case were Bertalign is used to fix alignments\n",
    "* In this example this is redundant but we can still observe an effect nevertheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79784934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('nl', 'da', num_of_sents=50)\n",
    "\n",
    "with open(join(mt_folder_gpt, 'nl-da.txt'), 'r') as f:\n",
    "    mt_sents = [ln.strip() for ln in f]\n",
    "\n",
    "print(len(mt_sents))\n",
    "mt_sents = mt_sents[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b12199",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp_src_ref/nl-da.nl\n",
    "!rm -rf tmp_src_ref/nl-da.da\n",
    "!rm -rf tmp_src_mt/nl-da.nl\n",
    "!rm -rf tmp_src_mt/nl-da.da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20720ff3",
   "metadata": {},
   "source": [
    "* `mt_sents` is 50 because the GPT translator's output was good. In some cases, it can go wrong and in those cases, bertalign may be required.\n",
    "* Here, we just re-align something that is already considered aligned. \n",
    "* The re-alignment requires us to re-align the original source with the reference and then align source with the machine translation\n",
    "* Then we just simply use the src as a key to align all three together with `post_triplet_align`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import align_sents\n",
    "_ = align_sents(\n",
    "    src_lang='nl',\n",
    "    tgt_lang='da',\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=tgt_sents,\n",
    "    folder_path='tmp_src_ref'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb2479",
   "metadata": {},
   "source": [
    "* 58 nl sents were aligned to 51 da sents implies:\n",
    "    * Some sents lost partners\n",
    "    * bertalign accounted for 1-to-many alignments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import align_sents\n",
    "_ = align_sents(\n",
    "    src_lang='nl',\n",
    "    tgt_lang='da',\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=mt_sents,\n",
    "    folder_path='tmp_src_mt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b887f9",
   "metadata": {},
   "source": [
    "* This time bertalign aligned 58 nl sents to 58 da sents\n",
    "* The original da sents were only 51 though\n",
    "* This implies that during triplet alignment, some sents will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf929327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "\n",
    "with open(join('tmp_src_ref', 'nl-da.nl'), 'r') as f:\n",
    "    src_sents_org = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_ref', 'nl-da.da'), 'r') as f:\n",
    "    tgt_sents_org = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_mt', 'nl-da.nl'), 'r') as f:\n",
    "    src_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_mt', 'nl-da.da'), 'r') as f:\n",
    "    mt_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents_org,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents_org,\n",
    "    src_lang='nl',\n",
    "    ref_lang='da',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1d7b",
   "metadata": {},
   "source": [
    "* It is noteworthy that we could in theory run this directly on the tgt_sents from the data manager rather than aligning twice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65599a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    src_lang='nl',\n",
    "    ref_lang='da',\n",
    "    folder_path='tmp_'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9598e",
   "metadata": {},
   "source": [
    "* But because the observed issue prior, it can result in more sentence loss. Hence for alignments, we do it twice to recover as many alignments as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "l2f = {'nl-da_full_fix': join('tmp', 'nl-da.jsonl'),\n",
    "       'nl-da_half_fix': join('tmp_', 'nl-da.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d0b9",
   "metadata": {},
   "source": [
    "* There is a visible impact on BLEU score but this is also because we're working only with 44-58 sentences\n",
    "* Observe how the full-fix brought us closer to the original case where 50 sents were aligned with 50 other sents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
