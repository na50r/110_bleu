{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1daa3d1",
   "metadata": {},
   "source": [
    "# Example Run\n",
    "* One possible way how the translation task can be conducted\n",
    "* In the real run, pairs will be chosen with reason and depending on the translator, we may run on batches of pairs or on all of them\n",
    "* In this Demo, we randomly choose some pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6228123",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ee179",
   "metadata": {},
   "source": [
    "* Code used for translation, namely from `data_management`, `util`, `translators` and `task` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient, DeeplClient\n",
    "from scripts.util import MyLogger\n",
    "from os.path import join\n",
    "from random import sample, seed\n",
    "seed(64)\n",
    "possible = [tuple(pair.split('-')) for pair in EuroParlManager.EP_PAIRS]\n",
    "extended = [(pair[1], pair[0]) for pair in possible]\n",
    "possible = possible + extended\n",
    "some_pairs = sample(sorted(possible), k=4)\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "mt_folder_gpt = join(example_folder, 'gpt41')\n",
    "mt_folder_deepl = join(example_folder, 'deepl')\n",
    "\n",
    "dm = EuroParlManager()  \n",
    "logger = MyLogger(logfile=join(example_folder, 'log.jsonl'))\n",
    "client_gpt = GPTClient(logger=logger)  \n",
    "client_deepl = DeeplClient(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3ea07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fr', 'da'), ('de', 'fr'), ('nl', 'da'), ('it', 'pt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=50\n",
    ")\n",
    "\n",
    "task_deepl = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_deepl,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_deepl,\n",
    "    num_of_sents=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576c84d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair fr-da has been translated already.\n",
      "50 translated from fr to da\n",
      "Document for pair de-fr has been translated already.\n",
      "50 translated from de to fr\n",
      "Document for pair nl-da has been translated already.\n",
      "50 translated from nl to da\n",
      "Document for pair it-pt has been translated already.\n",
      "50 translated from it to pt\n"
     ]
    }
   ],
   "source": [
    "task_deepl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document for pair fr-da has been translated already.\n",
      "50 translated from fr to da\n",
      "Document for pair de-fr has been translated already.\n",
      "50 translated from de to fr\n",
      "Document for pair nl-da has been translated already.\n",
      "50 translated from nl to da\n",
      "Document for pair it-pt has been translated already.\n",
      "50 translated from it to pt\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f630ea4",
   "metadata": {},
   "source": [
    "* *Document for pair {src_lang}-{tgt_lang} has been translated already* shows up because the code checks the `mt_folder` for existing files and if it finds them, it will not call the API\n",
    "* Makes it overall safer to run API-calling code within Jupyter Notebooks, the notebook is re-runnable\n",
    "\n",
    "**NOTE**: Everything that comes after this will NOT be part of the official translation task notebooks. \n",
    "* The translation tasks will be performed as soon as relevant code (`data_management.py`, `util.p`, `translators.py`, `task.py`) is deemed stable and safe enough. \n",
    "* The following will contain post-processing and analysis steps that belong to the second part of the project, where code can be still developed further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a44ae",
   "metadata": {},
   "source": [
    "## Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9fc245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"translator\": \"deepl_document\", \"src_lang\": \"fr\", \"tgt_lang\": \"da\", \"start\": 1745851892.2054236, \"id\": \"cb59119b-7f06-4fc1-9f83-a2d36957fb00\", \"in_lines\": 50, \"in_sents\": 54, \"timestamp\": \"2025-04-28 16:51:32.223822+02:00\", \"in_chars\": 7457, \"in_tokens\": 1644, \"git_hash\": \"76cf461\", \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"end\": 1745851898.7286563, \"time\": 6.523232698440552, \"out_chars\": 6571, \"out_lines\": 50, \"out_sents\": 53, \"out_tokens\": 1815, \"status\": \"done\", \"error_msg\": null}\n",
      "{\"translator\": \"gpt-4.1\", \"src_lang\": \"it\", \"tgt_lang\": \"pt\", \"start\": 1745852021.4017231, \"id\": \"9bf55f53-44ec-4351-90d3-a9ab01e2fc44\", \"in_lines\": 50, \"in_sents\": 53, \"timestamp\": \"2025-04-28 16:53:41.459331+02:00\", \"in_chars\": 7494, \"in_tokens\": 1823, \"git_hash\": \"76cf461\", \"dataset\": {\"name\": \"Helsinki-NLP/europarl\", \"num_of_sents\": 50, \"start_idx\": 0, \"split\": \"train[:500]\"}, \"end\": 1745852037.7404916, \"time\": 16.338768482208252, \"out_chars\": 7250, \"out_lines\": 50, \"out_sents\": 54, \"out_tokens\": 1557, \"in_model_tokens\": 1873, \"out_model_tokens\": 1558, \"finish_reason\": \"stop\"}\n"
     ]
    }
   ],
   "source": [
    "!cat $example_folder/log.jsonl | head -n 1\n",
    "!cat $example_folder/log.jsonl | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaec3a2",
   "metadata": {},
   "source": [
    "* Logs for DeepL and GPT4.1 can differ based on what the respective API provides in the response body.\n",
    "* DeepL provides a `\"status\"` field that contains values such as `done`, indicating us that the request has been processed fully.\n",
    "* GPT4.1's response body contains the actual tokens it used, we estimate them using tiktoken, and also a `\"finish_reason\"`, which tells us that the output came from a request that was processed fully. If the value was `\"length\"` instead of `\"stop\"`, then that would mean the output was likely cut off due to the rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad7e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total est. cost:\t0.0670\n",
      "Total real cost:\t0.0674\n",
      "Ratio\t0.9937\n"
     ]
    }
   ],
   "source": [
    "from scripts.stats import GPT41_RATE\n",
    "import json\n",
    "with open(join(example_folder, 'log.jsonl')) as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "total_est_cost = 0\n",
    "total_real_cost = 0\n",
    "for log in log_data:\n",
    "    if log['translator'] == 'gpt-4.1':\n",
    "        est_cost = GPT41_RATE[0]*log['in_tokens'] + GPT41_RATE[1]*log['out_tokens']\n",
    "        real_cost = GPT41_RATE[0]*log['in_model_tokens'] + \\\n",
    "            GPT41_RATE[1]*log['out_model_tokens']\n",
    "        total_est_cost += est_cost\n",
    "        total_real_cost += real_cost\n",
    "print(f'Total est. cost:\\t{total_est_cost:.4f}')\n",
    "print(f'Total real cost:\\t{total_real_cost:.4f}')\n",
    "print(f'Ratio\\t{total_est_cost/total_real_cost:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3509b",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=50)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=50)\n",
    "    mt_sents = load_sents(mt_folder_deepl, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_deepl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53338f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mt\": \"Reprise de la session\", \"ref\": \"Reprise de la session\", \"src\": \"Wiederaufnahme der Sitzungsperiode\"}\n"
     ]
    }
   ],
   "source": [
    "# Example of direct aligned sentences and translations in COMET format\n",
    "!cat tmp_deepl/de-fr.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c350b",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_deepl = {f.replace('.jsonl', ''): join('tmp_deepl', f) for f in os.listdir('tmp_deepl') if f.endswith('.jsonl')}\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "\n",
    "rp_deepl = ResultProducer(label2files=l2f_deepl)\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_deepl.compute_results()\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  de-fr  35.901115  60.228306\n",
      "1  fr-da  32.608040  58.539183\n",
      "2  it-pt  33.270872  57.956424\n",
      "3  nl-da  26.663987  54.279791\n",
      "\n",
      "   Label       BLEU       chrF\n",
      "0  de-fr  27.803709  55.916120\n",
      "1  fr-da  30.738095  56.870821\n",
      "2  it-pt  30.903444  56.830762\n",
      "3  nl-da  26.754190  52.946628\n"
     ]
    }
   ],
   "source": [
    "rp_deepl.display_results()\n",
    "print()\n",
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71372b03",
   "metadata": {},
   "source": [
    "## Effect of Bertalign\n",
    "* In the following, we show a case were Bertalign is used to fix alignments\n",
    "* In this example this is redundant but we can still observe an effect nevertheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79784934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('nl', 'da', num_of_sents=50)\n",
    "\n",
    "with open(join(mt_folder_gpt, 'nl-da.txt'), 'r') as f:\n",
    "    mt_sents = [ln.strip() for ln in f]\n",
    "\n",
    "len(mt_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b12199",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp/nl-da.nl\n",
    "!rm -rf tmp/nl-da.da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20720ff3",
   "metadata": {},
   "source": [
    "* `mt_sents` is 50 because the GPT translator's output was good. In some cases, it can go wrong and in those cases, bertalign may be required.\n",
    "* Here, we just re-align something that is already considered aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e8d3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language: nl, Number of sentences: 58\n",
      "Target language: da, Number of sentences: 58\n",
      "Embedding source and target text using paraphrase-multilingual-MiniLM-L12-v2 ...\n",
      "Performing first-step alignment ...\n",
      "Performing second-step alignment ...\n",
      "Finished! Successfully aligned 58 nl sentences to 58 da sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import align_src_mt_sents\n",
    "_ = align_src_mt_sents(\n",
    "    src_lang='nl',\n",
    "    mt_lang='da',\n",
    "    src_sents=src_sents,\n",
    "    mt_sents=mt_sents,\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3f2f8",
   "metadata": {},
   "source": [
    "* Bertalign detected 58 sentences, this is because one **line** can contain multiple sentences\n",
    "* Can be either because many-to-one alignments or corpus authors made blunders\n",
    "* For evaluation, the impact of this should not be too severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf929327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 sents aligned for nl and da\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "\n",
    "with open(join('tmp', 'nl-da.nl'), 'r') as f:\n",
    "    src_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp', 'nl-da.da'), 'r') as f:\n",
    "    mt_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    src_lang='nl',\n",
    "    ref_lang='da',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1d7b",
   "metadata": {},
   "source": [
    "* Bertalign detected 58 sentences in both languages but when we tried to re-align the triplets, there were sentences that were left empty\n",
    "* Those sentences were removed, resulting only in 44 aligned sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f57e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label       BLEU       chrF\n",
      "0  nl-da  28.385311  53.761071\n"
     ]
    }
   ],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "l2f = {'nl-da' : join('tmp', 'nl-da.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d0b9",
   "metadata": {},
   "source": [
    "* There is a visible impact on BLEU score but this is also because we're working only with 47-55 sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
