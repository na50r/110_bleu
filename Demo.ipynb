{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57b8a97",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad3a84",
   "metadata": {},
   "source": [
    "* Shows possible translation process using GPTClient\n",
    "* Some failures occured while making this Demo, act as good guideline on how to deal with failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6038e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following English sentences into German.\n",
      "Please make sure to keep the same formatting, do not add more newlines.\n",
      "You are not allowed to omit anything.\n",
      "Here is the text:\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "from scripts.translators import GPTClient\n",
    "gpt = GPTClient()\n",
    "print(gpt.user_prompt('en', 'de', 'Hello World'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fe3a8",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536aa0b7",
   "metadata": {},
   "source": [
    "* Setup the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient\n",
    "from scripts.logger import MyLogger\n",
    "from os.path import join\n",
    "from random import sample, seed\n",
    "\n",
    "some_pairs = [('en', 'de'), ('nl', 'da'), ('de', 'en'), ('fi', 'it')]\n",
    "\n",
    "example_folder = 'exampl'\n",
    "logfile = join(example_folder, 'log.jsonl')\n",
    "\n",
    "\n",
    "dm = EuroParlManager()\n",
    "logger = MyLogger(logfile=logfile)\n",
    "client_gpt = GPTClient(logger=logger)\n",
    "\n",
    "mt_folder_gpt = join(example_folder, client_gpt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔️]: 400 translated from en to de\n",
      "[❌]: Output for nl-da is not acceptable!\n",
      "[⏲️]: Retrying nl-da...\n",
      "[✔️]: 400 translated from nl to da\n",
      "[✔️]: 400 translated from de to en\n",
      "[✔️]: 399 translated from fi to it\n"
     ]
    }
   ],
   "source": [
    "task_gpt.run()\n",
    "# This cell has be run in the past multiple times with provided input\n",
    "# See logs in log.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215213f",
   "metadata": {},
   "source": [
    "* The selected pairs were not random; based on experiments with GPT4.1, we knew that they illustrate rather interesting cases\n",
    "* `nl-da` often returns insufficient number of sentences, not enough for us to post-process. Hence we call the API again (and again)\n",
    "* `fi-it` tends to return as 399 instead of 400. We consider this still sufficient for our purposes, hence we post-process it ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f3c89",
   "metadata": {},
   "source": [
    "## Post-Processing\n",
    "* Phase1 and Phase2 will not involve Post-Processing directly, both are translation Phases.\n",
    "* In this Demo, we demonstrate how the Post-Processing process will look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb2a69",
   "metadata": {},
   "source": [
    "### Dealing with Malformatted Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c192444",
   "metadata": {},
   "source": [
    "* The pair `fi-it` has 399 sentences, which is still sufficient for evaluation but cannot be directly aligned. \n",
    "* We use bertalign to correct the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2f6846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.post_process import align_sents\n",
    "from scripts.util import load_sents\n",
    "mt_sents = load_sents(mt_folder_gpt, 'fi', 'it')\n",
    "print(len(mt_sents))\n",
    "\n",
    "mt_sents = mt_sents[:50]\n",
    "# For demonstration, we run bertalign only on the first 50\n",
    "len(mt_sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ad798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source language: fi, Number of sentences: 53\n",
      "Target language: it, Number of sentences: 53\n",
      "Embedding source and target text using paraphrase-multilingual-MiniLM-L12-v2 ...\n",
      "Performing first-step alignment ...\n",
      "Performing second-step alignment ...\n",
      "Finished! Successfully aligned 53 fi sentences to 53 it sentences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('fi', 'it', num_of_sents=50)\n",
    "\n",
    "src_sents_a, mt_sents_a = align_sents(\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=mt_sents,\n",
    "    src_lang='fi',\n",
    "    tgt_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709009e",
   "metadata": {},
   "source": [
    "* Observe that 50 sents from the EuroParl corpus can refer 53 sents in reality\n",
    "* Can be caused due to 1-to-many alignments or author blunders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ccc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21af7e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 sents aligned for fi and it\n"
     ]
    }
   ],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_a,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    mt_sents_ali=mt_sents_a,\n",
    "    src_lang='fi',\n",
    "    ref_lang='it',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f609abd",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd0caf",
   "metadata": {},
   "source": [
    "* Evaluation is done on JSONL files that are in COMET format, containing machine translation, reference and source text.\n",
    "* In this notebook we compute only BLEU scores but the format allows us to compute COMET scores as well (will be done on Google Colab due to requiremnt of GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4494fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mt\": \"Wiederaufnahme der Sitzung\", \"ref\": \"Wiederaufnahme der Sitzungsperiode\", \"src\": \"Resumption of the session\"}\n"
     ]
    }
   ],
   "source": [
    "!cat tmp_gpt/en-de.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "l2f_gpt['fi-it-fixed'] = join('tmp', 'fi-it.jsonl')\n",
    "\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Label       BLEU       chrF\n",
      "0        de-en  31.936751  58.870155\n",
      "1        en-de  27.393981  58.559454\n",
      "2        fi-it   7.380175  30.666184\n",
      "3        nl-da  28.736205  55.242953\n",
      "4  fi-it-fixed  19.681201  52.423551\n"
     ]
    }
   ],
   "source": [
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f6895",
   "metadata": {},
   "source": [
    "* We observed that the re-alignment will improve the BLEU score\n",
    "* It may be still low due to running it only on the first 50 rather than all roughly 400 sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf17fb67",
   "metadata": {},
   "source": [
    "## Failures\n",
    "* For documentation purposes, cases where the call was successful but we received insufficient translations, we keep the translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c839b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-en.txt\n",
      "en-de.txt\n",
      "fi-it.txt\n",
      "nl-da.txt\n",
      "nl-da_fail1.txt\n"
     ]
    }
   ],
   "source": [
    "!ls exampl/gpt-4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e1843",
   "metadata": {},
   "source": [
    "* Default configurations for the tasks are:\n",
    "* 30 seconds retry delay, if call fails or has an error, we wait 30s before starting the next one.\n",
    "* 3 retries, if call fails or has an error, we retry 3 times before skipping the pair.\n",
    "* Margin of 20%, i.e. for n input sentences, we accept 0.8n or 1.2n output sentences, to account for cases where the model returns too much or too little."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
