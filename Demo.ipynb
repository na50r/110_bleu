{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1daa3d1",
   "metadata": {},
   "source": [
    "# Example Run\n",
    "* One possible way how the translation task can be conducted\n",
    "* In the real run, pairs will be chosen with reason and depending on the translator, we may run on batches of pairs or on all of them\n",
    "* In this Demo, we randomly choose some pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6228123",
   "metadata": {},
   "source": [
    "## Translation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ee179",
   "metadata": {},
   "source": [
    "* Code used for translation, namely from `data_management`, `util`, `translators` and `task` MUST NOT CHANGE mid or post translation.\n",
    "* It has to be decided at which commit code is considered `fixed` and after that those 3 files must remain untouched.\n",
    "* If Git still tracks changes, those changes may not impact anything that would make the code behave differently from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f66fff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.task import TranslationTask\n",
    "from scripts.data_management import EuroParlManager\n",
    "from scripts.translators import GPTClient, DeeplClient\n",
    "from scripts.logger import MyLogger\n",
    "from os.path import join\n",
    "\n",
    "some_pairs = [('de', 'en'), ('en', 'de'), ('en', 'el'), ('el', 'en')]\n",
    "\n",
    "example_folder = 'exmpl'\n",
    "mt_folder_gpt = join(example_folder, 'gpt41')\n",
    "mt_folder_deepl = join(example_folder, 'deepl')\n",
    "\n",
    "dm = EuroParlManager()  \n",
    "logfile_path = join(example_folder, 'log.jsonl')\n",
    "logger = MyLogger(logfile=logfile_path)\n",
    "\n",
    "\n",
    "client_gpt = GPTClient(logger=logger)  \n",
    "client_deepl = DeeplClient(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_gpt,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_gpt,\n",
    "    num_of_sents=400\n",
    ")\n",
    "\n",
    "task_deepl = TranslationTask(\n",
    "    target_pairs=some_pairs,\n",
    "    dm=dm,\n",
    "    client=client_deepl,\n",
    "    logger=logger,\n",
    "    mt_folder=mt_folder_deepl,\n",
    "    num_of_sents=400\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_deepl.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cadbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_gpt.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f630ea4",
   "metadata": {},
   "source": [
    "* *Document for pair {src_lang}-{tgt_lang} has been translated already* shows up because the code checks the `mt_folder` for existing files and if it finds them, it will not call the API\n",
    "* Makes it overall safer to run API-calling code within Jupyter Notebooks, the notebook is re-runnable\n",
    "\n",
    "**NOTE**: Everything that comes after this will NOT be part of the official translation task notebooks. \n",
    "* The translation tasks will be performed as soon as relevant code (`data_management.py`, `util.p`, `translators.py`, `task.py`) is deemed stable and safe enough. \n",
    "* The following will contain post-processing and analysis steps that belong to the second part of the project, where code can be still developed further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6e702",
   "metadata": {},
   "source": [
    "## Re-Running\n",
    "* In some cases, translations may fail and it may be required to redo the API call. To ensure transparancy, we account for this by implementing rigurous logging.\n",
    "* Let us assume that the translation for `de-en` by GPT4.1 only contains 200 lines opposed to 400. Let us also assume that these 200 lines correspond to roughly 200 sentences, certainly not roughly 400. \n",
    "* In some cases, GPT can place multiple sentences on the same line, in those cases we do not need to re-run the translation but can utilize bertalign to align the source and target sentences.\n",
    "* In such case, we do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(logfile_path, 'r') as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "for log in log_data:\n",
    "    tl_log = log['translation']\n",
    "    src_l = tl_log['src_lang']\n",
    "    tgt_l = tl_log['tgt_lang']\n",
    "    if src_l == 'de' and tgt_l == 'en':\n",
    "        print(tl_log['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.logger import ReRun\n",
    "new_logger = MyLogger(logfile=login_path), rerun=ReRun(pairs=[('de-en')], reasons=['logger demonstration'], log_ids=[]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a44ae",
   "metadata": {},
   "source": [
    "## Logs\n",
    "* We can print our logs within the notebook but it is safer to store them externally.\n",
    "* This notebook can be re-run post translation, API calls will not be made but the logs will change\n",
    "* External stored logs represent logs created at time of translation and can be viewed through Python or unix commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fc245",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $example_folder/log.jsonl | head -n 1\n",
    "!cat $example_folder/log.jsonl | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaec3a2",
   "metadata": {},
   "source": [
    "* Logs for DeepL and GPT4.1 can differ based on what the respective API provides in the response body.\n",
    "* DeepL provides a `\"status\"` field that contains values such as `done`, indicating us that the request has been processed fully.\n",
    "* GPT4.1's response body contains the actual tokens it used, we estimate them using tiktoken, and also a `\"finish_reason\"`, which tells us that the output came from a request that was processed fully. If the value was `\"length\"` instead of `\"stop\"`, then that would mean the output was likely cut off due to the rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.stats import GPT41_RATE\n",
    "import json\n",
    "with open(join(example_folder, 'log.jsonl')) as f:\n",
    "    log_data = [json.loads(ln) for ln in f]\n",
    "\n",
    "total_est_cost = 0\n",
    "total_real_cost = 0\n",
    "for log in log_data:\n",
    "    if log['translator'] == 'gpt-4.1':\n",
    "        est_cost = GPT41_RATE[0]*log['in_tokens'] + GPT41_RATE[1]*log['out_tokens']\n",
    "        real_cost = GPT41_RATE[0]*log['in_model_tokens'] + \\\n",
    "            GPT41_RATE[1]*log['out_model_tokens']\n",
    "        total_est_cost += est_cost\n",
    "        total_real_cost += real_cost\n",
    "print(f'Total est. cost:\\t{total_est_cost:.4f}')\n",
    "print(f'Total real cost:\\t{total_real_cost:.4f}')\n",
    "print(f'Ratio\\t{total_est_cost/total_real_cost:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3509b",
   "metadata": {},
   "source": [
    "# Post Processing\n",
    "* This example case was an ideal case, as the number of input and output remained the same. \n",
    "    * For DeepL this is likely. \n",
    "    * For GPT, this can also go wrong and we may get back malformatted output that we have to align again. \n",
    "* This is an ideal case, hence we perform a direct alignment. \n",
    "* Code for post-processing can change whenever, **last one committed counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d988b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align\n",
    "from scripts.util import load_sents\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_gpt, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_gpt'\n",
    "    )\n",
    "\n",
    "for pair in some_pairs:\n",
    "    s, t = pair\n",
    "    src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "    mt_sents = load_sents(mt_folder_deepl, s, t)\n",
    "    direct_triplet_align(\n",
    "        mt_sents=mt_sents,\n",
    "        ref_sents=tgt_sents,\n",
    "        src_sents=src_sents,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='tmp_deepl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53338f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of direct aligned sentences and translations in COMET format\n",
    "!cat tmp_deepl/de-fr.jsonl | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c350b",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f83b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "l2f_deepl = {f.replace('.jsonl', ''): join('tmp_deepl', f) for f in os.listdir('tmp_deepl') if f.endswith('.jsonl')}\n",
    "l2f_gpt = {f.replace('.jsonl', ''): join('tmp_gpt', f)\n",
    "             for f in os.listdir('tmp_gpt') if f.endswith('.jsonl')}\n",
    "\n",
    "\n",
    "rp_deepl = ResultProducer(label2files=l2f_deepl)\n",
    "rp_gpt = ResultProducer(label2files=l2f_gpt)\n",
    "rp_deepl.compute_results()\n",
    "rp_gpt.compute_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab353ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_deepl.display_results()\n",
    "print()\n",
    "rp_gpt.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71372b03",
   "metadata": {},
   "source": [
    "## Effect of Bertalign\n",
    "* In the following, we show a case were Bertalign is used to fix alignments\n",
    "* In this example this is redundant but we can still observe an effect nevertheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79784934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from scripts.data_management import EuroParlManager\n",
    "dm = EuroParlManager()\n",
    "src_sents, tgt_sents = dm.get_sentence_pairs('nl', 'da', num_of_sents=50)\n",
    "\n",
    "with open(join(mt_folder_gpt, 'nl-da.txt'), 'r') as f:\n",
    "    mt_sents = [ln.strip() for ln in f]\n",
    "\n",
    "print(len(mt_sents))\n",
    "mt_sents = mt_sents[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b12199",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp_src_ref/nl-da.nl\n",
    "!rm -rf tmp_src_ref/nl-da.da\n",
    "!rm -rf tmp_src_mt/nl-da.nl\n",
    "!rm -rf tmp_src_mt/nl-da.da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20720ff3",
   "metadata": {},
   "source": [
    "* `mt_sents` is 50 because the GPT translator's output was good. In some cases, it can go wrong and in those cases, bertalign may be required.\n",
    "* Here, we just re-align something that is already considered aligned. \n",
    "* The re-alignment requires us to re-align the original source with the reference and then align source with the machine translation\n",
    "* Then we just simply use the src as a key to align all three together with `post_triplet_align`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import align_sents\n",
    "_ = align_sents(\n",
    "    src_lang='nl',\n",
    "    tgt_lang='da',\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=tgt_sents,\n",
    "    folder_path='tmp_src_ref'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb2479",
   "metadata": {},
   "source": [
    "* 58 nl sents were aligned to 51 da sents implies:\n",
    "    * Some sents lost partners\n",
    "    * bertalign accounted for 1-to-many alignments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import align_sents\n",
    "_ = align_sents(\n",
    "    src_lang='nl',\n",
    "    tgt_lang='da',\n",
    "    src_sents=src_sents,\n",
    "    tgt_sents=mt_sents,\n",
    "    folder_path='tmp_src_mt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b887f9",
   "metadata": {},
   "source": [
    "* This time bertalign aligned 58 nl sents to 58 da sents\n",
    "* The original da sents were only 51 though\n",
    "* This implies that during triplet alignment, some sents will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf929327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import post_triplet_align\n",
    "\n",
    "with open(join('tmp_src_ref', 'nl-da.nl'), 'r') as f:\n",
    "    src_sents_org = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_ref', 'nl-da.da'), 'r') as f:\n",
    "    tgt_sents_org = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_mt', 'nl-da.nl'), 'r') as f:\n",
    "    src_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "with open(join('tmp_src_mt', 'nl-da.da'), 'r') as f:\n",
    "    mt_sents_ali = [ln.strip() for ln in f]\n",
    "\n",
    "\n",
    "post_triplet_align(\n",
    "    src_sents_org=src_sents_org,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents_org,\n",
    "    src_lang='nl',\n",
    "    ref_lang='da',\n",
    "    folder_path='tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1d7b",
   "metadata": {},
   "source": [
    "* It is noteworthy that we could in theory run this directly on the tgt_sents from the data manager rather than aligning twice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65599a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_triplet_align(\n",
    "    src_sents_org=src_sents,\n",
    "    src_sents_ali=src_sents_ali,\n",
    "    mt_sents_ali=mt_sents_ali,\n",
    "    ref_sents_org=tgt_sents,\n",
    "    src_lang='nl',\n",
    "    ref_lang='da',\n",
    "    folder_path='tmp_'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9598e",
   "metadata": {},
   "source": [
    "* But because the observed issue prior, it can result in more sentence loss. Hence for alignments, we do it twice to recover as many alignments as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "l2f = {'nl-da_full_fix': join('tmp', 'nl-da.jsonl'),\n",
    "       'nl-da_half_fix': join('tmp_', 'nl-da.jsonl')}\n",
    "rp = ResultProducer(label2files=l2f)\n",
    "rp.compute_results()\n",
    "rp.display_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d0b9",
   "metadata": {},
   "source": [
    "* There is a visible impact on BLEU score but this is also because we're working only with 44-58 sentences\n",
    "* Observe how the full-fix brought us closer to the original case where 50 sents were aligned with 50 other sents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
