{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57657ace",
   "metadata": {},
   "source": [
    "# GPT Testing\n",
    "* Showcases how different prompts affect the output\n",
    "* We choose the prompt used for `gpt1` using the model `gpt-4.1` as it seems to be the most stable\n",
    "* Note, some issues can be dealt with using `bertalign`, others can only be solved by re-running it, as GPT is never fully deterministic. \n",
    "* `temperature=0` makes it as close to determnistic as possible but random sampling is still present behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9570f7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 106, 105)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import FloresPlusManager\n",
    "from scripts.translators import GPTClient\n",
    "from scripts.util import MyLogger, LANG_ISO, split_sents\n",
    "from io import StringIO\n",
    "logfile = StringIO()\n",
    "logger = MyLogger(logfile=logfile)\n",
    "\n",
    "dm = FloresPlusManager()\n",
    "de_sents, en_sents = dm.get_sentence_pairs('de', 'en', num_of_sents=100)\n",
    "real_de_sents = split_sents('\\n'.join(de_sents), 'de')\n",
    "real_en_sents = split_sents('\\n'.join(en_sents), 'en')\n",
    "len(de_sents), len(en_sents), len(real_de_sents), len(real_en_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb187f",
   "metadata": {},
   "source": [
    "* Case1: Default Prompt, Include System & User prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb901575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 106)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt1 = GPTClient(logger=logger)\n",
    "out = gpt1.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352f166",
   "metadata": {},
   "source": [
    "* Case2: Includes only System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae29377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 106)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2 = GPTClient(logger=logger)\n",
    "gpt2.user_prompt = lambda src_lang, tgt_lang, text: text\n",
    "out = gpt2.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de8163",
   "metadata": {},
   "source": [
    "* Case3: Includes only modified System prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf4b56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 106)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt(src_lang, tgt_lang):\n",
    "    p1 = f\"You are a {LANG_ISO[src_lang]}-to-{LANG_ISO[tgt_lang]} translator.\"\n",
    "    p2 = f\"Please make sure to keep the same formatting, do not add more newlines.\"\n",
    "    return '\\n'.join([p1, p2])\n",
    "\n",
    "gpt3 = GPTClient(logger=logger)\n",
    "gpt3.user_prompt = lambda src_lang, tgt_lang, text: text\n",
    "gpt3.sys_prompt = sys_prompt\n",
    "\n",
    "out = gpt3.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7c0e6",
   "metadata": {},
   "source": [
    "* Case4: Default prompt but with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4395c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 104)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4 = GPTClient(logger=logger, model='gpt-4o')\n",
    "out = gpt4.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa466e",
   "metadata": {},
   "source": [
    "* Case5: Only System prompt with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42888fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 136)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt5 = GPTClient(logger=logger, model='gpt-4o')\n",
    "gpt5.user_prompt = lambda src_lang, tgt_lang, text: text\n",
    "out = gpt5.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd44166",
   "metadata": {},
   "source": [
    "* Case6: Only modified System prompt with GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9757db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 104)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sys_prompt(src_lang, tgt_lang):\n",
    "    p1 = f\"You are a {LANG_ISO[src_lang]}-to-{LANG_ISO[tgt_lang]} translator.\"\n",
    "    p2 = f\"Please make sure to keep the same formatting, do not add more newlines.\"\n",
    "    return '\\n'.join([p1, p2])\n",
    "\n",
    "gpt6 = GPTClient(logger=logger, model='gpt-4o')\n",
    "gpt6.user_prompt = lambda src_lang, tgt_lang, text: text\n",
    "gpt6.sys_prompt = sys_prompt\n",
    "\n",
    "out = gpt6.translate_document(\n",
    "    text=de_sents,\n",
    "    src_lang='de',\n",
    "    tgt_lang='en'\n",
    ")\n",
    "real_sents = split_sents('\\n'.join(out), 'en')\n",
    "len(out), len(real_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d3484",
   "metadata": {},
   "source": [
    "* This notebook also demonstrates how the logger can be used. In this case, a logfile does not exist and everything was stored in-memory within an `StringIO` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1  31.86s 100 100\n",
      "gpt-4.1  55.64s 100 100\n",
      "gpt-4.1  40.34s 100 100\n",
      "gpt-4o   39.95s 100 1\n",
      "gpt-4o   35.27s 100 63\n",
      "gpt-4o   33.22s 100 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "logfile_str = logfile.getvalue()\n",
    "log_data = [json.loads(ln) for ln in logfile_str.splitlines()]\n",
    "for log in log_data:\n",
    "    print(f\"{log['translator']:<8} {log['time']:.2f}s {log['in_lines']} {log['out_lines']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924dc85",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "* It is difficult to illustrate all possible variations of prompt-engineering issues we faced as they are not fully reproducible.\n",
    "* In some instances, they can be language-dependent but not for a specific language\n",
    "* In some instances, they are input-length depdendent, issue not observable for 50 sentences, may occur for 100 or 200 and etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
