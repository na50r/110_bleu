{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8e4a03",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "* Here we compute matrices of BLEU scores, first without any alignment, then with alignment. \n",
    "* `Preparation.ipynb` was run before to create the files within `translations`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828a766",
   "metadata": {},
   "source": [
    "## Direct Evaluation\n",
    "* Compute Scores immediately after translation\n",
    "* Assumption: Alignment was preserved by the translator, so we only need to create triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280ce76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "set1 = set(FloresPlusManager.get_pairs())\n",
    "set2 = set(EuroParlManager.get_pairs())\n",
    "set1==set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf96cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_management import EuroParlManager, FloresPlusManager, Opus100Manager\n",
    "parts = {\n",
    "    'opus': {'dm':Opus100Manager(), 'pairs':Opus100Manager.get_pairs()},\n",
    "    'ep': {'dm':EuroParlManager(), 'pairs':EuroParlManager.get_pairs()},\n",
    "    'flores': {'dm':FloresPlusManager(), 'pairs':FloresPlusManager.get_pairs()}\n",
    "}\n",
    "\n",
    "translators = ['gpt', 'deepl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e01dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.post_process import direct_triplet_align, load_sents_from_file\n",
    "from os.path import join\n",
    "\n",
    "for dataset, content in parts.items():\n",
    "    dm = content['dm']\n",
    "    pairs = content['pairs']\n",
    "    for pair in pairs:\n",
    "        s,t = pair\n",
    "        for translator in translators:\n",
    "            filename = f'{dataset}-{translator}-{s}-{t}'\n",
    "            mt_sents = load_sents_from_file(folder='translations', filename=filename)\n",
    "            src_sents, tgt_sents = dm.get_sentence_pairs(s, t, num_of_sents=400)\n",
    "            direct_triplet_align(\n",
    "                mt_sents=mt_sents,\n",
    "                src_sents=src_sents,\n",
    "                ref_sents=tgt_sents,\n",
    "                src_lang=s,\n",
    "                ref_lang=t,\n",
    "                folder_path='direct_triplets',\n",
    "                prefix=f'{dataset}-{translator}-'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "files = os.listdir('direct_triplets')\n",
    "os.makedirs('direct_results', exist_ok=True)\n",
    "\n",
    "result_setup = ['ep-gpt', 'ep-deepl', 'flores-gpt', 'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "for rs in result_setup:\n",
    "    l2f = {f.replace(f'{rs}-', '').replace('.jsonl', ''):join('direct_triplets', f) for f in files if f.startswith(rs)}\n",
    "    rp = ResultProducer(label2files=l2f)\n",
    "    rp.compute_results()\n",
    "    rp.store_results(join('direct_results', f'{rs}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75d7c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.scoring import create_matrix_from_csv\n",
    "res_files = os.listdir('direct_results')\n",
    "res2df = {f.replace('.csv', ''):{'file':join('direct_results', f), 'df':None} for f in res_files}\n",
    "\n",
    "for rs, content in res2df.items():\n",
    "    file_path = content['file']\n",
    "    df = create_matrix_from_csv(file_path)\n",
    "    res2df[rs]['df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e540c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  34.1  28.3  40.9  37.1  25.5  35.7  27.6  30.9  31.0  31.2\n",
      "de  35.0   NaN  26.4  37.7  36.1  24.6  37.8  27.2  28.3  31.0  30.0\n",
      "el  34.4  30.0   NaN  39.0  38.2  23.6  37.3  28.7  28.5  34.3  29.3\n",
      "en  37.5  32.5  30.8   NaN  41.1  24.4  38.5  29.2  32.2  34.2  32.3\n",
      "es  37.1  32.9  30.2  43.3   NaN  24.9  39.9  30.3  30.3  35.8  30.5\n",
      "fi  32.6  28.7  25.1  35.5  32.0   NaN  32.5  24.3  27.0  27.9  26.5\n",
      "fr  32.9  30.3  27.8  38.3  37.7  23.0   NaN  28.8  29.0  33.2  28.5\n",
      "it  29.1  26.5  25.5  33.2  34.7  19.8  33.3   NaN  26.3  30.0  24.2\n",
      "nl  28.7  25.3  22.1  31.2  29.1  19.5  29.8  23.7   NaN  26.4  23.6\n",
      "pt  32.7  30.7  28.7  37.2  39.1  23.2  39.1  28.8  28.7   NaN  27.9\n",
      "sv  36.1  30.6  27.7  39.9  35.0  22.4  34.8  27.4  29.3  31.2   NaN\n",
      "\n",
      "ep-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  34.1  27.4  34.3  33.5  21.6  31.9  19.9  26.5  26.2  29.3\n",
      "de  34.5   NaN  23.4   7.5  34.4   4.8  31.3  24.3  25.3  27.4  27.3\n",
      "el  32.5  27.9   NaN  34.1  37.6  19.8  36.1  11.5  12.9  30.0  27.2\n",
      "en  34.6  27.1  28.5   NaN  36.7   5.9  33.2  27.1  27.9  23.9  27.7\n",
      "es  36.4  32.4  15.4   2.4   NaN  19.2  36.0  28.3  15.1  32.2  28.0\n",
      "fi  29.0  26.4  22.9  31.8  29.8   NaN  30.5   7.2   6.7  24.9  24.4\n",
      "fr  33.0  28.9  28.1  33.9  37.5  18.7   NaN  27.1  27.2  27.4  27.2\n",
      "it  26.9  22.8  24.6  29.1  31.7  13.2  28.6   NaN  23.2  25.9  21.7\n",
      "nl  28.5  22.6  21.5  29.7  27.4  16.1  26.9  22.0   NaN  22.9  22.6\n",
      "pt  32.5  28.4  28.8  33.1  35.7   5.8  33.8  25.8  26.0   NaN  24.4\n",
      "sv  33.1  27.9  24.7  33.8  32.4   6.6  30.6  25.0  24.1  25.2   NaN\n",
      "\n",
      "flores-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  37.9  27.1  54.8  26.4  26.4  44.5  30.9  29.3  35.0  39.8\n",
      "de  41.1   NaN  25.4  49.2  24.9  25.9  41.5  30.7  28.6  33.3  37.3\n",
      "el  34.6  31.6   NaN  41.8  24.5  21.6  38.6  28.0  24.6  29.8  31.0\n",
      "en  50.6  44.4  30.6   NaN  28.7  29.8  52.4  34.8  32.4  42.3  47.1\n",
      "es  30.4  27.6  20.5  35.8   NaN  19.9  35.6  27.2  24.4  27.2  27.6\n",
      "fi  33.2  30.7  22.0  38.2  21.4   NaN  37.0  26.4  24.8  27.9  30.1\n",
      "fr  38.4  34.6  25.4  49.2  26.1  24.9   NaN  30.6  27.3  33.6  35.3\n",
      "it  31.3  29.5  22.1  37.3  24.2  20.6  36.9   NaN  23.9  27.8  29.1\n",
      "nl  31.4  29.9  20.5  36.5  23.1  21.5  35.0  26.2   NaN  27.5  28.2\n",
      "pt  39.7  36.6  26.3  53.7  25.9  24.6  44.2  31.0  27.1   NaN  37.1\n",
      "sv  43.1  37.5  26.7  53.6  25.6  25.6  45.0  31.1  28.5  35.0   NaN\n",
      "\n",
      "flores-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  38.9  25.1  51.7  26.8  25.4  43.6  29.6  28.9  42.0  39.0\n",
      "de  38.7   NaN  24.6  48.8  26.1  25.6  40.5  29.1  28.9  38.3  36.0\n",
      "el  34.8  32.4   NaN  43.6  25.2  22.5  39.1  25.6  26.4  35.9  32.4\n",
      "en  49.3  43.6  29.0   NaN  29.2  29.4  51.9  32.7  30.9  51.4  46.4\n",
      "es  28.6  28.3   0.2  36.0   NaN  19.2  32.3  21.7  23.1  24.3  27.3\n",
      "fi   0.3  30.0   0.2  39.7   0.7   NaN  36.2  25.8   0.6   0.6  27.6\n",
      "fr  36.7  34.9  24.7  49.7  26.6  24.4   NaN  26.5  26.7  40.0  35.3\n",
      "it  29.4  31.2  21.1  39.2  22.6  20.9   0.6   NaN  23.4  29.2  28.7\n",
      "nl  28.5  28.8  19.0  37.0  23.4  18.4  33.1  24.2   NaN  30.5  25.8\n",
      "pt  39.1  36.8  24.2  55.5  25.3  24.4  44.8  27.2  27.6   NaN  36.8\n",
      "sv  40.1  38.3  24.8  52.9  26.3  24.5  41.7  28.7  28.0  41.7   NaN\n",
      "\n",
      "opus-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN   NaN   NaN  40.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "de   NaN   NaN   NaN  36.3   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "el   NaN   NaN   NaN  34.7   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "en  38.9  32.4  29.2   NaN  40.0  25.1  40.3  34.2  32.1  34.2  34.0\n",
      "es   NaN   NaN   NaN  44.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fi   NaN   NaN   NaN  32.6   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fr   NaN   NaN   NaN  41.6   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "it   NaN   NaN   NaN  37.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "nl   NaN   NaN   NaN  33.9   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "pt   NaN   NaN   NaN  40.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "sv   NaN   NaN   NaN  36.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "\n",
      "opus-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN   NaN   NaN  37.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "de   NaN   NaN   NaN  10.7   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "el   NaN   NaN   NaN  33.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "en  35.5  31.0  28.3   NaN  39.3  20.2  36.0  32.3  30.3  29.6  30.5\n",
      "es   NaN   NaN   NaN  43.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fi   NaN   NaN   NaN  31.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fr   NaN   NaN   NaN  39.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "it   NaN   NaN   NaN  36.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "nl   NaN   NaN   NaN  31.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "pt   NaN   NaN   NaN   0.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "sv   NaN   NaN   NaN  34.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in res2df:\n",
    "    out = res2df[key]['df'].round(1)\n",
    "    print(key)\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e498461",
   "metadata": {},
   "source": [
    "* Now we can check if the pairs we assumed to be misaligned have very low BLEU scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe616dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "da-it: 19.91\n",
      "es-el: 15.40\n",
      "es-nl: 15.05\n",
      "it-fi: 13.18\n",
      "el-nl: 12.86\n",
      "el-it: 11.54\n",
      "de-en: 7.48\n",
      "fi-it: 7.24\n",
      "fi-nl: 6.73\n",
      "sv-fi: 6.63\n",
      "en-fi: 5.88\n",
      "pt-fi: 5.85\n",
      "de-fi: 4.77\n",
      "es-en: 2.41\n",
      "\n",
      "flores-gpt\n",
      "fi-es: 0.65\n",
      "it-fr: 0.62\n",
      "fi-nl: 0.60\n",
      "fi-pt: 0.58\n",
      "fi-da: 0.29\n",
      "es-el: 0.23\n",
      "fi-el: 0.22\n",
      "\n",
      "opus-gpt\n",
      "de-en: 10.65\n",
      "pt-en: 0.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "mismatches = {\n",
    "    'ep-gpt':[],\n",
    "    'flores-gpt':[],\n",
    "    'opus-gpt':[],\n",
    "}\n",
    "\n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines!=400:\n",
    "        score = res2df[key]['df'].loc[s, t]\n",
    "        mismatches[key].append((f'{s}-{t}', score))\n",
    "\n",
    "for key in mismatches:\n",
    "    print(key)\n",
    "    for item in sorted(mismatches[key], key=lambda x: x[1], reverse=True):\n",
    "        label, score = item\n",
    "        print(f'{label}: {score:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a10c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n",
      "0.29\n",
      "0.22\n",
      "0.65\n",
      "0.60\n",
      "0.58\n",
      "0.62\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "for prefix, info in prefix2file.items():\n",
    "    if prefix.startswith('flores-gpt'):\n",
    "        outlines = info['log']['out_lines']\n",
    "        if outlines != 400:\n",
    "            src_lang, tgt_lang = prefix.split('-')[2], prefix.split('-')[3]\n",
    "            score = res2df['flores-gpt']['df'].loc[src_lang, tgt_lang]\n",
    "            print(f'{score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2336cad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.65\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "for prefix, info in prefix2file.items():\n",
    "    if prefix.startswith('opus-gpt'):\n",
    "        outlines = info['log']['out_lines']\n",
    "        if outlines != 400:\n",
    "            src_lang, tgt_lang = prefix.split('-')[2], prefix.split('-')[3]\n",
    "            score = res2df['opus-gpt']['df'].loc[src_lang, tgt_lang]\n",
    "            print(f'{score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c93ce652",
   "metadata": {},
   "outputs": [],
   "source": [
    "check1 = res2df['ep-gpt']['df']\n",
    "check2 = res2df['ep-deepl']['df']\n",
    "\n",
    "check1_flat = check1.values.flatten()\n",
    "check2_flat = check2.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdc633ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.403131020989917, 28.320273995031453)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1.loc['da', 'el'], check2.loc['da', 'el']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad8f6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.403131020989917, 28.320273995031453)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1_flat[2], check2_flat[2] # flattens all values in 1D-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f382006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.61\n",
      "p-value: 0.000\n",
      "Pearson correlation: 0.80\n",
      "p-value: 0.000\n",
      "Pearson correlation: 0.30\n",
      "p-value: 0.206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "parts = ['ep', 'flores', 'opus']\n",
    "\n",
    "for part in parts:\n",
    "    gpt = f'{part}-gpt'\n",
    "    deepl = f'{part}-deepl'\n",
    "    gpt_df = res2df[gpt]['df']\n",
    "    deepl_df = res2df[deepl]['df']\n",
    "\n",
    "    gpt_flat = gpt_df.values.flatten()\n",
    "    deepl_flat = deepl_df.values.flatten()\n",
    "\n",
    "    mask = ~np.isnan(gpt_flat) & ~np.isnan(deepl_flat)\n",
    "\n",
    "    # Compute Pearson correlation\n",
    "    corr, pval = pearsonr(gpt_flat[mask], deepl_flat[mask])\n",
    "    print(f\"Pearson correlation: {corr:.2f}\")\n",
    "    print(f\"p-value: {pval:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75c4eb",
   "metadata": {},
   "source": [
    "## Post-Processed Evaluation\n",
    "* Alignment was conducted on Google Collab using `bertalign`\n",
    "* The notebook can be found [here](https://colab.research.google.com/drive/1xlwQPctsOGjZB2NpB9WNtzWPae_Oj4gt?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2c3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scripts.post_process import post_triplet_align, load_aligned_sents_from_file\n",
    "import os\n",
    "from os.path import join\n",
    "src2hyp_fo = 'source2translations'\n",
    "src2ref_fo = 'source2reference'\n",
    "\n",
    "files = [f.replace('.jsonl', '') for f in os.listdir(src2hyp_fo)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c406bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 sents aligned for da and de\n",
      "385 sents aligned for da and el\n",
      "384 sents aligned for da and en\n",
      "383 sents aligned for da and es\n",
      "387 sents aligned for da and fi\n",
      "384 sents aligned for da and fr\n",
      "363 sents aligned for da and it\n",
      "384 sents aligned for da and nl\n",
      "382 sents aligned for da and pt\n",
      "386 sents aligned for da and sv\n",
      "372 sents aligned for de and da\n",
      "366 sents aligned for de and el\n",
      "377 sents aligned for de and en\n",
      "369 sents aligned for de and es\n",
      "379 sents aligned for de and fi\n",
      "378 sents aligned for de and fr\n",
      "361 sents aligned for de and it\n",
      "372 sents aligned for de and nl\n",
      "369 sents aligned for de and pt\n",
      "370 sents aligned for de and sv\n",
      "394 sents aligned for el and da\n",
      "391 sents aligned for el and de\n",
      "392 sents aligned for el and en\n",
      "391 sents aligned for el and es\n",
      "395 sents aligned for el and fi\n",
      "391 sents aligned for el and fr\n",
      "376 sents aligned for el and it\n",
      "387 sents aligned for el and nl\n",
      "387 sents aligned for el and pt\n",
      "389 sents aligned for el and sv\n",
      "382 sents aligned for en and da\n",
      "386 sents aligned for en and de\n",
      "380 sents aligned for en and el\n",
      "377 sents aligned for en and es\n",
      "381 sents aligned for en and fi\n",
      "378 sents aligned for en and fr\n",
      "366 sents aligned for en and it\n",
      "377 sents aligned for en and nl\n",
      "379 sents aligned for en and pt\n",
      "378 sents aligned for en and sv\n",
      "390 sents aligned for es and da\n",
      "386 sents aligned for es and de\n",
      "386 sents aligned for es and el\n",
      "390 sents aligned for es and en\n",
      "392 sents aligned for es and fi\n",
      "389 sents aligned for es and fr\n",
      "374 sents aligned for es and it\n",
      "379 sents aligned for es and nl\n",
      "385 sents aligned for es and pt\n",
      "389 sents aligned for es and sv\n",
      "391 sents aligned for fi and da\n",
      "390 sents aligned for fi and de\n",
      "386 sents aligned for fi and el\n",
      "386 sents aligned for fi and en\n",
      "388 sents aligned for fi and es\n",
      "392 sents aligned for fi and fr\n",
      "367 sents aligned for fi and it\n",
      "383 sents aligned for fi and nl\n",
      "386 sents aligned for fi and pt\n",
      "384 sents aligned for fi and sv\n",
      "389 sents aligned for fr and da\n",
      "391 sents aligned for fr and de\n",
      "381 sents aligned for fr and el\n",
      "383 sents aligned for fr and en\n",
      "387 sents aligned for fr and es\n",
      "390 sents aligned for fr and fi\n",
      "372 sents aligned for fr and it\n",
      "379 sents aligned for fr and nl\n",
      "383 sents aligned for fr and pt\n",
      "388 sents aligned for fr and sv\n",
      "377 sents aligned for it and da\n",
      "378 sents aligned for it and de\n",
      "375 sents aligned for it and el\n",
      "378 sents aligned for it and en\n",
      "380 sents aligned for it and es\n",
      "374 sents aligned for it and fi\n",
      "378 sents aligned for it and fr\n",
      "378 sents aligned for it and nl\n",
      "370 sents aligned for it and pt\n",
      "377 sents aligned for it and sv\n",
      "343 sents aligned for nl and da\n",
      "342 sents aligned for nl and de\n",
      "339 sents aligned for nl and el\n",
      "339 sents aligned for nl and en\n",
      "338 sents aligned for nl and es\n",
      "345 sents aligned for nl and fi\n",
      "339 sents aligned for nl and fr\n",
      "328 sents aligned for nl and it\n",
      "336 sents aligned for nl and pt\n",
      "333 sents aligned for nl and sv\n",
      "388 sents aligned for pt and da\n",
      "384 sents aligned for pt and de\n",
      "384 sents aligned for pt and el\n",
      "389 sents aligned for pt and en\n",
      "386 sents aligned for pt and es\n",
      "391 sents aligned for pt and fi\n",
      "390 sents aligned for pt and fr\n",
      "376 sents aligned for pt and it\n",
      "386 sents aligned for pt and nl\n",
      "388 sents aligned for pt and sv\n",
      "366 sents aligned for sv and da\n",
      "362 sents aligned for sv and de\n",
      "373 sents aligned for sv and el\n",
      "375 sents aligned for sv and en\n",
      "383 sents aligned for sv and es\n",
      "376 sents aligned for sv and fi\n",
      "381 sents aligned for sv and fr\n",
      "366 sents aligned for sv and it\n",
      "375 sents aligned for sv and nl\n",
      "378 sents aligned for sv and pt\n",
      "386 sents aligned for da and de\n",
      "387 sents aligned for da and el\n",
      "386 sents aligned for da and en\n",
      "386 sents aligned for da and es\n",
      "390 sents aligned for da and fi\n",
      "388 sents aligned for da and fr\n",
      "364 sents aligned for da and it\n",
      "383 sents aligned for da and nl\n",
      "384 sents aligned for da and pt\n",
      "388 sents aligned for da and sv\n",
      "368 sents aligned for de and da\n",
      "357 sents aligned for de and el\n",
      "368 sents aligned for de and en\n",
      "365 sents aligned for de and es\n",
      "371 sents aligned for de and fi\n",
      "369 sents aligned for de and fr\n",
      "347 sents aligned for de and it\n",
      "366 sents aligned for de and nl\n",
      "360 sents aligned for de and pt\n",
      "369 sents aligned for de and sv\n",
      "394 sents aligned for el and da\n",
      "391 sents aligned for el and de\n",
      "393 sents aligned for el and en\n",
      "391 sents aligned for el and es\n",
      "396 sents aligned for el and fi\n",
      "391 sents aligned for el and fr\n",
      "374 sents aligned for el and it\n",
      "388 sents aligned for el and nl\n",
      "387 sents aligned for el and pt\n",
      "389 sents aligned for el and sv\n",
      "382 sents aligned for en and da\n",
      "386 sents aligned for en and de\n",
      "380 sents aligned for en and el\n",
      "377 sents aligned for en and es\n",
      "381 sents aligned for en and fi\n",
      "379 sents aligned for en and fr\n",
      "366 sents aligned for en and it\n",
      "377 sents aligned for en and nl\n",
      "379 sents aligned for en and pt\n",
      "378 sents aligned for en and sv\n",
      "392 sents aligned for es and da\n",
      "388 sents aligned for es and de\n",
      "386 sents aligned for es and el\n",
      "390 sents aligned for es and en\n",
      "391 sents aligned for es and fi\n",
      "389 sents aligned for es and fr\n",
      "375 sents aligned for es and it\n",
      "382 sents aligned for es and nl\n",
      "385 sents aligned for es and pt\n",
      "388 sents aligned for es and sv\n",
      "389 sents aligned for fi and da\n",
      "390 sents aligned for fi and de\n",
      "384 sents aligned for fi and el\n",
      "383 sents aligned for fi and en\n",
      "386 sents aligned for fi and es\n",
      "387 sents aligned for fi and fr\n",
      "367 sents aligned for fi and it\n",
      "381 sents aligned for fi and nl\n",
      "384 sents aligned for fi and pt\n",
      "384 sents aligned for fi and sv\n",
      "388 sents aligned for fr and da\n",
      "391 sents aligned for fr and de\n",
      "382 sents aligned for fr and el\n",
      "383 sents aligned for fr and en\n",
      "387 sents aligned for fr and es\n",
      "390 sents aligned for fr and fi\n",
      "372 sents aligned for fr and it\n",
      "378 sents aligned for fr and nl\n",
      "383 sents aligned for fr and pt\n",
      "389 sents aligned for fr and sv\n",
      "377 sents aligned for it and da\n",
      "378 sents aligned for it and de\n",
      "375 sents aligned for it and el\n",
      "377 sents aligned for it and en\n",
      "380 sents aligned for it and es\n",
      "374 sents aligned for it and fi\n",
      "378 sents aligned for it and fr\n",
      "378 sents aligned for it and nl\n",
      "370 sents aligned for it and pt\n",
      "377 sents aligned for it and sv\n",
      "343 sents aligned for nl and da\n",
      "342 sents aligned for nl and de\n",
      "339 sents aligned for nl and el\n",
      "339 sents aligned for nl and en\n",
      "338 sents aligned for nl and es\n",
      "344 sents aligned for nl and fi\n",
      "338 sents aligned for nl and fr\n",
      "329 sents aligned for nl and it\n",
      "335 sents aligned for nl and pt\n",
      "333 sents aligned for nl and sv\n",
      "390 sents aligned for pt and da\n",
      "385 sents aligned for pt and de\n",
      "386 sents aligned for pt and el\n",
      "390 sents aligned for pt and en\n",
      "386 sents aligned for pt and es\n",
      "391 sents aligned for pt and fi\n",
      "391 sents aligned for pt and fr\n",
      "376 sents aligned for pt and it\n",
      "386 sents aligned for pt and nl\n",
      "389 sents aligned for pt and sv\n",
      "351 sents aligned for sv and da\n",
      "360 sents aligned for sv and de\n",
      "344 sents aligned for sv and el\n",
      "348 sents aligned for sv and en\n",
      "361 sents aligned for sv and es\n",
      "356 sents aligned for sv and fi\n",
      "351 sents aligned for sv and fr\n",
      "334 sents aligned for sv and it\n",
      "349 sents aligned for sv and nl\n",
      "348 sents aligned for sv and pt\n",
      "426 sents aligned for da and de\n",
      "420 sents aligned for da and el\n",
      "420 sents aligned for da and en\n",
      "417 sents aligned for da and es\n",
      "428 sents aligned for da and fi\n",
      "420 sents aligned for da and fr\n",
      "418 sents aligned for da and it\n",
      "418 sents aligned for da and nl\n",
      "420 sents aligned for da and pt\n",
      "418 sents aligned for da and sv\n",
      "419 sents aligned for de and da\n",
      "411 sents aligned for de and el\n",
      "411 sents aligned for de and en\n",
      "413 sents aligned for de and es\n",
      "421 sents aligned for de and fi\n",
      "412 sents aligned for de and fr\n",
      "411 sents aligned for de and it\n",
      "413 sents aligned for de and nl\n",
      "415 sents aligned for de and pt\n",
      "412 sents aligned for de and sv\n",
      "424 sents aligned for el and da\n",
      "424 sents aligned for el and de\n",
      "423 sents aligned for el and en\n",
      "417 sents aligned for el and es\n",
      "419 sents aligned for el and fi\n",
      "419 sents aligned for el and fr\n",
      "423 sents aligned for el and it\n",
      "413 sents aligned for el and nl\n",
      "423 sents aligned for el and pt\n",
      "421 sents aligned for el and sv\n",
      "427 sents aligned for en and da\n",
      "425 sents aligned for en and de\n",
      "425 sents aligned for en and el\n",
      "423 sents aligned for en and es\n",
      "427 sents aligned for en and fi\n",
      "426 sents aligned for en and fr\n",
      "424 sents aligned for en and it\n",
      "419 sents aligned for en and nl\n",
      "426 sents aligned for en and pt\n",
      "427 sents aligned for en and sv\n",
      "421 sents aligned for es and da\n",
      "419 sents aligned for es and de\n",
      "415 sents aligned for es and el\n",
      "421 sents aligned for es and en\n",
      "414 sents aligned for es and fi\n",
      "418 sents aligned for es and fr\n",
      "420 sents aligned for es and it\n",
      "412 sents aligned for es and nl\n",
      "424 sents aligned for es and pt\n",
      "418 sents aligned for es and sv\n",
      "412 sents aligned for fi and da\n",
      "411 sents aligned for fi and de\n",
      "398 sents aligned for fi and el\n",
      "406 sents aligned for fi and en\n",
      "406 sents aligned for fi and es\n",
      "406 sents aligned for fi and fr\n",
      "405 sents aligned for fi and it\n",
      "410 sents aligned for fi and nl\n",
      "403 sents aligned for fi and pt\n",
      "405 sents aligned for fi and sv\n",
      "423 sents aligned for fr and da\n",
      "425 sents aligned for fr and de\n",
      "418 sents aligned for fr and el\n",
      "423 sents aligned for fr and en\n",
      "417 sents aligned for fr and es\n",
      "423 sents aligned for fr and fi\n",
      "423 sents aligned for fr and it\n",
      "419 sents aligned for fr and nl\n",
      "421 sents aligned for fr and pt\n",
      "423 sents aligned for fr and sv\n",
      "421 sents aligned for it and da\n",
      "425 sents aligned for it and de\n",
      "423 sents aligned for it and el\n",
      "424 sents aligned for it and en\n",
      "422 sents aligned for it and es\n",
      "424 sents aligned for it and fi\n",
      "424 sents aligned for it and fr\n",
      "420 sents aligned for it and nl\n",
      "424 sents aligned for it and pt\n",
      "425 sents aligned for it and sv\n",
      "399 sents aligned for nl and da\n",
      "403 sents aligned for nl and de\n",
      "392 sents aligned for nl and el\n",
      "396 sents aligned for nl and en\n",
      "390 sents aligned for nl and es\n",
      "406 sents aligned for nl and fi\n",
      "398 sents aligned for nl and fr\n",
      "400 sents aligned for nl and it\n",
      "397 sents aligned for nl and pt\n",
      "394 sents aligned for nl and sv\n",
      "424 sents aligned for pt and da\n",
      "423 sents aligned for pt and de\n",
      "420 sents aligned for pt and el\n",
      "422 sents aligned for pt and en\n",
      "421 sents aligned for pt and es\n",
      "422 sents aligned for pt and fi\n",
      "420 sents aligned for pt and fr\n",
      "421 sents aligned for pt and it\n",
      "416 sents aligned for pt and nl\n",
      "422 sents aligned for pt and sv\n",
      "423 sents aligned for sv and da\n",
      "423 sents aligned for sv and de\n",
      "422 sents aligned for sv and el\n",
      "424 sents aligned for sv and en\n",
      "423 sents aligned for sv and es\n",
      "423 sents aligned for sv and fi\n",
      "421 sents aligned for sv and fr\n",
      "423 sents aligned for sv and it\n",
      "415 sents aligned for sv and nl\n",
      "423 sents aligned for sv and pt\n",
      "428 sents aligned for da and de\n",
      "420 sents aligned for da and el\n",
      "420 sents aligned for da and en\n",
      "418 sents aligned for da and es\n",
      "428 sents aligned for da and fi\n",
      "420 sents aligned for da and fr\n",
      "419 sents aligned for da and it\n",
      "418 sents aligned for da and nl\n",
      "422 sents aligned for da and pt\n",
      "420 sents aligned for da and sv\n",
      "420 sents aligned for de and da\n",
      "413 sents aligned for de and el\n",
      "413 sents aligned for de and en\n",
      "413 sents aligned for de and es\n",
      "421 sents aligned for de and fi\n",
      "412 sents aligned for de and fr\n",
      "412 sents aligned for de and it\n",
      "413 sents aligned for de and nl\n",
      "415 sents aligned for de and pt\n",
      "411 sents aligned for de and sv\n",
      "424 sents aligned for el and da\n",
      "422 sents aligned for el and de\n",
      "423 sents aligned for el and en\n",
      "416 sents aligned for el and es\n",
      "421 sents aligned for el and fi\n",
      "419 sents aligned for el and fr\n",
      "423 sents aligned for el and it\n",
      "413 sents aligned for el and nl\n",
      "423 sents aligned for el and pt\n",
      "423 sents aligned for el and sv\n",
      "427 sents aligned for en and da\n",
      "426 sents aligned for en and de\n",
      "424 sents aligned for en and el\n",
      "422 sents aligned for en and es\n",
      "427 sents aligned for en and fi\n",
      "426 sents aligned for en and fr\n",
      "424 sents aligned for en and it\n",
      "419 sents aligned for en and nl\n",
      "426 sents aligned for en and pt\n",
      "426 sents aligned for en and sv\n",
      "422 sents aligned for es and da\n",
      "422 sents aligned for es and de\n",
      "416 sents aligned for es and el\n",
      "421 sents aligned for es and en\n",
      "417 sents aligned for es and fi\n",
      "414 sents aligned for es and fr\n",
      "422 sents aligned for es and it\n",
      "411 sents aligned for es and nl\n",
      "424 sents aligned for es and pt\n",
      "418 sents aligned for es and sv\n",
      "414 sents aligned for fi and da\n",
      "414 sents aligned for fi and de\n",
      "403 sents aligned for fi and el\n",
      "408 sents aligned for fi and en\n",
      "404 sents aligned for fi and es\n",
      "409 sents aligned for fi and fr\n",
      "405 sents aligned for fi and it\n",
      "412 sents aligned for fi and nl\n",
      "408 sents aligned for fi and pt\n",
      "407 sents aligned for fi and sv\n",
      "423 sents aligned for fr and da\n",
      "425 sents aligned for fr and de\n",
      "418 sents aligned for fr and el\n",
      "423 sents aligned for fr and en\n",
      "417 sents aligned for fr and es\n",
      "424 sents aligned for fr and fi\n",
      "423 sents aligned for fr and it\n",
      "419 sents aligned for fr and nl\n",
      "421 sents aligned for fr and pt\n",
      "423 sents aligned for fr and sv\n",
      "423 sents aligned for it and da\n",
      "424 sents aligned for it and de\n",
      "421 sents aligned for it and el\n",
      "423 sents aligned for it and en\n",
      "421 sents aligned for it and es\n",
      "423 sents aligned for it and fi\n",
      "423 sents aligned for it and fr\n",
      "420 sents aligned for it and nl\n",
      "422 sents aligned for it and pt\n",
      "424 sents aligned for it and sv\n",
      "401 sents aligned for nl and da\n",
      "403 sents aligned for nl and de\n",
      "392 sents aligned for nl and el\n",
      "394 sents aligned for nl and en\n",
      "390 sents aligned for nl and es\n",
      "409 sents aligned for nl and fi\n",
      "396 sents aligned for nl and fr\n",
      "400 sents aligned for nl and it\n",
      "398 sents aligned for nl and pt\n",
      "393 sents aligned for nl and sv\n",
      "423 sents aligned for pt and da\n",
      "424 sents aligned for pt and de\n",
      "419 sents aligned for pt and el\n",
      "421 sents aligned for pt and en\n",
      "421 sents aligned for pt and es\n",
      "419 sents aligned for pt and fi\n",
      "419 sents aligned for pt and fr\n",
      "421 sents aligned for pt and it\n",
      "415 sents aligned for pt and nl\n",
      "421 sents aligned for pt and sv\n",
      "426 sents aligned for sv and da\n",
      "425 sents aligned for sv and de\n",
      "424 sents aligned for sv and el\n",
      "425 sents aligned for sv and en\n",
      "421 sents aligned for sv and es\n",
      "424 sents aligned for sv and fi\n",
      "422 sents aligned for sv and fr\n",
      "425 sents aligned for sv and it\n",
      "417 sents aligned for sv and nl\n",
      "425 sents aligned for sv and pt\n",
      "383 sents aligned for da and en\n",
      "394 sents aligned for de and en\n",
      "378 sents aligned for el and en\n",
      "382 sents aligned for en and da\n",
      "398 sents aligned for en and de\n",
      "372 sents aligned for en and el\n",
      "394 sents aligned for en and es\n",
      "361 sents aligned for en and fi\n",
      "390 sents aligned for en and fr\n",
      "383 sents aligned for en and it\n",
      "381 sents aligned for en and nl\n",
      "382 sents aligned for en and pt\n",
      "362 sents aligned for en and sv\n",
      "393 sents aligned for es and en\n",
      "374 sents aligned for fi and en\n",
      "397 sents aligned for fr and en\n",
      "395 sents aligned for it and en\n",
      "388 sents aligned for nl and en\n",
      "389 sents aligned for pt and en\n",
      "381 sents aligned for sv and en\n",
      "384 sents aligned for da and en\n",
      "368 sents aligned for de and en\n",
      "380 sents aligned for el and en\n",
      "384 sents aligned for en and da\n",
      "399 sents aligned for en and de\n",
      "373 sents aligned for en and el\n",
      "393 sents aligned for en and es\n",
      "361 sents aligned for en and fi\n",
      "390 sents aligned for en and fr\n",
      "383 sents aligned for en and it\n",
      "379 sents aligned for en and nl\n",
      "380 sents aligned for en and pt\n",
      "364 sents aligned for en and sv\n",
      "394 sents aligned for es and en\n",
      "377 sents aligned for fi and en\n",
      "397 sents aligned for fr and en\n",
      "395 sents aligned for it and en\n",
      "388 sents aligned for nl and en\n",
      "390 sents aligned for pt and en\n",
      "380 sents aligned for sv and en\n"
     ]
    }
   ],
   "source": [
    "for fi in files:\n",
    "    dataset, translator, s, t = fi.split('-')\n",
    "    src_sents_a, mt_sents_a = load_aligned_sents_from_file(fi, folder=src2hyp_fo)\n",
    "    key = f'{dataset}-{s}-{t}'\n",
    "    src_sents_o, ref_sents_o = load_aligned_sents_from_file(key, folder=src2ref_fo)\n",
    "    post_triplet_align(\n",
    "        src_sents_org=src_sents_o,\n",
    "        src_sents_ali=src_sents_a,\n",
    "        ref_sents_org=ref_sents_o,\n",
    "        mt_sents_ali=mt_sents_a,\n",
    "        src_lang=s,\n",
    "        ref_lang=t,\n",
    "        folder_path='post_triplets',\n",
    "        prefix=f'{dataset}-{translator}-'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add99461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.scoring import ResultProducer\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "files = os.listdir('post_triplets')\n",
    "os.makedirs('post_results', exist_ok=True)\n",
    "\n",
    "result_setup = ['ep-gpt', 'ep-deepl', 'flores-gpt',\n",
    "                'flores-deepl', 'opus-gpt', 'opus-deepl']\n",
    "\n",
    "for rs in result_setup:\n",
    "    l2f = {f.replace(f'{rs}-', '').replace('.jsonl', '')\n",
    "                     : join('post_triplets', f) for f in files if f.startswith(rs)}\n",
    "    rp = ResultProducer(label2files=l2f)\n",
    "    rp.compute_results()\n",
    "    rp.store_results(join('post_results', f'{rs}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ebde265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.scoring import create_matrix_from_csv\n",
    "res_files = os.listdir('post_results')\n",
    "post_res2df = {f.replace('.csv', ''): {'file': join(\n",
    "    'post_results', f), 'df': None} for f in res_files}\n",
    "\n",
    "for rs, content in post_res2df.items():\n",
    "    file_path = content['file']\n",
    "    df = create_matrix_from_csv(file_path)\n",
    "    post_res2df[rs]['df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6c7519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  34.1  28.3  41.0  36.2  25.8  36.0  27.9  31.1  31.2  31.5\n",
      "de  35.3   NaN  26.9  37.8  36.4  24.7  38.1  27.5  28.5  31.1  30.4\n",
      "el  34.3  30.2   NaN  39.3  38.4  23.6  37.7  28.8  28.8  34.5  29.5\n",
      "en  37.5  33.0  31.3   NaN  41.0  24.7  38.8  29.0  32.4  34.6  32.9\n",
      "es  36.8  33.0  30.4  43.3   NaN  25.0  39.7  30.4  30.2  35.8  30.8\n",
      "fi  32.6  28.9  25.4  35.8  31.7   NaN  32.6  24.8  27.3  28.0  27.0\n",
      "fr  32.7  30.1  27.6  38.4  37.5  22.4   NaN  28.5  28.8  33.3  28.4\n",
      "it  29.4  27.3  26.2  33.9  35.4  20.0  34.1   NaN  26.4  30.8  24.7\n",
      "nl  31.1  27.2  23.4  33.4  31.1  21.9  31.7  25.2   NaN  28.4  25.6\n",
      "pt  32.7  30.6  28.7  37.2  38.9  23.4  39.2  29.1  29.1   NaN  28.0\n",
      "sv  36.1  31.0  27.9  40.1  35.0  22.3  34.9  27.6  29.4  31.3   NaN\n",
      "\n",
      "ep-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  34.1  27.1  34.6  33.2  21.9  31.9  25.1  26.9  26.4  29.7\n",
      "de  34.8   NaN  23.4  32.6  35.0  20.4  31.1  25.0  25.5  27.2  27.7\n",
      "el  32.5  28.1   NaN  34.3  37.8  19.8  36.4  26.1  25.3  30.1  27.2\n",
      "en  34.7  27.4  28.8   NaN  36.9  19.2  33.4  26.9  28.2  24.3  28.4\n",
      "es  36.4  32.6  30.6  36.6   NaN  19.3  35.9  28.6  27.4  32.4  28.4\n",
      "fi  28.9  26.5  22.7  31.4  29.8   NaN  30.3  22.3  22.4  24.7  24.6\n",
      "fr  33.0  28.7  27.8  34.0  37.5  18.3   NaN  27.0  27.0  27.4  27.3\n",
      "it  27.0  23.3  25.2  29.4  32.4  15.5  29.2   NaN  23.4  26.6  22.2\n",
      "nl  30.8  23.8  22.9  31.8  29.8  17.6  28.8  23.6   NaN  24.3  25.0\n",
      "pt  32.7  28.4  28.6  33.1  35.6  18.8  34.0  26.3  26.3   NaN  24.6\n",
      "sv  33.0  28.3  24.6  33.8  32.8  19.2  30.0  25.2  24.5  25.0   NaN\n",
      "\n",
      "flores-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  37.7  27.2  54.7  26.5  26.3  44.8  31.0  29.5  35.1  39.7\n",
      "de  41.2   NaN  25.5  49.7  25.0  26.3  42.1  31.0  28.8  33.3  37.8\n",
      "el  34.5  31.6   NaN  41.8  24.7  21.8  38.7  28.0  24.7  29.8  31.2\n",
      "en  50.5  44.3  30.5   NaN  28.8  29.6  52.4  34.8  32.4  42.2  47.0\n",
      "es  30.5  27.7  20.6  35.9   NaN  20.1  35.7  27.2  24.7  27.3  27.6\n",
      "fi  33.2  30.8  22.2  39.0  21.5   NaN  37.2  26.6  25.1  28.4  30.2\n",
      "fr  38.6  34.7  25.4  49.3  26.2  25.0   NaN  30.6  27.4  33.8  35.4\n",
      "it  31.3  29.3  22.2  37.6  24.2  20.7  36.8   NaN  24.0  28.0  28.9\n",
      "nl  31.3  29.7  20.4  36.5  23.0  22.0  35.1  26.2   NaN  27.9  28.2\n",
      "pt  39.9  36.7  26.4  54.0  26.0  24.7  44.3  31.2  27.3   NaN  37.3\n",
      "sv  43.0  37.5  26.7  53.6  25.6  25.4  45.0  31.0  28.7  34.8   NaN\n",
      "\n",
      "flores-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN  38.7  25.4  51.6  26.9  25.5  43.8  29.6  28.9  42.1  39.0\n",
      "de  38.9   NaN  25.0  49.0  26.4  26.0  41.0  29.3  29.2  38.2  36.4\n",
      "el  34.7  32.3   NaN  43.5  25.4  22.5  39.1  25.6  26.5  35.8  32.5\n",
      "en  49.2  43.6  28.9   NaN  29.1  29.4  51.8  32.6  30.9  51.2  46.3\n",
      "es  28.8  28.5  19.9  36.2   NaN  19.3  32.4  21.7  23.3  24.4  27.3\n",
      "fi  30.4  30.1  21.4  40.2  23.1   NaN  36.6  25.8  25.4  32.7  27.8\n",
      "fr  36.8  35.1  25.0  49.8  26.7  24.5   NaN  26.5  26.7  40.1  35.4\n",
      "it  29.4  31.0  21.1  39.6  22.7  20.9  33.4   NaN  23.5  29.2  28.5\n",
      "nl  28.3  28.5  19.2  37.3  23.5  18.8  33.4  23.9   NaN  30.9  25.5\n",
      "pt  39.3  37.0  24.3  55.8  25.5  24.6  45.1  27.4  27.8   NaN  36.9\n",
      "sv  40.0  38.2  24.8  52.9  26.4  24.4  41.9  28.6  28.1  41.5   NaN\n",
      "\n",
      "opus-deepl\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN   NaN   NaN  41.7   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "de   NaN   NaN   NaN  37.3   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "el   NaN   NaN   NaN  36.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "en  40.6  33.3  30.8   NaN  41.6  26.6  41.3  35.7  33.9  35.8  37.4\n",
      "es   NaN   NaN   NaN  46.4   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fi   NaN   NaN   NaN  35.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fr   NaN   NaN   NaN  42.4   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "it   NaN   NaN   NaN  38.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "nl   NaN   NaN   NaN  35.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "pt   NaN   NaN   NaN  41.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "sv   NaN   NaN   NaN  38.4   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "\n",
      "opus-gpt\n",
      "      da    de    el    en    es    fi    fr    it    nl    pt    sv\n",
      "da   NaN   NaN   NaN  39.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "de   NaN   NaN   NaN  36.6   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "el   NaN   NaN   NaN  34.6   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "en  37.0  31.6  29.8   NaN  40.5  21.1  36.9  33.5  32.2  31.0  33.0\n",
      "es   NaN   NaN   NaN  44.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fi   NaN   NaN   NaN  33.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "fr   NaN   NaN   NaN  40.3   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "it   NaN   NaN   NaN  37.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "nl   NaN   NaN   NaN  31.8   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "pt   NaN   NaN   NaN  38.9   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "sv   NaN   NaN   NaN  36.2   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in post_res2df:\n",
    "    out = post_res2df[key]['df'].round(1)\n",
    "    print(key)\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf89af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep\n",
      "Pearson correlation: 0.93\n",
      "p-value: 0.000\n",
      "\n",
      "flores\n",
      "Pearson correlation: 0.96\n",
      "p-value: 0.000\n",
      "\n",
      "opus\n",
      "Pearson correlation: 0.96\n",
      "p-value: 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "parts = ['ep', 'flores', 'opus']\n",
    "\n",
    "for part in parts:\n",
    "    gpt = f'{part}-gpt'\n",
    "    deepl = f'{part}-deepl'\n",
    "    gpt_df = post_res2df[gpt]['df']\n",
    "    deepl_df = post_res2df[deepl]['df']\n",
    "\n",
    "    gpt_flat = gpt_df.values.flatten()\n",
    "    deepl_flat = deepl_df.values.flatten()\n",
    "\n",
    "    mask = ~np.isnan(gpt_flat) & ~np.isnan(deepl_flat)\n",
    "\n",
    "    # Compute Pearson correlation\n",
    "    corr, pval = pearsonr(gpt_flat[mask], deepl_flat[mask])\n",
    "    print(part)\n",
    "    print(f\"Pearson correlation: {corr:.2f}\")\n",
    "    print(f\"p-value: {pval:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe2f3b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-deepl\n",
      "mean 0.32\n",
      "max 2.43\n",
      "min -0.91\n",
      "\n",
      "ep-gpt\n",
      "mean 2.15\n",
      "max 34.19\n",
      "min -0.56\n",
      "\n",
      "flores-deepl\n",
      "mean 0.09\n",
      "max 0.74\n",
      "min -0.23\n",
      "\n",
      "flores-gpt\n",
      "mean 1.74\n",
      "max 32.75\n",
      "min -0.29\n",
      "\n",
      "opus-deepl\n",
      "mean 1.52\n",
      "max 3.40\n",
      "min 0.23\n",
      "\n",
      "opus-gpt\n",
      "mean 4.45\n",
      "max 38.80\n",
      "min 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for key in post_res2df:\n",
    "    out = post_res2df[key]['df'] - res2df[key]['df']\n",
    "    print(key)\n",
    "    print('mean', f'{np.nanmean(out.values):.2f}')\n",
    "    print('max', f'{np.nanmax(out.values):.2f}')\n",
    "    print('min', f'{np.nanmin(out.values):.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bdbdf",
   "metadata": {},
   "source": [
    "* We can check if the misaligned were improved with the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ad15da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep-gpt\n",
      "da-it: 19.91 -> 25.13\n",
      "es-el: 15.40 -> 30.55\n",
      "es-nl: 15.05 -> 27.40\n",
      "it-fi: 13.18 -> 15.49\n",
      "el-nl: 12.86 -> 25.28\n",
      "el-it: 11.54 -> 26.05\n",
      "de-en: 7.48 -> 32.61\n",
      "fi-it: 7.24 -> 22.30\n",
      "fi-nl: 6.73 -> 22.44\n",
      "sv-fi: 6.63 -> 19.18\n",
      "en-fi: 5.88 -> 19.21\n",
      "pt-fi: 5.85 -> 18.76\n",
      "de-fi: 4.77 -> 20.43\n",
      "es-en: 2.41 -> 36.59\n",
      "\n",
      "flores-gpt\n",
      "fi-es: 0.65 -> 23.09\n",
      "it-fr: 0.62 -> 33.37\n",
      "fi-nl: 0.60 -> 25.39\n",
      "fi-pt: 0.58 -> 32.68\n",
      "fi-da: 0.29 -> 30.45\n",
      "es-el: 0.23 -> 19.87\n",
      "fi-el: 0.22 -> 21.36\n",
      "\n",
      "opus-gpt\n",
      "de-en: 10.65 -> 36.60\n",
      "pt-en: 0.11 -> 38.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import json\n",
    "with open(join('translations', 'info.json'), 'r') as f:\n",
    "    prefix2file = json.load(f)\n",
    "\n",
    "mismatches = {\n",
    "    'ep-gpt': [],\n",
    "    'flores-gpt': [],\n",
    "    'opus-gpt': [],\n",
    "}\n",
    "\n",
    "for prefix, info in prefix2file.items():\n",
    "    dataset, translator, s, t = prefix.split('-')\n",
    "    key = f'{dataset}-{translator}'\n",
    "    outlines = info['log']['out_lines']\n",
    "    if outlines != 400:\n",
    "        score = res2df[key]['df'].loc[s, t]\n",
    "        improved = post_res2df[key]['df'].loc[s, t]\n",
    "        mismatches[key].append((f'{s}-{t}', score, improved))\n",
    "\n",
    "for key in mismatches:\n",
    "    print(key)\n",
    "    for item in sorted(mismatches[key], key=lambda x: x[1], reverse=True):\n",
    "        label, score, improved = item\n",
    "        print(f'{label}: {score:.2f} -> {improved:.2f}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
